{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "extractor incremental mean images with and without clusters.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6vORZRxNJYy",
        "colab_type": "text"
      },
      "source": [
        "# **Setup**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "949YS4s7JotS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "6cadee55-eb8d-4180-f7a1-a67a4f2977a5"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Jun 23 09:06:26 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBlcck1tgm95",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ac47f65d-ab98-407a-fee0-304f0fd1a3f4"
      },
      "source": [
        "!cat /proc/cpuinfo"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processor\t: 0\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 79\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0x1\n",
            "cpu MHz\t\t: 2200.000\n",
            "cache size\t: 56320 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 4\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 2\n",
            "apicid\t\t: 0\n",
            "initial apicid\t: 0\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa itlb_multihit\n",
            "bogomips\t: 4400.00\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 1\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 79\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0x1\n",
            "cpu MHz\t\t: 2200.000\n",
            "cache size\t: 56320 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 4\n",
            "core id\t\t: 1\n",
            "cpu cores\t: 2\n",
            "apicid\t\t: 2\n",
            "initial apicid\t: 2\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa itlb_multihit\n",
            "bogomips\t: 4400.00\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 2\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 79\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0x1\n",
            "cpu MHz\t\t: 2200.000\n",
            "cache size\t: 56320 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 4\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 2\n",
            "apicid\t\t: 1\n",
            "initial apicid\t: 1\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa itlb_multihit\n",
            "bogomips\t: 4400.00\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 3\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 79\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0x1\n",
            "cpu MHz\t\t: 2200.000\n",
            "cache size\t: 56320 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 4\n",
            "core id\t\t: 1\n",
            "cpu cores\t: 2\n",
            "apicid\t\t: 3\n",
            "initial apicid\t: 3\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa itlb_multihit\n",
            "bogomips\t: 4400.00\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbHg8CdIoYRN",
        "colab_type": "text"
      },
      "source": [
        "**CHECK FOR DECENT GPU** (not K80)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CO92U6fAmzk9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "52b296d4-1fc5-4a29-dba1-18a53e884c71"
      },
      "source": [
        "# download and unpack tsnecuda from anaconda.org\n",
        "\n",
        "!wget https://anaconda.org/CannyLab/tsnecuda/2.1.0/download/linux-64/tsnecuda-2.1.0-cuda100.tar.bz2\n",
        "!tar xvjf tsnecuda-2.1.0-cuda100.tar.bz2\n",
        "!cp -r site-packages/* /usr/local/lib/python3.6/dist-packages/\n",
        "!echo $LD_LIBRARY_PATH \n",
        "!ln -s /content/lib/libfaiss.so $LD_LIBRARY_PATH/libfaiss.so\n",
        "import tsnecuda\n",
        "# tsnecuda.test()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-23 09:06:35--  https://anaconda.org/CannyLab/tsnecuda/2.1.0/download/linux-64/tsnecuda-2.1.0-cuda100.tar.bz2\n",
            "Resolving anaconda.org (anaconda.org)... 104.17.93.24, 104.17.92.24, 2606:4700::6811:5d18, ...\n",
            "Connecting to anaconda.org (anaconda.org)|104.17.93.24|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-tar]\n",
            "Saving to: ‘tsnecuda-2.1.0-cuda100.tar.bz2’\n",
            "\n",
            "tsnecuda-2.1.0-cuda     [         <=>        ]  35.75M  7.86MB/s    in 5.4s    \n",
            "\n",
            "2020-06-23 09:06:42 (6.60 MB/s) - ‘tsnecuda-2.1.0-cuda100.tar.bz2’ saved [37484309]\n",
            "\n",
            "info/hash_input.json\n",
            "info/index.json\n",
            "info/files\n",
            "info/git\n",
            "info/about.json\n",
            "info/recipe/docker/Dockerfile\n",
            "info/recipe/docs/results/speedup.png\n",
            "info/recipe/docs/results/multi-threaded.png\n",
            "info/recipe/docs/cifar_speedup.png\n",
            "info/recipe/docs/results/single-threaded.png\n",
            "info/recipe/docs/mnist_speedup.png\n",
            "info/recipe/docs/simulated_speedup.png\n",
            "info/recipe/build/.gitkeep\n",
            "info/recipe/conda_build_config.yaml\n",
            "info/recipe/meta.yaml\n",
            "site-packages/tsnecuda-2.1.0-py3.7.egg-info/dependency_links.txt\n",
            "site-packages/tsnecuda-2.1.0-py3.7.egg-info/top_level.txt\n",
            "site-packages/tsnecuda-2.1.0-py3.7.egg-info/requires.txt\n",
            "info/recipe/src/python/CHANGES.txt\n",
            "info/recipe/src/python/LICENSE.txt\n",
            "info/recipe/src/python/docs/FAQ.txt\n",
            "site-packages/tsnecuda-2.1.0-py3.7.egg-info/SOURCES.txt\n",
            "info/recipe/src/python/README.txt\n",
            "info/recipe/src/style_guide.txt\n",
            "info/recipe/CMakeLists.txt\n",
            "info/recipe/src/util/thrust_utils.cu\n",
            "info/recipe/src/util/debug_utils.cu\n",
            "info/recipe/src/util/random_utils.cu\n",
            "info/recipe/src/util/reduce_utils.cu\n",
            "info/recipe/src/kernels/attr_forces.cu\n",
            "info/recipe/src/test/test.cu\n",
            "info/recipe/src/kernels/rep_forces.cu\n",
            "info/recipe/src/kernels/apply_forces.cu\n",
            "info/recipe/src/ext/pymodule_ext.cu\n",
            "info/recipe/src/util/matrix_broadcast_utils.cu\n",
            "info/recipe/src/kernels/perplexity_search.cu\n",
            "info/recipe/src/util/cuda_utils.cu\n",
            "info/recipe/src/util/data_utils.cu\n",
            "info/recipe/src/exe/main.cu\n",
            "info/recipe/src/util/math_utils.cu\n",
            "info/recipe/src/util/distance_utils.cu\n",
            "info/recipe/src/kernels/nbodyfft.cu\n",
            "info/recipe/src/fit_tsne.cu\n",
            "info/recipe/docs/.gitignore\n",
            "info/recipe/visualization/animation.gif\n",
            "info/recipe/docs/mnist_comparison.jpg\n",
            "info/recipe/.travis.yml\n",
            "site-packages/tsnecuda-2.1.0-py3.7.egg-info/PKG-INFO\n",
            "bin/.tsnecuda-pre-link.sh\n",
            "info/recipe/docker/clone_and_build.sh\n",
            "info/recipe/docker/conda_build.sh\n",
            "info/recipe/build.sh\n",
            "lib/libgtest_main.a\n",
            "lib/libgmock_main.a\n",
            "lib/libgmock.a\n",
            "lib/libgtest.a\n",
            "info/recipe/README.md\n",
            "info/recipe/meta.yaml.template\n",
            "info/recipe/cmake/write_python_version_string.cmake\n",
            "info/recipe/cross-linux.cmake\n",
            "info/recipe/cmake/Modules/FindOpenBLAS.cmake\n",
            "info/recipe/cmake/Modules/FindFFTW.cmake\n",
            "info/recipe/cmake/Modules/FindMKL.cmake\n",
            "info/recipe/src/python/tsnecuda/__init__.py\n",
            "site-packages/tsnecuda/__init__.py\n",
            "info/recipe/src/python/setup.py\n",
            "info/recipe/visualization/vis_rt.py\n",
            "info/recipe/visualization/visualize_mnist.py\n",
            "info/recipe/visualization/visualize.py\n",
            "info/recipe/docs/test_dist_cont.py\n",
            "link.py\n",
            "info/recipe/.ycm_extra_conf.py\n",
            "info/recipe/src/python/tsnecuda/TSNE.py\n",
            "site-packages/tsnecuda/TSNE.py\n",
            "site-packages/tsnecuda/test/__init__.py\n",
            "info/recipe/src/python/tsnecuda/test/__init__.py\n",
            "info/recipe/src/python/MANIFEST.in\n",
            "info/recipe/docs/Doxyfile.in\n",
            "info/recipe/src/include/kernels/rep_forces.h\n",
            "info/recipe/src/include/util/debug_utils.h\n",
            "info/recipe/src/include/fit_tsne.h\n",
            "info/recipe/src/include/kernels/apply_forces.h\n",
            "info/recipe/src/include/kernels/attr_forces.h\n",
            "info/recipe/src/include/util/random_utils.h\n",
            "info/recipe/src/include/common.h\n",
            "info/recipe/src/include/util/cuda_utils.h\n",
            "info/recipe/src/include/util/thrust_transform_functions.h\n",
            "info/recipe/src/include/kernels/perplexity_search.h\n",
            "info/recipe/src/include/util/thrust_utils.h\n",
            "info/recipe/src/include/ext/pymodule_ext.h\n",
            "info/recipe/src/include/kernels/nbodyfft.h\n",
            "info/recipe/src/include/util/matrix_broadcast_utils.h\n",
            "info/recipe/src/include/util/data_utils.h\n",
            "info/recipe/src/include/test/test_distance.h\n",
            "info/recipe/src/include/util/reduce_utils.h\n",
            "info/recipe/src/include/test/test_math.h\n",
            "info/recipe/src/include/util/math_utils.h\n",
            "info/recipe/src/include/util/distance_utils.h\n",
            "info/recipe/src/include/test/test_reduce.h\n",
            "info/recipe/src/include/options.h\n",
            "info/recipe/src/include/test/test_tsne.h\n",
            "info/recipe/docs/results/benchmark_results.pkl\n",
            "lib/libfaiss.so\n",
            "site-packages/tsnecuda/libtsnecuda.so\n",
            "info/recipe/.gitignore\n",
            "info/recipe/.gitmodules\n",
            "info/recipe/LICENSE\n",
            "info/recipe/src/python/MANIFEST\n",
            "Scripts/.tsnecuda-pre-link.bat\n",
            "/usr/lib64-nvidia\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJw2tn6ohu3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tsnecuda\n",
        "# tsnecuda.test()\n",
        "from tsnecuda import TSNE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjmzHT-Q3RR4",
        "colab_type": "text"
      },
      "source": [
        "**Install python packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uneVv4y2YcwF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "3c01a654-6e9e-4ca3-e93c-a8450e157aec"
      },
      "source": [
        "'''\n",
        "!pip3 install 'torch==1.4.0'\n",
        "!pip3 install 'torchvision==0.5.0'\n",
        "!pip3 install 'Pillow-SIMD'\n",
        "!pip3 install 'tqdm'\n",
        "'''\n",
        "!pip install kmeans-pytorch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kmeans-pytorch\n",
            "  Downloading https://files.pythonhosted.org/packages/b5/c9/eb5b82e7e9741e61acf1aff70530a08810aa0c7e2272c534ff7a150fc5bd/kmeans_pytorch-0.3-py3-none-any.whl\n",
            "Installing collected packages: kmeans-pytorch\n",
            "Successfully installed kmeans-pytorch-0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPJT2xmJ3Xnm",
        "colab_type": "text"
      },
      "source": [
        "**Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBUh1xw7Yr6k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import logging\n",
        "import copy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "import dill\n",
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKMon4lO3aYE",
        "colab_type": "text"
      },
      "source": [
        "**Download dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XABs0cQ7ak2r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# if not os.path.isdir('./cifar-100-python'):\n",
        "#   !wget https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
        "#   !tar xfz cifar-100-python.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Gob5Y8_9SoR",
        "colab_type": "text"
      },
      "source": [
        "**MACROS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXGAM0a43mCg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DEVICE = 'cuda'\n",
        "\n",
        "NUM_EPOCHS = 70\n",
        "BATCH_SIZE = 128\n",
        "LR = 2.0\n",
        "GAMMA = 0.2\n",
        "K = 2000\n",
        "FIRST_STEP = 49\n",
        "SECOND_STEP = 63"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISfQL4G03rIN",
        "colab_type": "text"
      },
      "source": [
        "**Load datasets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da1N6YJuEz-H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define transforms for training phase\n",
        "train_transform = transforms.Compose([\n",
        "                                      transforms.ToPILImage(),\n",
        "                                      transforms.RandomCrop(32, padding=4),\n",
        "                                      transforms.RandomHorizontalFlip(0.5),\n",
        "                                      transforms.ToTensor(), # Turn PIL Image to torch.Tensor\n",
        "                                      transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)) # Normalizes tensor with mean and standard deviation\n",
        "])\n",
        "# Define transforms for the evaluation phase\n",
        "eval_transform = transforms.Compose([\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))                                    \n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWcKmQ86ZCES",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = torchvision.datasets.CIFAR100('./', train=True, transform=train_transform, target_transform=None, download=True)\n",
        "test_dataset = torchvision.datasets.CIFAR100('./', train=False, transform=eval_transform, target_transform=None, download=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AS480DOfNrzq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "886a260d-bd7e-429b-bb8e-63bdb3a921d4"
      },
      "source": [
        "print(train_dataset.class_to_idx)\n",
        "print(train_dataset.classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'apple': 0, 'aquarium_fish': 1, 'baby': 2, 'bear': 3, 'beaver': 4, 'bed': 5, 'bee': 6, 'beetle': 7, 'bicycle': 8, 'bottle': 9, 'bowl': 10, 'boy': 11, 'bridge': 12, 'bus': 13, 'butterfly': 14, 'camel': 15, 'can': 16, 'castle': 17, 'caterpillar': 18, 'cattle': 19, 'chair': 20, 'chimpanzee': 21, 'clock': 22, 'cloud': 23, 'cockroach': 24, 'couch': 25, 'crab': 26, 'crocodile': 27, 'cup': 28, 'dinosaur': 29, 'dolphin': 30, 'elephant': 31, 'flatfish': 32, 'forest': 33, 'fox': 34, 'girl': 35, 'hamster': 36, 'house': 37, 'kangaroo': 38, 'keyboard': 39, 'lamp': 40, 'lawn_mower': 41, 'leopard': 42, 'lion': 43, 'lizard': 44, 'lobster': 45, 'man': 46, 'maple_tree': 47, 'motorcycle': 48, 'mountain': 49, 'mouse': 50, 'mushroom': 51, 'oak_tree': 52, 'orange': 53, 'orchid': 54, 'otter': 55, 'palm_tree': 56, 'pear': 57, 'pickup_truck': 58, 'pine_tree': 59, 'plain': 60, 'plate': 61, 'poppy': 62, 'porcupine': 63, 'possum': 64, 'rabbit': 65, 'raccoon': 66, 'ray': 67, 'road': 68, 'rocket': 69, 'rose': 70, 'sea': 71, 'seal': 72, 'shark': 73, 'shrew': 74, 'skunk': 75, 'skyscraper': 76, 'snail': 77, 'snake': 78, 'spider': 79, 'squirrel': 80, 'streetcar': 81, 'sunflower': 82, 'sweet_pepper': 83, 'table': 84, 'tank': 85, 'telephone': 86, 'television': 87, 'tiger': 88, 'tractor': 89, 'train': 90, 'trout': 91, 'tulip': 92, 'turtle': 93, 'wardrobe': 94, 'whale': 95, 'willow_tree': 96, 'wolf': 97, 'woman': 98, 'worm': 99}\n",
            "['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z02x1UlmNfWK",
        "colab_type": "text"
      },
      "source": [
        "# **Split Dataset into batches of 10 classes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFQMAnDpqSZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = train_dataset.classes.copy()\n",
        "random.seed(666)\n",
        "random.shuffle(labels)\n",
        "\n",
        "# incremental_mapping = train_dataset.class_to_idx\n",
        "# partitions = [labels]\n",
        "\n",
        "incremental_mapping = {v: k for k, v in enumerate(labels)}\n",
        "partitions = []\n",
        "for i in range(10):\n",
        "  partitions.append(labels[i*10:(i+1)*10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxSqAzdFeinM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BatchDataset:\n",
        "  def __init__(self, dataset, labels, split='train', transform=None, target_transform=None, mapping = incremental_mapping):\n",
        "    self.data_per_label=[]\n",
        "    self.split = split\n",
        "    self.transform = transform\n",
        "    self.target_transform = target_transform\n",
        "    self.data = []\n",
        "    self.labels = labels\n",
        "    self.labels_to_int = [incremental_mapping[label] for label in labels]\n",
        "    \n",
        "    for label in labels: \n",
        "      data_per_label=[(dataset.data[x], int(self.labels_to_int[labels.index(label)])) for x in [index for index, element in enumerate(dataset.targets) if element == dataset.class_to_idx[label]]]\n",
        "      self.data+=data_per_label\n",
        "      self.data_per_label.append(data_per_label)\n",
        "  def __getitem__(self, index):\n",
        "    image, label = self.data[index]\n",
        "    if self.transform is not None:\n",
        "      image = self.transform(image)\n",
        "    return index, image, label\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpCwcPv3b-WF",
        "colab_type": "text"
      },
      "source": [
        "**Create splits**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHk5_g6Pj_sL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ce98fc8d-2f1f-4973-8c45-22585c41e668"
      },
      "source": [
        "train_datasets = []\n",
        "# val_datasets = []\n",
        "test_datasets = []\n",
        "\n",
        "for i, partition in enumerate(partitions):\n",
        "  batch_test=BatchDataset(test_dataset,partition,transform=eval_transform, mapping = incremental_mapping)\n",
        "  test_datasets.append(batch_test)\n",
        "  batch = BatchDataset(train_dataset, partition,transform=train_transform, mapping = incremental_mapping)\n",
        "  train_datasets.append(batch)\n",
        "  # sss = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2)\n",
        "  # for train_indexes, val_indexes in sss.split(range(len(batch)), [x[1] for x in batch.data]):\n",
        "    # batch_val_dataset = Subset(batch, val_indexes)\n",
        "    # batch_train_dataset = Subset(batch, train_indexes)\n",
        "    # train_datasets.append(batch_train_dataset)\n",
        "    # val_datasets.append(batch_val_dataset)\n",
        "print(len(train_dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLbmVHm5Nwsk",
        "colab_type": "text"
      },
      "source": [
        "# **ResNet32**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Exbyc4iv_Cpe",
        "colab_type": "text"
      },
      "source": [
        "**ResNets for CIFAR100**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQkjYKsDBaGR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "\"\"\"\n",
        "Credits to @hshustc\n",
        "Taken from https://github.com/hshustc/CVPR19_Incremental_Learning/tree/master/cifar100-class-incremental\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers):\n",
        "        self.inplanes = 16\n",
        "        super(ResNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = self._make_layer(block, 16, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 32, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 64, layers[2], stride=2)\n",
        "        self.avgpool = nn.AvgPool2d(8, stride=1)\n",
        "\n",
        "        self.out_dim = 64 * block.expansion\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        return x\n",
        "\n",
        "def resnet20(pretrained=False, **kwargs):\n",
        "    n = 3\n",
        "    model = ResNet(BasicBlock, [n, n, n], **kwargs)\n",
        "    return model\n",
        "\n",
        "def resnet32(pretrained=False, **kwargs):\n",
        "    n = 5\n",
        "    model = ResNet(BasicBlock, [n, n, n], **kwargs)\n",
        "    return model\n",
        "\n",
        "def resnet56(pretrained=False, **kwargs):\n",
        "    n = 9\n",
        "    model = ResNet(Bottleneck, [n, n, n], **kwargs)\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZxOzjlMXB8v",
        "colab_type": "text"
      },
      "source": [
        "# **iCaRL model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9686ugaH5XYt",
        "colab_type": "text"
      },
      "source": [
        "ICARL NET "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyh9W7MM5RUR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "from torch.utils.data import DataLoader\n",
        "from kmeans_pytorch import kmeans, kmeans_predict\n",
        "\n",
        "class iCarlNet(nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes):\n",
        "    self.total_num_classes = n_classes\n",
        "    self.known_classes = 0\n",
        "    self.list_known_classes=[]\n",
        "    self.exemplar_sets = []\n",
        "    self.flag_mean = True\n",
        "    self.exemplar_means = []\n",
        "    self.exemplars_list_knn=[]\n",
        "    self.labels_knn=[]\n",
        "    self.flag=True\n",
        "    # We take a standard ResNet and Extend it\n",
        "    super(iCarlNet, self).__init__()\n",
        "    self.extractor = resnet32()\n",
        "    self.fully_connected = nn.Linear(self.extractor.out_dim, 0, bias=True)\n",
        "    #self.fully_connected=nn.Sequential(nn.Linear(self.extractor.out_dim,self.extractor.out_dim,bias=True),nn.ReLU(),nn.Linear(self.extractor.out_dim,self.extractor.out_dim,bias=True),nn.ReLU(),nn.Linear(self.extractor.out_dim,0))\n",
        "    #self.fully_connected=nn.Sequential(nn.Linear(self.extractor.out_dim,self.extractor.out_dim,bias=True),nn.ReLU(),nn.Linear(self.extractor.out_dim,42,bias=True),nn.ReLU(),nn.Linear(42,0))\n",
        "    torch.nn.init.xavier_uniform_(self.fully_connected.weight)\n",
        "    self.fully_connected.bias.data.fill_(0.01)\n",
        "    self.loss=nn.BCEWithLogitsLoss()\n",
        "        \n",
        "  def forward(self, x):\n",
        "    # X: input data\n",
        "\n",
        "    self.extractor.to(DEVICE)\n",
        "    self.fully_connected.to(DEVICE)\n",
        "\n",
        "    x = self.extractor(x)\n",
        "    x = self.fully_connected(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "  def batch_forward(self,x):\n",
        "    self.step_extractor.to(DEVICE)\n",
        "    self.step_fully_connected.to(DEVICE)\n",
        "    x = self.step_extractor(x)\n",
        "    x = self.step_fully_connected(x)\n",
        "    return x\n",
        "\n",
        "  def batch_trainer(self,dataset):\n",
        "    self.train()\n",
        "    self.step_fully_connected = nn.Linear(self.extractor.out_dim, 10, bias=True)\n",
        "    torch.nn.init.xavier_uniform_(self.step_fully_connected.weight)\n",
        "    self.step_fully_connected.bias.data.fill_(0.01)\n",
        "    self.step_extractor = resnet32()\n",
        "    classes_to_idx = dataset.labels_to_int\n",
        "    offset = min(classes_to_idx)\n",
        "    train_data_loader = DataLoader(\n",
        "        dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "    \n",
        "    optimizer = optim.SGD(self.parameters(), lr=2.0,weight_decay=0.00001, momentum = 0.9)\n",
        "    scheduler = MultiStepLR(optimizer,[47,63],gamma=GAMMA)\n",
        "\n",
        "    N_CLASSES = 10\n",
        "    eye = torch.eye(N_CLASSES)\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "      print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], LR: {scheduler.get_last_lr()}\")\n",
        "      i=0\n",
        "      for indices, images, labels in train_data_loader:\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "        indices = indices.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        labels_one_hot_new_classes = []\n",
        "        for label in labels:\n",
        "          labels_one_hot_new_classes.append(eye[label-offset])\n",
        "        labels_one_hot_new_classes = torch.stack(labels_one_hot_new_classes).cuda()\n",
        "        output = self.batch_forward(images)\n",
        "        loss=self.loss(output,labels_one_hot_new_classes)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        i+=1\n",
        "      print(f\"Loss step extractor: {loss.item()}\")\n",
        "      torch.cuda.empty_cache()\n",
        "      scheduler.step() \n",
        "  \n",
        "  def classify_without_mean_cosine_similarity(self,input_image_batch):\n",
        "    # input image batch: batch of 128 images to compute predictions on\n",
        "\n",
        "    self.eval()\n",
        "    with torch.no_grad():\n",
        "      # mean: tensor of dimension: known_classes x features (64)\n",
        "      mean = torch.stack(self.exemplar_means).squeeze(1).cuda()\n",
        "      # extract the features of the whole batch \n",
        "      self.extractor.to(DEVICE)   \n",
        "      features = self.extractor(input_image_batch)        \n",
        "      predictions = []\n",
        "\n",
        "      # normalize and predict by nearest exemplar mean\n",
        "      for n, feature in enumerate(features):\n",
        "        feature.data = feature.data / feature.data.norm() \n",
        "        feature=feature.expand_as(mean)\n",
        "        cosine_similarity = nn.CosineSimilarity(dim=1, eps=1e-08)\n",
        "        distances=cosine_similarity(feature,mean)\n",
        "        predictions.append(torch.argmax(distances, 0))\n",
        "      return predictions\n",
        "\n",
        "  def compute_exemplar_list_knn(self,transform):\n",
        "    self.eval()\n",
        "    with torch.no_grad():\n",
        "      exemplar_features = []\n",
        "      labels=[]\n",
        "      for i,exemplars in enumerate(self.exemplar_sets):\n",
        "        for exemplar in exemplars:\n",
        "          feature = self.extractor(transform(exemplar).unsqueeze(0).cuda())\n",
        "          feature.data = feature.data / feature.data.norm()\n",
        "          exemplar_features.append(feature)\n",
        "          labels.append(i)\n",
        "      \n",
        "      self.exemplars_list_knn=exemplar_features\n",
        "      self.labels_knn=labels\n",
        "\n",
        "  def KNN_classify(self,input_image_batch,k):\n",
        "    exemplar_features=torch.stack(self.exemplars_list_knn).squeeze(1)\n",
        "    self.eval()\n",
        "    with torch.no_grad():\n",
        "      # mean: tensor of dimension: known_classes x features (64)\n",
        "      # mean = torch.stack(self.exemplar_means).squeeze(1).cuda()\n",
        "      # extract the features of the whole batch \n",
        "      self.extractor.to(DEVICE)   \n",
        "      features = self.extractor(input_image_batch)        \n",
        "      predictions = []\n",
        "\n",
        "      # normalize and predict by nearest exemplar mean\n",
        "      for n, feature in enumerate(features):\n",
        "        labels_knn=[]\n",
        "        feature.data = feature.data / feature.data.norm() \n",
        "        feature=feature.expand_as(exemplar_features)\n",
        "        l2_distances=torch.sum((feature - exemplar_features)**2, 1)\n",
        "        knn=l2_distances.topk(k, largest=False)\n",
        "        for index in knn.indices.tolist():\n",
        "          labels_knn.append(self.labels_knn[index])\n",
        "        predictions.append(torch.tensor(max(set(labels_knn),key=labels_knn.count)))\n",
        "      return predictions\n",
        "\n",
        "  def update_representation_using_cross_entropy_and_kl(self, dataset):\n",
        "    # dataset: training data belonging to 10 new classes\n",
        "\n",
        "    ########################################\n",
        "    #loss1=nn.MSELoss()\n",
        "    loss1=nn.CrossEntropyLoss(ignore_index=-1)\n",
        "    loss2=nn.MSELoss()\n",
        "    #loss2=nn.KLDivLoss(reduction='batchmean')\n",
        "    #loss2=nn.CrossEntropyLoss()\n",
        "    sigmoid = nn.Sigmoid()\n",
        "    log_sigmoid = nn.LogSigmoid()\n",
        "    softmax = nn.Softmax()\n",
        "    log_softmax = nn.LogSoftmax()\n",
        "    optimizer = optim.SGD(self.parameters(), lr=0.2,weight_decay=0.00001, momentum = 0.9)\n",
        "    scheduler = MultiStepLR(optimizer,[47,63],gamma=GAMMA)\n",
        "    ########################################\n",
        "\n",
        "    self.combine_dataset_with_exemplars(dataset)\n",
        "    self.flag_mean = True\n",
        "    classes_to_idx = dataset.labels_to_int\n",
        "    new_classes = [cls for cls in classes_to_idx if cls not in self.list_known_classes]\n",
        "\n",
        "    train_data_loader = DataLoader(\n",
        "        dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "    \n",
        "    # if some classes have been previously observed, compute the\n",
        "    # outputs of the new data on the old weights\n",
        "\n",
        "    if self.known_classes > 0:\n",
        "      self.eval()\n",
        "      logits_old_net = torch.zeros(len(dataset.data), self.known_classes).cuda()\n",
        "      labels_old_net = torch.zeros(len(dataset.data)).cuda()\n",
        "\n",
        "      with torch.no_grad():\n",
        "        for indices, images, labels in train_data_loader:\n",
        "          images = images.to(DEVICE)\n",
        "          g = self.forward(images)\n",
        "          logits_old_net[indices] = sigmoid(g)\n",
        "          #logits_old_net[indices]=softmax(g)\n",
        "          _,predictions=torch.max(g.data,1)\n",
        "          labels_old_net[indices]=predictions.type(torch.cuda.FloatTensor)\n",
        "\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "    self.increment_classes(new_classes)\n",
        "    \n",
        "    # start training on the new batch of 10 classes + exemplars\n",
        "    self.train()\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "      print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], LR: {scheduler.get_last_lr()}\")\n",
        "      i=0\n",
        "      for indices, images, labels in train_data_loader:\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "        indices = indices.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        output = self.forward(images)\n",
        "\n",
        "        # classification loss only for the first batch of 10 classes\n",
        "        if self.known_classes==0:\n",
        "          #labels_one_hot_new_classes = []\n",
        "          #for label in labels:\n",
        "          #  labels_one_hot_new_classes.append(eye[label])\n",
        "          #labels_one_hot_new_classes = torch.stack(labels_one_hot_new_classes).cuda()\n",
        "          #loss=self.loss(output,labels_one_hot_new_classes)\n",
        "          #loss=loss1(softmax(output),torch.eye(self.known_classes+10)[labels].cuda()) mse calssification\n",
        "          loss=loss1(output,labels) #croos_entropy classification\n",
        "          loss.backward()\n",
        "        # clf + dst loss\n",
        "        if self.known_classes > 0:\n",
        "          #labels_one_hot_new_classes = eye[:, self.known_classes:]\n",
        "          # print(labels_one_hot_new_classes.size())\n",
        "          #labels_one_hot = []\n",
        "          #for label in labels:\n",
        "          #  labels_one_hot.append(labels_one_hot_new_classes[label])\n",
        "          #labels_one_hot = torch.stack(labels_one_hot).cuda()\n",
        "          logits = logits_old_net[indices].cuda()\n",
        "          labels_distillation=labels_old_net[indices].cuda()\n",
        "          # print(f\"logits old net: {logits.size()}\")\n",
        "          # print(f\"new classes onehot encoded: {labels_one_hot.size()}\")\n",
        "          #labels_concatenate = torch.zeros(logits_old_net.size()\n",
        "          # print(f\"{logits.size()}-{labels_one_hot.size()}\")\n",
        "          #labels_concatenate=torch.cat((logits,labels_one_hot),dim=1)\n",
        "          #loss_classification=loss1(softmax(output),torch.eye(self.known_classes+10)[labels].cuda()) #mse classification\n",
        "          loss_classification=loss1(output,labels) #cross_entropy classification\n",
        "          #print(\"loss_classification :{}\".format(loss_classification.item()))\n",
        "          #loss_distillation=loss2((output[:,:self.known_classes]),labels_distillation.type(torch.cuda.LongTensor)) #cross_entropy_distillation\n",
        "          loss_distillation=loss2(sigmoid(output[:,:self.known_classes]),logits)\n",
        "          #print(\"loss_distillation :{}\".format(loss_distillation.item()))\n",
        "          loss=loss_classification+abs(loss_distillation)\n",
        "          loss.backward()\n",
        "        optimizer.step()\n",
        "        i+=1\n",
        "      torch.cuda.empty_cache()\n",
        "      print(f\"Loss: {loss.item()}\")\n",
        "      scheduler.step() \n",
        "    self.known_classes += len(new_classes)\n",
        "\n",
        "  def update_representation(self, dataset):             \n",
        "    self.combine_dataset_with_exemplars(dataset)\n",
        "    self.flag_mean = True\n",
        "    classes_to_idx = dataset.labels_to_int\n",
        "    new_classes = [cls for cls in classes_to_idx if cls not in self.list_known_classes] #gets indexes of new classes only\n",
        "\n",
        "    train_data_loader = DataLoader(\n",
        "        dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "    \n",
        "    preds_old_net = []\n",
        "    #preds_old_net = torch.zeros(len(dataset), self.num_classes).cuda()\n",
        "    \n",
        "    if self.known_classes > 0:\n",
        "      print(f\"calculating output old classes\")\n",
        "      self.eval()\n",
        "      logits_old_net = torch.zeros(len(dataset.data), self.known_classes).cuda()\n",
        "      with torch.no_grad():\n",
        "        for indices, images, labels in train_data_loader:\n",
        "          images = images.to(DEVICE)\n",
        "          g = self.forward(images)\n",
        "          sigmoid = torch.nn.Sigmoid()\n",
        "          logits_old_net[indices] = sigmoid(g)\n",
        "        # preds_old_net.append(g.data)\n",
        "        # preds_old_net[indices] = g.data\n",
        "      \n",
        "      # print(f\"Labels old net size: {preds_old_net.size()}\")\n",
        "      # print(f\"Labels old net: {preds_old_net}\")\n",
        "      # preds_old_net = preds_old_net.to(DEVICE)\n",
        "      # logits_old_net = torch.cat(logits_old_net)         \n",
        "      # print(logits_old_net.size())\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "    self.increment_classes(new_classes)\n",
        "    \n",
        "    optimizer = optim.SGD(self.parameters(), lr=2.0,weight_decay=0.00001, momentum = 0.9)\n",
        "    scheduler = MultiStepLR(optimizer,[47,63],gamma=GAMMA)\n",
        "    self.train()\n",
        "\n",
        "    eye = torch.eye(self.known_classes+len(new_classes))\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "      print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], LR: {scheduler.get_last_lr()}\")\n",
        "      i=0\n",
        "      for indices, images, labels in train_data_loader:\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "        indices = indices.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        output = self.forward(images)\n",
        "        # print(f\"Output size: {output.size()}\")\n",
        "        # print(f\"Labels size: {labels.size()}\")\n",
        "\n",
        "        if self.known_classes==0:\n",
        "          labels_one_hot_new_classes = []\n",
        "          for label in labels:\n",
        "            labels_one_hot_new_classes.append(eye[label])\n",
        "          labels_one_hot_new_classes = torch.stack(labels_one_hot_new_classes).cuda()\n",
        "          loss=self.loss(output,labels_one_hot_new_classes)\n",
        "          loss.backward()\n",
        "        if self.known_classes > 0:\n",
        "          labels_one_hot_new_classes = eye[:, self.known_classes:]\n",
        "          # print(labels_one_hot_new_classes.size())\n",
        "          labels_one_hot = []\n",
        "          for label in labels:\n",
        "            labels_one_hot.append(labels_one_hot_new_classes[label])\n",
        "          labels_one_hot = torch.stack(labels_one_hot).cuda()\n",
        "          logits = logits_old_net[indices].cuda()\n",
        "          # print(f\"logits old net: {logits.size()}\")\n",
        "          # print(f\"new classes onehot encoded: {labels_one_hot.size()}\")\n",
        "          #labels_concatenate = torch.zeros(logits_old_net.size()\n",
        "          # print(f\"{logits.size()}-{labels_one_hot.size()}\")\n",
        "          labels_concatenate=torch.cat((logits,labels_one_hot),dim=1)\n",
        "          loss=self.loss(output,labels_concatenate)\n",
        "          loss.backward()\n",
        "        optimizer.step()\n",
        "        i+=1\n",
        "      torch.cuda.empty_cache()\n",
        "      print(f\"Loss: {loss.item()}\")\n",
        "      scheduler.step() \n",
        "    self.known_classes += len(new_classes)\n",
        "\n",
        "  def classify(self, input_image_batch, transform):\n",
        "    # input_image_batch: batch of up to 10 shuffled classes that we use for training and validation\n",
        "    # transform: transformation to be applied to raw exemplar images\n",
        "    batch_size = input_image_batch.size(0)\n",
        "    self.eval()\n",
        "    with torch.no_grad():\n",
        "      if self.flag_mean:\n",
        "        print(f\"num exemplar sets: {len(self.exemplar_sets)}\")\n",
        "        exemplar_means = []\n",
        "        for exemplars in self.exemplar_sets:\n",
        "          features = []\n",
        "          for exemplar in exemplars:\n",
        "            feature = self.extractor(transform(exemplar).unsqueeze(0).cuda())\n",
        "            feature.data = feature.data / feature.data.norm()\n",
        "            features.append(feature)\n",
        "          features = torch.stack(features)\n",
        "          exemplar_mean = torch.mean(features, 0)\n",
        "          exemplar_means.append(exemplar_mean)\n",
        "        print(f\"Exemplar means len: {len(exemplar_means)}\")\n",
        "        self.exemplar_means = exemplar_means\n",
        "        self.flag_mean = False\n",
        "\n",
        "      mean = torch.stack(self.exemplar_means).squeeze(1)    # tensor of dimension: known_classes x features (64)\n",
        "      # print(mean.size())\n",
        "      features = self.extractor(input_image_batch)          # extracts the features of the batch\n",
        "      predictions = []\n",
        "      for n, feature in enumerate(features):\n",
        "        feature.data = feature.data / feature.data.norm()   # normalize and returns the distance of the nearest one\n",
        "      # Predict label by nearest exemplar mean\n",
        "        distances = torch.sum((feature - mean)**2, 1)\n",
        "        predictions.append(torch.argmin(distances, 0))\n",
        "      return predictions\n",
        "\n",
        "  def classify_without_mean(self,input_image_batch):\n",
        "    # input_image_batch: batch of up to 10 shuffled classes that we use for training and validation\n",
        "\n",
        "    self.eval()\n",
        "    with torch.no_grad():\n",
        "      # mean: tensor of dimensions known_classes x features (64)\n",
        "      mean = torch.stack(self.exemplar_means).squeeze(1)    \n",
        "\n",
        "      features = self.extractor(input_image_batch)          # extracts the features of the batch\n",
        "      predictions = []\n",
        "      for n, feature in enumerate(features):\n",
        "        feature.data = feature.data / feature.data.norm()   # normalize and returns the distance of the nearest one\n",
        "        # Predict label by nearest exemplar mean\n",
        "        distances = torch.sum((feature - mean)**2, 1)\n",
        "        predictions.append(torch.argmin(distances, 0))\n",
        "      return predictions\n",
        "\n",
        "  def construct_with_class_mean(self, images, exemplars_per_class, transform):\n",
        "    self.eval()\n",
        "    with torch.no_grad():\n",
        "      if self.flag_mean:\n",
        "        print(f\"num exemplar sets: {len(self.exemplar_sets)}\")\n",
        "        exemplar_means = []\n",
        "        for exemplars in self.exemplar_sets:\n",
        "          features = []\n",
        "          for exemplar in exemplars:\n",
        "            feature = self.extractor(transform(exemplar).unsqueeze(0).cuda())\n",
        "            feature.data = feature.data / feature.data.norm()\n",
        "            features.append(feature)\n",
        "          features = torch.stack(features)\n",
        "          exemplar_mean = torch.mean(features, 0)\n",
        "          exemplar_means.append(exemplar_mean)\n",
        "        print(f\"Exemplar means len: {len(exemplar_means)}\")\n",
        "        self.exemplar_means = exemplar_means\n",
        "        self.flag_mean = False\n",
        "  \n",
        "      images_features = []\n",
        "      exemplar_set = []\n",
        "      exemplar_features = []\n",
        "      for image in images:\n",
        "        image = transform(image[0]).to(DEVICE).unsqueeze(0)\n",
        "        feature = self.extractor(image)\n",
        "        feature.data = feature.data / feature.data.norm()\n",
        "        images_features.append(feature)\n",
        "      images_features = torch.stack(images_features, dim=0)\n",
        "      # should do the mean on the dimension of the append\n",
        "      class_mean = torch.mean(images_features, 0)\n",
        "      class_mean = class_mean / class_mean.norm()\n",
        "      # self.exemplar_means.append(class_mean)\n",
        "      for i in range(exemplars_per_class):                #gets the nearest image to the mean and returns it\n",
        "        mask = [True]*len(images)\n",
        "        total = np.sum(exemplar_features, axis=0)\n",
        "        extracted_features = images_features\n",
        "        mean = class_mean\n",
        "        average_feature_vector = (float(1)/(i+1))*(extracted_features + total).squeeze(1)\n",
        "        average_feature_vector = average_feature_vector / average_feature_vector.norm()\n",
        "        j = torch.argmin(torch.sqrt(\n",
        "            torch.sum(mean-average_feature_vector, 1)**2))\n",
        "        exemplar_set.append(images[j][0])\n",
        "        exemplar_features.append(extracted_features[j].squeeze(0))\n",
        "        mask[j] = False\n",
        "        images_features = images_features[mask]\n",
        "        images = np.array(images)[mask].tolist()\n",
        "      self.exemplar_sets.append(exemplar_set)\n",
        "      print(f\"Created exemplar set for class {images[0][1]} of len {len(self.exemplar_sets[0])}\")\n",
        "\n",
        "  def construct_exemplar_set(self, images, exemplars_per_class, transform):     # images: images of one class of the training set, exemplars_per_class is m, transform is the transformation\n",
        "    self.eval()\n",
        "    with torch.no_grad():\n",
        "      images_features = []\n",
        "      exemplar_set = []\n",
        "      exemplar_features = []\n",
        "      for image in images:\n",
        "        image = transform(image[0]).to(DEVICE).unsqueeze(0)\n",
        "        feature = self.extractor(image)\n",
        "        feature.data = feature.data / feature.data.norm()\n",
        "        images_features.append(feature)\n",
        "      images_features = torch.stack(images_features, dim=0)\n",
        "      # should do the mean on the dimension of the append\n",
        "      class_mean = torch.mean(images_features, 0)\n",
        "      class_mean = class_mean / class_mean.norm()         #computes the mean of the class and normalizes it, it creates the features of the average image\n",
        "      self.exemplar_means.append(class_mean)\n",
        "      for i in range(exemplars_per_class):                #gets the nearest image to the mean and returns it\n",
        "        mask = [True]*len(images)\n",
        "        total = np.sum(exemplar_features, axis=0)\n",
        "        extracted_features = images_features\n",
        "        mean = class_mean\n",
        "        average_feature_vector = (float(1)/(i+1))*(extracted_features + total).squeeze(1)\n",
        "        average_feature_vector = average_feature_vector / average_feature_vector.norm()\n",
        "        j = torch.argmin(torch.sqrt(\n",
        "            torch.sum(mean-average_feature_vector, 1)**2))\n",
        "        exemplar_set.append(images[j][0])\n",
        "        exemplar_features.append(extracted_features[j].squeeze(0))\n",
        "        mask[j] = False\n",
        "        images_features = images_features[mask]\n",
        "        images = np.array(images)[mask].tolist()\n",
        "      self.exemplar_sets.append(exemplar_set)\n",
        "      print(f\"Created exemplar set for class {images[0][1]} of len {len(self.exemplar_sets[0])}\")\n",
        "\n",
        "  def construct_exemplar_set_mean_images(self, images_per_label, num_exemplars, num_clusters, num_images_per_cluster, transform):\n",
        "    self.eval()\n",
        "    with torch.no_grad():\n",
        "      images_features = []\n",
        "      for image in images_per_label:\n",
        "        image = transform(image[0]).to(DEVICE).unsqueeze(0)\n",
        "        feature = self.extractor(image)\n",
        "        feature.data = feature.data / feature.data.norm()\n",
        "        images_features.append(feature)\n",
        "      images_features = torch.stack(images_features, dim=0)\n",
        "      # should do the mean on the dimension of the append\n",
        "      class_mean = torch.mean(images_features, 0)\n",
        "      class_mean = class_mean / class_mean.norm()\n",
        "      self.exemplar_means.append(class_mean)\n",
        "\n",
        "      device = torch.device('cuda:0')\n",
        "      # images_features = []\n",
        "      # self.extractor.to(DEVICE)\n",
        "      # for image in images_per_label:\n",
        "      #   image_features = self.extractor(transform(image[0]).unsqueeze(0).cuda())\n",
        "      #   image_features.data = image_features.data / image_features.data.norm()\n",
        "      #   images_features.append(image_features)\n",
        "      # # images_features: list of tensors 1x64\n",
        "      # images_features = torch.stack(images_features).squeeze(1)\n",
        "      # print(f\"Stacked images features: {images_features.size()}\")\n",
        "      # reduced_features = TSNE(n_components=2 , perplexity=15 , learning_rate=10).fit_transform(images_features.cpu())\n",
        "      # print(f\"reduced features size: {torch.tensor(reduced_features).size()}\")\n",
        "      # reduced_features= torch.tensor(reduced_features).cuda()\n",
        "      # clusters_indices_x size: len(images_per_label) x 1\n",
        "      # cluster_centers size: num_cluster x 2\n",
        "      clusters_indices_x, cluster_centers = kmeans(images_features.squeeze(1), num_clusters = num_clusters, distance = 'euclidean', device = device)\n",
        "\n",
        "      # class mean for NME classify, class_mean_classify size: 1x64\n",
        "      # class_mean_classify = torch.mean(images_features.unsqueeze(1), 0)\n",
        "      # print(f\"class mean size: {class_mean_classify.size()}\")\n",
        "      # class_mean_classify = class_mean_classify / class_mean_classify.norm()\n",
        "      # self.exemplar_means.append(class_mean_classify.cuda())\n",
        "\n",
        "      # class mean for clustering, class_mean size: 1x2 \n",
        "      # class_mean = torch.mean(images_features)\n",
        "      # class_mean.data = class_mean.data / class_mean.data.norm()\n",
        "\n",
        "      # centroid_distances size: num_clusters x 1\n",
        "      print(cluster_centers.size())\n",
        "      print(class_mean.size())\n",
        "      \n",
        "      centroid_distances = torch.sum((cluster_centers.cuda() - class_mean.cuda())**2, dim=1)\n",
        "      centroid_distances = centroid_distances / torch.sum(centroid_distances)\n",
        "      print(f\"Distances size: {centroid_distances.size()}\")\n",
        "\n",
        "      # fill clusters\n",
        "      clusters = []\n",
        "      for i in range(num_clusters):\n",
        "        cluster = [j for j, x in enumerate(clusters_indices_x) if x == i]\n",
        "        clusters.append(cluster)\n",
        "\n",
        "      images_mean = []\n",
        "      pil = transforms.ToPILImage()\n",
        "      for m in range(num_exemplars):\n",
        "        image_mean = np.zeros((32, 32, 3))\n",
        "        for i, cluster in enumerate(clusters): \n",
        "          # indices of cluster images to be used for image_mean\n",
        "          cluster_images = random.choices(cluster, k = min(len(cluster), num_images_per_cluster-1) )\n",
        "          for j in  cluster_images:\n",
        "            image = images_per_label[j][0]\n",
        "            image_mean += (1 - centroid_distances[i].item())*image\n",
        "        image_mean /= np.max(image_mean)\n",
        "        image_mean *= 255\n",
        "        image_mean = image_mean.astype(np.uint8)\n",
        "        # plt.imshow(pil(image_mean))\n",
        "        # plt.show()\n",
        "        images_mean.append(image_mean)\n",
        "      print(\"Matteo merda\")\n",
        "      self.exemplar_sets.append(images_mean)\n",
        "\n",
        "  def construct_exemplar_set_mean_images_no_clusters(self, images_per_label, num_exemplars, num_images_per_exemplar, transform):\n",
        "    self.eval()\n",
        "    with torch.no_grad():\n",
        "      images_features = []\n",
        "      for image in images_per_label:\n",
        "        image = transform(image[0]).to(DEVICE).unsqueeze(0)\n",
        "        feature = self.extractor(image)\n",
        "        feature.data = feature.data / feature.data.norm()\n",
        "        images_features.append(feature)\n",
        "      images_features = torch.stack(images_features, dim=0)\n",
        "      # should do the mean on the dimension of the append\n",
        "      class_mean = torch.mean(images_features, 0)\n",
        "      class_mean = class_mean / class_mean.norm()\n",
        "      self.exemplar_means.append(class_mean)\n",
        "      class_mean = class_mean.squeeze(1)\n",
        "      images_features = images_features.squeeze(1)\n",
        "      distances = torch.sum((class_mean - images_features)**2, 1)\n",
        "      distances /= torch.sum(distances)\n",
        "\n",
        "      pil = transforms.ToPILImage()\n",
        "      images_mean = []\n",
        "\n",
        "      for i in range(num_exemplars):                #gets the nearest image to the mean and returns it\n",
        "        j = random.choices(range(len(images_per_label)), k = num_images_per_exemplar)\n",
        "        image_mean = np.zeros((32,32,3))\n",
        "        image_mean += 0.8*images_per_label[j[0]][0]\n",
        "        for image in j[1:]:\n",
        "          image_mean += 0.2/(num_images_per_exemplar-1)*images_per_label[image][0]\n",
        "\n",
        "        if np.max(image_mean) > 255:\n",
        "          image_mean /= np.max(image_mean)\n",
        "          image_mean *= 255\n",
        "        image_mean = image_mean.astype(np.uint8)\n",
        "\n",
        "        images_per_label = [x for n, x in enumerate(images_per_label) if n != j[0]]\n",
        "        images_mean.append(image_mean)\n",
        "        # plt.imshow(pil(image_mean))\n",
        "        # plt.show()\n",
        "      self.exemplar_sets.append(images_mean)\n",
        "      print(\"Matteo merda\")\n",
        "      print(f\"Created exemplar set for class {images_per_label[0][1]} of len {len(self.exemplar_sets[0])}\")\n",
        "\n",
        "  def construct_examplar_set_mean_image_with_clusters(self, images_per_label, num_exemplars, num_clusters, num_images_per_cluster, transform, feature_extractor):\n",
        "    self.eval()\n",
        "    with torch.no_grad():\n",
        "  \n",
        "      images_features = []\n",
        "      exemplar_set = []\n",
        "      exemplar_features = []\n",
        "      for image in images_per_label:\n",
        "        image = transform(image[0]).to(DEVICE).unsqueeze(0)\n",
        "        feature = self.extractor(image)\n",
        "        feature.data = feature.data / feature.data.norm()\n",
        "        images_features.append(feature)\n",
        "      images_features = torch.stack(images_features, dim=0)\n",
        "      # should do the mean on the dimension of the append\n",
        "      class_mean = torch.mean(images_features, 0)\n",
        "      class_mean = class_mean / class_mean.norm()\n",
        "      self.exemplar_means.append(class_mean)\n",
        "\n",
        "      images_features_step_extractor = []\n",
        "      for image in images_per_label:\n",
        "        image = transform(image[0]).to(DEVICE).unsqueeze(0)\n",
        "        feature = feature_extractor(image)\n",
        "        feature.data = feature.data / feature.data.norm()\n",
        "        images_features_step_extractor.append(feature)\n",
        "      images_features_step_extractor = torch.stack(images_features_step_extractor, dim=0)\n",
        "      # should do the mean on the dimension of the append\n",
        "\n",
        "      device = torch.device('cuda:0')\n",
        "      clusters_indices_x, cluster_centers = kmeans(images_features_step_extractor.squeeze(1), num_clusters = num_clusters, distance = 'euclidean', device = device)\n",
        "      print(cluster_centers.size())\n",
        "      print(class_mean.size())\n",
        "      \n",
        "      centroid_distances = torch.sum((cluster_centers.cuda() - class_mean.cuda())**2, dim=1)\n",
        "      centroid_distances = centroid_distances / torch.sum(centroid_distances)\n",
        "      print(f\"Distances size: {centroid_distances.size()}\")\n",
        "\n",
        "      # fill clusters\n",
        "      clusters = []\n",
        "      cluster_distances=[]\n",
        "      for i in range(num_clusters):\n",
        "        cluster = [j for j, x in enumerate(clusters_indices_x) if x == i]\n",
        "        clusters.append(cluster)\n",
        "        distances_from_centroid=[]\n",
        "        for image_index in cluster:\n",
        "          distances_from_centroid.append((torch.sum((images_features_step_extractor[image_index][0].cuda()-cluster_centers[i].cuda())**2).cuda()))\n",
        "           \n",
        "        cluster_distances.append(distances_from_centroid)\n",
        "      images_mean = []\n",
        "      pil = transforms.ToPILImage()\n",
        "      images_mean = []\n",
        "      pil = transforms.ToPILImage()\n",
        "      for m in range(num_exemplars):\n",
        "        image_mean = np.zeros((32, 32, 3))\n",
        "        i=random.randint(0,len(clusters)-1)\n",
        "        while(len(cluster_distances[i])==0):\n",
        "          i=random.randint(0,len(clusters)-1)\n",
        "        index_nearest=np.argmin(cluster_distances[i])\n",
        "        #print(index_nearest)\n",
        "        #print(type(index_nearest))\n",
        "        if(type(index_nearest) is not np.int64):\n",
        "          index_nearest=index_nearest[0]\n",
        "        index_nearest_image=clusters[i][index_nearest]\n",
        "        cluster_distances[i]=[x for n,x in enumerate(cluster_distances[i]) if n!=index_nearest]\n",
        "        clusters[i]=[x for n,x in enumerate(clusters[i]) if n!=index_nearest]\n",
        "          # indices of cluster images to be used for image_mean\n",
        "        cluster_images = random.choices(cluster, k = min(len(cluster), num_images_per_cluster-1) )\n",
        "        image_mean+=0.8*images_per_label[index_nearest_image][0]\n",
        "        for j in  cluster_images:\n",
        "          image = images_per_label[j][0]\n",
        "          image_mean += 0.2/len(cluster_images)*image\n",
        "        if(np.max(image_mean)>255):\n",
        "          image_mean /= np.max(image_mean)\n",
        "          image_mean *= 255\n",
        "        image_mean = image_mean.astype(np.uint8)\n",
        "        # pil=transforms.ToPILImage()\n",
        "        # if(m%20==0):\n",
        "        #   plt.imshow(pil(image_mean))\n",
        "        #   plt.show()\n",
        "        images_mean.append(image_mean)\n",
        "      print(\"Matteo merda\")\n",
        "      self.exemplar_sets.append(images_mean)\n",
        "\n",
        "  def construct_examplar_set_random(self, images, exemplars_per_class, transform):\n",
        "    self.eval()\n",
        "    with torch.no_grad():\n",
        "  \n",
        "      images_features = []\n",
        "      exemplar_set = []\n",
        "      exemplar_features = []\n",
        "      for image in images:\n",
        "        image = transform(image[0]).to(DEVICE).unsqueeze(0)\n",
        "        feature = self.extractor(image)\n",
        "        feature.data = feature.data / feature.data.norm()\n",
        "        images_features.append(feature)\n",
        "      images_features = torch.stack(images_features, dim=0)\n",
        "      # should do the mean on the dimension of the append\n",
        "      class_mean = torch.mean(images_features, 0)\n",
        "      class_mean = class_mean / class_mean.norm()\n",
        "      self.exemplar_means.append(class_mean)\n",
        "      for i in range(exemplars_per_class):                #gets the nearest image to the mean and returns it\n",
        "        mask = [True]*len(images)\n",
        "        j = random.choice(range(len(images)))\n",
        "        exemplar_set.append(images[j][0])\n",
        "        mask[j] = False\n",
        "        images_features = images_features[mask]\n",
        "        images = np.array(images)[mask].tolist()\n",
        "      self.exemplar_sets.append(exemplar_set)\n",
        "      print(f\"Created exemplar set for class {images[0][1]} of len {len(self.exemplar_sets[0])}\")\n",
        "\n",
        "  def compute_means(self,transform):\n",
        "    self.eval()\n",
        "    with torch.no_grad():\n",
        "      print(f\"num exemplar sets: {len(self.exemplar_sets)}\")\n",
        "      exemplar_means = []\n",
        "      for exemplars in self.exemplar_sets:\n",
        "        features = []\n",
        "        for exemplar in exemplars:\n",
        "          feature = self.extractor(transform(exemplar).unsqueeze(0).cuda())\n",
        "          feature.data = feature.data / feature.data.norm()\n",
        "          features.append(feature)\n",
        "        features = torch.stack(features)\n",
        "        exemplar_mean = torch.mean(features, 0)\n",
        "        exemplar_means.append(exemplar_mean)\n",
        "      print(f\"Exemplar means len: {len(exemplar_means)}\")\n",
        "      self.exemplar_means = exemplar_means\n",
        "      self.flag_mean = False\n",
        "\n",
        "  def combine_dataset_with_exemplars(self, dataset):    #combines them\n",
        "    list_exemplars = []\n",
        "    for label, exemplars in enumerate(self.exemplar_sets):\n",
        "      list_exemplars += [(image, label) for image in exemplars]\n",
        "      dataset.labels_to_int.append(label)\n",
        "    dataset.data = list_exemplars + dataset.data\n",
        "\n",
        "  def increment_classes(self, classes_to_add):          # increments the number of classes we are using\n",
        "    n_classes_to_add = len(classes_to_add)\n",
        "    self.list_known_classes+=classes_to_add             #add the new classes\n",
        "    print(f\"Known classes {self.list_known_classes}\")\n",
        "    #weight = self.fully_connected[4].weight.data\n",
        "    weight = self.fully_connected.weight.data\n",
        "    #feature_size = self.fully_connected[4].in_features\n",
        "    feature_size = self.fully_connected.in_features\n",
        "    #old_num_classes = self.fully_connected[4].out_features\n",
        "    old_num_classes = self.fully_connected.out_features\n",
        "    #self.fully_connected[4] = nn.Linear(\n",
        "    #    feature_size, old_num_classes+n_classes_to_add, bias = True)\n",
        "    #self.fully_connected[4].weight.data[:old_num_classes] = weight\n",
        "    self.fully_connected = nn.Linear(\n",
        "        feature_size, old_num_classes+n_classes_to_add, bias = True)\n",
        "    self.fully_connected.weight.data[:old_num_classes] = weight\n",
        "\n",
        "  def reduce_exemplar_sets(self, m):                    # reduces exemplar set\n",
        "    for i in range(len(self.exemplar_sets)):\n",
        "      self.exemplar_sets[i] = self.exemplar_sets[i][:m]\n",
        "      print(f\"Reducing exemplars of class {i} to {len(self.exemplar_sets[i])}\")\n",
        "\n",
        "  def classifierMlp(self,images):\n",
        "    self.eval()\n",
        "    self.fully_connected.to(DEVICE)\n",
        "    self.extractor.to(DEVICE)\n",
        "    outputs=self.fully_connected(self.extractor(images))\n",
        "    _,preds=torch.max(outputs.data,1)\n",
        "    return preds\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSgcVoIhsEvq",
        "colab_type": "text"
      },
      "source": [
        "**Training with mean images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FO0TGrGuQKss",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bc01f943-87bf-451a-c902-8264c48e8d81"
      },
      "source": [
        "class featureExtractor(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(featureExtractor, self).__init__()\n",
        "    self.extractor = resnet32()\n",
        "    self.fully_connected = nn.Linear(self.extractor.out_dim, 10, bias=True)\n",
        "    torch.nn.init.xavier_uniform_(self.fully_connected.weight)\n",
        "    self.fully_connected.bias.data.fill_(0.01)\n",
        "    self.loss=nn.BCEWithLogitsLoss()\n",
        "\n",
        "  def forward(self, x):\n",
        "    self.extractor.to(DEVICE)\n",
        "    self.fully_connected.to(DEVICE)\n",
        "\n",
        "    x = self.extractor(x)\n",
        "    x = self.fully_connected(x)\n",
        "    \n",
        "    return x\n",
        "\n",
        "  def train(self, dataset):\n",
        "    classes_to_idx = dataset.labels_to_int\n",
        "    offset = min(classes_to_idx)\n",
        "    train_data_loader = DataLoader(\n",
        "        dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "    \n",
        "    optimizer = optim.SGD(self.parameters(), lr=2.0,weight_decay=0.00001, momentum = 0.9)\n",
        "    scheduler = MultiStepLR(optimizer,[47,63],gamma=GAMMA)\n",
        "\n",
        "    N_CLASSES = 10\n",
        "    eye = torch.eye(N_CLASSES)\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "      print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], LR: {scheduler.get_last_lr()}\")\n",
        "      i=0\n",
        "      for indices, images, labels in train_data_loader:\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "        indices = indices.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        labels_one_hot_new_classes = []\n",
        "        for label in labels:\n",
        "          labels_one_hot_new_classes.append(eye[label-offset])\n",
        "        labels_one_hot_new_classes = torch.stack(labels_one_hot_new_classes).cuda()\n",
        "        output = self.forward(images)\n",
        "        loss=self.loss(output,labels_one_hot_new_classes)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        i+=1\n",
        "      print(f\"Loss step extractor: {loss.item()}\")\n",
        "      torch.cuda.empty_cache()\n",
        "      scheduler.step() \n",
        "\n",
        "net=iCarlNet(n_classes=100)\n",
        "net.to(DEVICE)\n",
        "accuracies = []\n",
        "for i, train_dataset in enumerate(train_datasets):\n",
        "  torch.cuda.empty_cache()\n",
        "  print(f\"BATCH [{i}]\")\n",
        "  print(f\"Training on {train_dataset.labels} -> {train_dataset.labels_to_int}\")\n",
        "  net.train()\n",
        "  # net.batch_trainer(copy.deepcopy(train_dataset))\n",
        "  # extractor = featureExtractor()\n",
        "  # extractor.train(copy.deepcopy(train_dataset))\n",
        "  net.update_representation(copy.deepcopy(train_dataset))\n",
        "  # net.update_representation_using_cross_entropy_and_kl(copy.deepcopy(train_dataset))\n",
        "\n",
        "  m = int(K/((i+1)*10))\n",
        "  net.compute_means(train_dataset.transform)\n",
        "  net.reduce_exemplar_sets(m)\n",
        "  for data_per_label in train_dataset.data_per_label:\n",
        "    print(f\"Constructing exemplar for class [{data_per_label[0][1]}]\")\n",
        "    #net.construct_exemplar_set(data_per_label,m,train_dataset.transform)\n",
        "    #net.construct_exemplar_set_with_class_mean(data_per_label,m,train_dataset.transform)\n",
        "    # net.construct_exemplar_set_mean_images(data_per_label, m , 5, 8, train_dataset.transform)\n",
        "    # net.construct_exemplar_set_mean_images_no_clusters(data_per_label, m , 6, train_dataset.transform)\n",
        "    net.construct_examplar_set_mean_image_with_clusters(data_per_label, m , 10, 30, train_dataset.transform, copy.deepcopy(net.extractor))\n",
        "    #net.construct_exemplar_set_with_centroids(data_per_label,m,train_dataset.transform)\n",
        "    # net.construct_examplar_set_random(data_per_label,m,train_dataset.transform)\n",
        "  \n",
        "  #net.compute_exemplar_list_knn(train_dataset.transform)\n",
        "  net.eval()\n",
        "  corrects = 0\n",
        "  total = 0\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    for num in range(i+1):\n",
        "      print(f\"Validating classes {test_datasets[num].labels} -> {test_datasets[num].labels_to_int}\")\n",
        "      test_dataloader = DataLoader(test_datasets[num], batch_size=BATCH_SIZE, num_workers=4, shuffle = True)\n",
        "      for _, images, labels in test_dataloader:\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "        # classify using NME\n",
        "        #preds = torch.stack(net.KNN_classify(images,35)).cuda()\n",
        "        #preds=torch.stack(net.classify_without_mean_cosine_similarity(images)).cuda()\n",
        "        preds = torch.stack(net.classify_without_mean(images)).cuda()\n",
        "        #preds=net.classifierMlp(images)\n",
        "        # Update Corrects\n",
        "        #outputs = net(images)\n",
        "        #_, preds = torch.max(outputs.data, 1)\n",
        "        corrects += torch.sum(preds == labels.data).data.item()\n",
        "        total += len(images)\n",
        "    torch.cuda.empty_cache()\n",
        "    # Calculate Accuracy\n",
        "    accuracy = corrects / float(total)\n",
        "    accuracies.append(accuracy)\n",
        "    print(f\"Accuracy: {accuracy}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BATCH [0]\n",
            "Training on ['palm_tree', 'bottle', 'man', 'mushroom', 'snail', 'tiger', 'beaver', 'skyscraper', 'wardrobe', 'train'] -> [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "Known classes [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "Epoch [1/70], LR: [2.0]\n",
            "Loss: 0.31328269839286804\n",
            "Epoch [2/70], LR: [2.0]\n",
            "Loss: 0.33147579431533813\n",
            "Epoch [3/70], LR: [2.0]\n",
            "Loss: 0.31944331526756287\n",
            "Epoch [4/70], LR: [2.0]\n",
            "Loss: 0.30695781111717224\n",
            "Epoch [5/70], LR: [2.0]\n",
            "Loss: 0.33906397223472595\n",
            "Epoch [6/70], LR: [2.0]\n",
            "Loss: 0.29149118065834045\n",
            "Epoch [7/70], LR: [2.0]\n",
            "Loss: 0.29746589064598083\n",
            "Epoch [8/70], LR: [2.0]\n",
            "Loss: 0.2880215048789978\n",
            "Epoch [9/70], LR: [2.0]\n",
            "Loss: 0.34880611300468445\n",
            "Epoch [10/70], LR: [2.0]\n",
            "Loss: 0.3041495382785797\n",
            "Epoch [11/70], LR: [2.0]\n",
            "Loss: 0.2621713876724243\n",
            "Epoch [12/70], LR: [2.0]\n",
            "Loss: 0.31541168689727783\n",
            "Epoch [13/70], LR: [2.0]\n",
            "Loss: 0.2630032002925873\n",
            "Epoch [14/70], LR: [2.0]\n",
            "Loss: 0.29647096991539\n",
            "Epoch [15/70], LR: [2.0]\n",
            "Loss: 0.3561781346797943\n",
            "Epoch [16/70], LR: [2.0]\n",
            "Loss: 0.32319653034210205\n",
            "Epoch [17/70], LR: [2.0]\n",
            "Loss: 0.3268580734729767\n",
            "Epoch [18/70], LR: [2.0]\n",
            "Loss: 0.1792631596326828\n",
            "Epoch [19/70], LR: [2.0]\n",
            "Loss: 0.23690259456634521\n",
            "Epoch [20/70], LR: [2.0]\n",
            "Loss: 0.3838838040828705\n",
            "Epoch [21/70], LR: [2.0]\n",
            "Loss: 0.3243652880191803\n",
            "Epoch [22/70], LR: [2.0]\n",
            "Loss: 0.27961134910583496\n",
            "Epoch [23/70], LR: [2.0]\n",
            "Loss: 0.16002319753170013\n",
            "Epoch [24/70], LR: [2.0]\n",
            "Loss: 0.2351212501525879\n",
            "Epoch [25/70], LR: [2.0]\n",
            "Loss: 0.16667912900447845\n",
            "Epoch [26/70], LR: [2.0]\n",
            "Loss: 0.18848954141139984\n",
            "Epoch [27/70], LR: [2.0]\n",
            "Loss: 0.3111023008823395\n",
            "Epoch [28/70], LR: [2.0]\n",
            "Loss: 0.1965973824262619\n",
            "Epoch [29/70], LR: [2.0]\n",
            "Loss: 0.07714598625898361\n",
            "Epoch [30/70], LR: [2.0]\n",
            "Loss: 0.17747224867343903\n",
            "Epoch [31/70], LR: [2.0]\n",
            "Loss: 0.21799595654010773\n",
            "Epoch [32/70], LR: [2.0]\n",
            "Loss: 0.2514086365699768\n",
            "Epoch [33/70], LR: [2.0]\n",
            "Loss: 0.17084228992462158\n",
            "Epoch [34/70], LR: [2.0]\n",
            "Loss: 0.13829448819160461\n",
            "Epoch [35/70], LR: [2.0]\n",
            "Loss: 0.2500859200954437\n",
            "Epoch [36/70], LR: [2.0]\n",
            "Loss: 0.2612662613391876\n",
            "Epoch [37/70], LR: [2.0]\n",
            "Loss: 0.25574740767478943\n",
            "Epoch [38/70], LR: [2.0]\n",
            "Loss: 0.21580560505390167\n",
            "Epoch [39/70], LR: [2.0]\n",
            "Loss: 0.23415875434875488\n",
            "Epoch [40/70], LR: [2.0]\n",
            "Loss: 0.372826486825943\n",
            "Epoch [41/70], LR: [2.0]\n",
            "Loss: 0.13966964185237885\n",
            "Epoch [42/70], LR: [2.0]\n",
            "Loss: 0.19254706799983978\n",
            "Epoch [43/70], LR: [2.0]\n",
            "Loss: 0.054125260561704636\n",
            "Epoch [44/70], LR: [2.0]\n",
            "Loss: 0.17794406414031982\n",
            "Epoch [45/70], LR: [2.0]\n",
            "Loss: 0.13592863082885742\n",
            "Epoch [46/70], LR: [2.0]\n",
            "Loss: 0.12221743166446686\n",
            "Epoch [47/70], LR: [2.0]\n",
            "Loss: 0.08773278445005417\n",
            "Epoch [48/70], LR: [0.4]\n",
            "Loss: 0.13527558743953705\n",
            "Epoch [49/70], LR: [0.4]\n",
            "Loss: 0.28724274039268494\n",
            "Epoch [50/70], LR: [0.4]\n",
            "Loss: 0.05650411918759346\n",
            "Epoch [51/70], LR: [0.4]\n",
            "Loss: 0.09420986473560333\n",
            "Epoch [52/70], LR: [0.4]\n",
            "Loss: 0.18400835990905762\n",
            "Epoch [53/70], LR: [0.4]\n",
            "Loss: 0.2553500235080719\n",
            "Epoch [54/70], LR: [0.4]\n",
            "Loss: 0.15042619407176971\n",
            "Epoch [55/70], LR: [0.4]\n",
            "Loss: 0.05236377939581871\n",
            "Epoch [56/70], LR: [0.4]\n",
            "Loss: 0.23449400067329407\n",
            "Epoch [57/70], LR: [0.4]\n",
            "Loss: 0.1422223299741745\n",
            "Epoch [58/70], LR: [0.4]\n",
            "Loss: 0.05926311016082764\n",
            "Epoch [59/70], LR: [0.4]\n",
            "Loss: 0.03797590360045433\n",
            "Epoch [60/70], LR: [0.4]\n",
            "Loss: 0.11328598111867905\n",
            "Epoch [61/70], LR: [0.4]\n",
            "Loss: 0.31825515627861023\n",
            "Epoch [62/70], LR: [0.4]\n",
            "Loss: 0.1168440505862236\n",
            "Epoch [63/70], LR: [0.4]\n",
            "Loss: 0.12172459810972214\n",
            "Epoch [64/70], LR: [0.08000000000000002]\n",
            "Loss: 0.07131145149469376\n",
            "Epoch [65/70], LR: [0.08000000000000002]\n",
            "Loss: 0.051194943487644196\n",
            "Epoch [66/70], LR: [0.08000000000000002]\n",
            "Loss: 0.17755727469921112\n",
            "Epoch [67/70], LR: [0.08000000000000002]\n",
            "Loss: 0.09548144042491913\n",
            "Epoch [68/70], LR: [0.08000000000000002]\n",
            "Loss: 0.10941731184720993\n",
            "Epoch [69/70], LR: [0.08000000000000002]\n",
            "Loss: 0.01855466328561306\n",
            "Epoch [70/70], LR: [0.08000000000000002]\n",
            "Loss: 0.1703859269618988\n",
            "num exemplar sets: 0\n",
            "Exemplar means len: 0\n",
            "Constructing exemplar for class [0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 29it [00:00, 267.09it/s, center_shift=0.000048, iteration=29, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Matteo merda\n",
            "Constructing exemplar for class [1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 10it [00:00, 275.44it/s, center_shift=0.000008, iteration=10, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Matteo merda\n",
            "Constructing exemplar for class [2]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 22it [00:00, 281.80it/s, center_shift=0.000000, iteration=22, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Matteo merda\n",
            "Constructing exemplar for class [3]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 14it [00:00, 264.54it/s, center_shift=0.000091, iteration=14, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Matteo merda\n",
            "Constructing exemplar for class [4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 20it [00:00, 269.86it/s, center_shift=0.000072, iteration=20, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Matteo merda\n",
            "Constructing exemplar for class [5]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 12it [00:00, 269.43it/s, center_shift=0.000000, iteration=12, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Matteo merda\n",
            "Constructing exemplar for class [6]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 15it [00:00, 260.61it/s, center_shift=0.000039, iteration=15, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Matteo merda\n",
            "Constructing exemplar for class [7]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 16it [00:00, 289.24it/s, center_shift=0.000000, iteration=16, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Matteo merda\n",
            "Constructing exemplar for class [8]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 11it [00:00, 299.87it/s, center_shift=0.000034, iteration=11, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Matteo merda\n",
            "Constructing exemplar for class [9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 20it [00:00, 278.21it/s, center_shift=0.000000, iteration=20, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Matteo merda\n",
            "Validating classes ['palm_tree', 'bottle', 'man', 'mushroom', 'snail', 'tiger', 'beaver', 'skyscraper', 'wardrobe', 'train'] -> [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "Accuracy: 0.855\n",
            "BATCH [1]\n",
            "Training on ['bicycle', 'plain', 'couch', 'lobster', 'lion', 'chair', 'tulip', 'television', 'skunk', 'girl'] -> [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
            "calculating output old classes\n",
            "Known classes [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
            "Epoch [1/70], LR: [2.0]\n",
            "Loss: 0.18485446274280548\n",
            "Epoch [2/70], LR: [2.0]\n",
            "Loss: 0.1467989981174469\n",
            "Epoch [3/70], LR: [2.0]\n",
            "Loss: 0.13889482617378235\n",
            "Epoch [4/70], LR: [2.0]\n",
            "Loss: 0.13170014321804047\n",
            "Epoch [5/70], LR: [2.0]\n",
            "Loss: 0.14028464257717133\n",
            "Epoch [6/70], LR: [2.0]\n",
            "Loss: 0.12597499787807465\n",
            "Epoch [7/70], LR: [2.0]\n",
            "Loss: 0.13768528401851654\n",
            "Epoch [8/70], LR: [2.0]\n",
            "Loss: 0.12035088241100311\n",
            "Epoch [9/70], LR: [2.0]\n",
            "Loss: 0.11415344476699829\n",
            "Epoch [10/70], LR: [2.0]\n",
            "Loss: 0.1223205104470253\n",
            "Epoch [11/70], LR: [2.0]\n",
            "Loss: 0.13895131647586823\n",
            "Epoch [12/70], LR: [2.0]\n",
            "Loss: 0.12120534479618073\n",
            "Epoch [13/70], LR: [2.0]\n",
            "Loss: 0.11364691704511642\n",
            "Epoch [14/70], LR: [2.0]\n",
            "Loss: 0.10434094071388245\n",
            "Epoch [15/70], LR: [2.0]\n",
            "Loss: 0.10634808987379074\n",
            "Epoch [16/70], LR: [2.0]\n",
            "Loss: 0.11455308645963669\n",
            "Epoch [17/70], LR: [2.0]\n",
            "Loss: 0.10563817620277405\n",
            "Epoch [18/70], LR: [2.0]\n",
            "Loss: 0.11081988364458084\n",
            "Epoch [19/70], LR: [2.0]\n",
            "Loss: 0.10876002907752991\n",
            "Epoch [20/70], LR: [2.0]\n",
            "Loss: 0.11186995357275009\n",
            "Epoch [21/70], LR: [2.0]\n",
            "Loss: 0.11194436997175217\n",
            "Epoch [22/70], LR: [2.0]\n",
            "Loss: 0.1080552414059639\n",
            "Epoch [23/70], LR: [2.0]\n",
            "Loss: 0.11234135180711746\n",
            "Epoch [24/70], LR: [2.0]\n",
            "Loss: 0.11475484818220139\n",
            "Epoch [25/70], LR: [2.0]\n",
            "Loss: 0.10655615478754044\n",
            "Epoch [26/70], LR: [2.0]\n",
            "Loss: 0.09732594341039658\n",
            "Epoch [27/70], LR: [2.0]\n",
            "Loss: 0.10330148041248322\n",
            "Epoch [28/70], LR: [2.0]\n",
            "Loss: 0.09549307078123093\n",
            "Epoch [29/70], LR: [2.0]\n",
            "Loss: 0.10144852101802826\n",
            "Epoch [30/70], LR: [2.0]\n",
            "Loss: 0.08438281714916229\n",
            "Epoch [31/70], LR: [2.0]\n",
            "Loss: 0.10518040508031845\n",
            "Epoch [32/70], LR: [2.0]\n",
            "Loss: 0.09595545381307602\n",
            "Epoch [33/70], LR: [2.0]\n",
            "Loss: 0.10249928385019302\n",
            "Epoch [34/70], LR: [2.0]\n",
            "Loss: 0.10163838416337967\n",
            "Epoch [35/70], LR: [2.0]\n",
            "Loss: 0.09702025353908539\n",
            "Epoch [36/70], LR: [2.0]\n",
            "Loss: 0.10871297121047974\n",
            "Epoch [37/70], LR: [2.0]\n",
            "Loss: 0.0989784225821495\n",
            "Epoch [38/70], LR: [2.0]\n",
            "Loss: 0.1161867305636406\n",
            "Epoch [39/70], LR: [2.0]\n",
            "Loss: 0.09398285299539566\n",
            "Epoch [40/70], LR: [2.0]\n",
            "Loss: 0.10398098081350327\n",
            "Epoch [41/70], LR: [2.0]\n",
            "Loss: 0.07933808118104935\n",
            "Epoch [42/70], LR: [2.0]\n",
            "Loss: 0.09477724134922028\n",
            "Epoch [43/70], LR: [2.0]\n",
            "Loss: 0.11021286249160767\n",
            "Epoch [44/70], LR: [2.0]\n",
            "Loss: 0.09110304713249207\n",
            "Epoch [45/70], LR: [2.0]\n",
            "Loss: 0.08993890881538391\n",
            "Epoch [46/70], LR: [2.0]\n",
            "Loss: 0.10236053168773651\n",
            "Epoch [47/70], LR: [2.0]\n",
            "Loss: 0.08778183162212372\n",
            "Epoch [48/70], LR: [0.4]\n",
            "Loss: 0.0784018412232399\n",
            "Epoch [49/70], LR: [0.4]\n",
            "Loss: 0.0781140848994255\n",
            "Epoch [50/70], LR: [0.4]\n",
            "Loss: 0.06785072386264801\n",
            "Epoch [51/70], LR: [0.4]\n",
            "Loss: 0.08530332893133163\n",
            "Epoch [52/70], LR: [0.4]\n",
            "Loss: 0.07268346101045609\n",
            "Epoch [53/70], LR: [0.4]\n",
            "Loss: 0.0838746577501297\n",
            "Epoch [54/70], LR: [0.4]\n",
            "Loss: 0.07726700603961945\n",
            "Epoch [55/70], LR: [0.4]\n",
            "Loss: 0.08573473244905472\n",
            "Epoch [56/70], LR: [0.4]\n",
            "Loss: 0.074203260242939\n",
            "Epoch [57/70], LR: [0.4]\n",
            "Loss: 0.07346402853727341\n",
            "Epoch [58/70], LR: [0.4]\n",
            "Loss: 0.0738164409995079\n",
            "Epoch [59/70], LR: [0.4]\n",
            "Loss: 0.0729910209774971\n",
            "Epoch [60/70], LR: [0.4]\n",
            "Loss: 0.07223924249410629\n",
            "Epoch [61/70], LR: [0.4]\n",
            "Loss: 0.07009892910718918\n",
            "Epoch [62/70], LR: [0.4]\n",
            "Loss: 0.06683578342199326\n",
            "Epoch [63/70], LR: [0.4]\n",
            "Loss: 0.0737161710858345\n",
            "Epoch [64/70], LR: [0.08000000000000002]\n",
            "Loss: 0.07872607558965683\n",
            "Epoch [65/70], LR: [0.08000000000000002]\n",
            "Loss: 0.06935654580593109\n",
            "Epoch [66/70], LR: [0.08000000000000002]\n",
            "Loss: 0.07324446737766266\n",
            "Epoch [67/70], LR: [0.08000000000000002]\n",
            "Loss: 0.07027368992567062\n",
            "Epoch [68/70], LR: [0.08000000000000002]\n",
            "Loss: 0.06883657723665237\n",
            "Epoch [69/70], LR: [0.08000000000000002]\n",
            "Loss: 0.07793805748224258\n",
            "Epoch [70/70], LR: [0.08000000000000002]\n",
            "Loss: 0.0688900500535965\n",
            "num exemplar sets: 10\n",
            "Exemplar means len: 10\n",
            "Reducing exemplars of class 0 to 100\n",
            "Reducing exemplars of class 1 to 100\n",
            "Reducing exemplars of class 2 to 100\n",
            "Reducing exemplars of class 3 to 100\n",
            "Reducing exemplars of class 4 to 100\n",
            "Reducing exemplars of class 5 to 100\n",
            "Reducing exemplars of class 6 to 100\n",
            "Reducing exemplars of class 7 to 100\n",
            "Reducing exemplars of class 8 to 100\n",
            "Reducing exemplars of class 9 to 100\n",
            "Constructing exemplar for class [10]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 23it [00:00, 269.79it/s, center_shift=0.000000, iteration=23, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Matteo merda\n",
            "Constructing exemplar for class [11]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 15it [00:00, 290.38it/s, center_shift=0.000000, iteration=15, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Matteo merda\n",
            "Constructing exemplar for class [12]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 9it [00:00, 321.61it/s, center_shift=0.000082, iteration=9, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Matteo merda\n",
            "Constructing exemplar for class [13]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 10it [00:00, 322.42it/s, center_shift=0.000000, iteration=10, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Matteo merda\n",
            "Constructing exemplar for class [14]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 12it [00:00, 269.89it/s, center_shift=0.000053, iteration=12, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Matteo merda\n",
            "Constructing exemplar for class [15]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 15it [00:00, 287.42it/s, center_shift=0.000027, iteration=15, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Matteo merda\n",
            "Constructing exemplar for class [16]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 17it [00:00, 317.28it/s, center_shift=0.000000, iteration=17, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Matteo merda\n",
            "Constructing exemplar for class [17]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 13it [00:00, 295.04it/s, center_shift=0.000020, iteration=13, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Matteo merda\n",
            "Constructing exemplar for class [18]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 12it [00:00, 279.53it/s, center_shift=0.000052, iteration=12, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Matteo merda\n",
            "Constructing exemplar for class [19]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 14it [00:00, 266.64it/s, center_shift=0.000097, iteration=14, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Matteo merda\n",
            "Validating classes ['palm_tree', 'bottle', 'man', 'mushroom', 'snail', 'tiger', 'beaver', 'skyscraper', 'wardrobe', 'train'] -> [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "Validating classes ['bicycle', 'plain', 'couch', 'lobster', 'lion', 'chair', 'tulip', 'television', 'skunk', 'girl'] -> [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
            "Accuracy: 0.8015\n",
            "BATCH [2]\n",
            "Training on ['bowl', 'tank', 'lawn_mower', 'snake', 'ray', 'oak_tree', 'poppy', 'castle', 'telephone', 'clock'] -> [20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
            "calculating output old classes\n",
            "Known classes [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
            "Epoch [1/70], LR: [2.0]\n",
            "Loss: 0.12151625007390976\n",
            "Epoch [2/70], LR: [2.0]\n",
            "Loss: 0.14296215772628784\n",
            "Epoch [3/70], LR: [2.0]\n",
            "Loss: 0.11955651640892029\n",
            "Epoch [4/70], LR: [2.0]\n",
            "Loss: 0.12909506261348724\n",
            "Epoch [5/70], LR: [2.0]\n",
            "Loss: 0.10627537965774536\n",
            "Epoch [6/70], LR: [2.0]\n",
            "Loss: 0.11907169967889786\n",
            "Epoch [7/70], LR: [2.0]\n",
            "Loss: 0.10896347463130951\n",
            "Epoch [8/70], LR: [2.0]\n",
            "Loss: 0.10571790486574173\n",
            "Epoch [9/70], LR: [2.0]\n",
            "Loss: 0.1092405840754509\n",
            "Epoch [10/70], LR: [2.0]\n",
            "Loss: 0.10644464939832687\n",
            "Epoch [11/70], LR: [2.0]\n",
            "Loss: 0.10114461183547974\n",
            "Epoch [12/70], LR: [2.0]\n",
            "Loss: 0.10042275488376617\n",
            "Epoch [13/70], LR: [2.0]\n",
            "Loss: 0.09712360799312592\n",
            "Epoch [14/70], LR: [2.0]\n",
            "Loss: 0.10560352355241776\n",
            "Epoch [15/70], LR: [2.0]\n",
            "Loss: 0.10096162557601929\n",
            "Epoch [16/70], LR: [2.0]\n",
            "Loss: 0.10112450271844864\n",
            "Epoch [17/70], LR: [2.0]\n",
            "Loss: 0.10023939609527588\n",
            "Epoch [18/70], LR: [2.0]\n",
            "Loss: 0.10652504861354828\n",
            "Epoch [19/70], LR: [2.0]\n",
            "Loss: 0.09014318138360977\n",
            "Epoch [20/70], LR: [2.0]\n",
            "Loss: 0.09348329156637192\n",
            "Epoch [21/70], LR: [2.0]\n",
            "Loss: 0.094964899122715\n",
            "Epoch [22/70], LR: [2.0]\n",
            "Loss: 0.09069493412971497\n",
            "Epoch [23/70], LR: [2.0]\n",
            "Loss: 0.10341659188270569\n",
            "Epoch [24/70], LR: [2.0]\n",
            "Loss: 0.10119566321372986\n",
            "Epoch [25/70], LR: [2.0]\n",
            "Loss: 0.09463366121053696\n",
            "Epoch [26/70], LR: [2.0]\n",
            "Loss: 0.09138977527618408\n",
            "Epoch [27/70], LR: [2.0]\n",
            "Loss: 0.09498719871044159\n",
            "Epoch [28/70], LR: [2.0]\n",
            "Loss: 0.09618671983480453\n",
            "Epoch [29/70], LR: [2.0]\n",
            "Loss: 0.0878646969795227\n",
            "Epoch [30/70], LR: [2.0]\n",
            "Loss: 0.09244684129953384\n",
            "Epoch [31/70], LR: [2.0]\n",
            "Loss: 0.09454842656850815\n",
            "Epoch [32/70], LR: [2.0]\n",
            "Loss: 0.09229230135679245\n",
            "Epoch [33/70], LR: [2.0]\n",
            "Loss: 0.1003405898809433\n",
            "Epoch [34/70], LR: [2.0]\n",
            "Loss: 0.09191031754016876\n",
            "Epoch [35/70], LR: [2.0]\n",
            "Loss: 0.10491541028022766\n",
            "Epoch [36/70], LR: [2.0]\n",
            "Loss: 0.09987674653530121\n",
            "Epoch [37/70], LR: [2.0]\n",
            "Loss: 0.09008900821208954\n",
            "Epoch [38/70], LR: [2.0]\n",
            "Loss: 0.09220140427350998\n",
            "Epoch [39/70], LR: [2.0]\n",
            "Loss: 0.08707095682621002\n",
            "Epoch [40/70], LR: [2.0]\n",
            "Loss: 0.09929252415895462\n",
            "Epoch [41/70], LR: [2.0]\n",
            "Loss: 0.08357599377632141\n",
            "Epoch [42/70], LR: [2.0]\n",
            "Loss: 0.09228229522705078\n",
            "Epoch [43/70], LR: [2.0]\n",
            "Loss: 0.0828525573015213\n",
            "Epoch [44/70], LR: [2.0]\n",
            "Loss: 0.09025812894105911\n",
            "Epoch [45/70], LR: [2.0]\n",
            "Loss: 0.09325578808784485\n",
            "Epoch [46/70], LR: [2.0]\n",
            "Loss: 0.0960029661655426\n",
            "Epoch [47/70], LR: [2.0]\n",
            "Loss: 0.0836820974946022\n",
            "Epoch [48/70], LR: [0.4]\n",
            "Loss: 0.0767902135848999\n",
            "Epoch [49/70], LR: [0.4]\n",
            "Loss: 0.07859600335359573\n",
            "Epoch [50/70], LR: [0.4]\n",
            "Loss: 0.06873524934053421\n",
            "Epoch [51/70], LR: [0.4]\n",
            "Loss: 0.07327956706285477\n",
            "Epoch [52/70], LR: [0.4]\n",
            "Loss: 0.0827973410487175\n",
            "Epoch [53/70], LR: [0.4]\n",
            "Loss: 0.07417860627174377\n",
            "Epoch [54/70], LR: [0.4]\n",
            "Loss: 0.07623378187417984\n",
            "Epoch [55/70], LR: [0.4]\n",
            "Loss: 0.07975880801677704\n",
            "Epoch [56/70], LR: [0.4]\n",
            "Loss: 0.08111964911222458\n",
            "Epoch [57/70], LR: [0.4]\n",
            "Loss: 0.08022205531597137\n",
            "Epoch [58/70], LR: [0.4]\n",
            "Loss: 0.06947934627532959\n",
            "Epoch [59/70], LR: [0.4]\n",
            "Loss: 0.07921219617128372\n",
            "Epoch [60/70], LR: [0.4]\n",
            "Loss: 0.07206527888774872\n",
            "Epoch [61/70], LR: [0.4]\n",
            "Loss: 0.07397287338972092\n",
            "Epoch [62/70], LR: [0.4]\n",
            "Loss: 0.07552605867385864\n",
            "Epoch [63/70], LR: [0.4]\n",
            "Loss: 0.0755748450756073\n",
            "Epoch [64/70], LR: [0.08000000000000002]\n",
            "Loss: 0.07771483063697815\n",
            "Epoch [65/70], LR: [0.08000000000000002]\n",
            "Loss: 0.07359602302312851\n",
            "Epoch [66/70], LR: [0.08000000000000002]\n",
            "Loss: 0.07380326837301254\n",
            "Epoch [67/70], LR: [0.08000000000000002]\n",
            "Loss: 0.07879561930894852\n",
            "Epoch [68/70], LR: [0.08000000000000002]\n",
            "Loss: 0.07639597356319427\n",
            "Epoch [69/70], LR: [0.08000000000000002]\n",
            "Loss: 0.0707961767911911\n",
            "Epoch [70/70], LR: [0.08000000000000002]\n",
            "Loss: 0.07521415501832962\n",
            "num exemplar sets: 20\n",
            "Exemplar means len: 20\n",
            "Reducing exemplars of class 0 to 66\n",
            "Reducing exemplars of class 1 to 66\n",
            "Reducing exemplars of class 2 to 66\n",
            "Reducing exemplars of class 3 to 66\n",
            "Reducing exemplars of class 4 to 66\n",
            "Reducing exemplars of class 5 to 66\n",
            "Reducing exemplars of class 6 to 66\n",
            "Reducing exemplars of class 7 to 66\n",
            "Reducing exemplars of class 8 to 66\n",
            "Reducing exemplars of class 9 to 66\n",
            "Reducing exemplars of class 10 to 66\n",
            "Reducing exemplars of class 11 to 66\n",
            "Reducing exemplars of class 12 to 66\n",
            "Reducing exemplars of class 13 to 66\n",
            "Reducing exemplars of class 14 to 66\n",
            "Reducing exemplars of class 15 to 66\n",
            "Reducing exemplars of class 16 to 66\n",
            "Reducing exemplars of class 17 to 66\n",
            "Reducing exemplars of class 18 to 66\n",
            "Reducing exemplars of class 19 to 66\n",
            "Constructing exemplar for class [20]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 16it [00:00, 257.37it/s, center_shift=0.000046, iteration=16, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Matteo merda\n",
            "Constructing exemplar for class [21]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 10it [00:00, 245.99it/s, center_shift=0.000000, iteration=10, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Matteo merda\n",
            "Constructing exemplar for class [22]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 9it [00:00, 294.89it/s, center_shift=0.000000, iteration=9, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Matteo merda\n",
            "Constructing exemplar for class [23]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 21it [00:00, 298.36it/s, center_shift=0.000000, iteration=21, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Matteo merda\n",
            "Constructing exemplar for class [24]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 17it [00:00, 279.60it/s, center_shift=0.000038, iteration=17, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Matteo merda\n",
            "Constructing exemplar for class [25]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 7it [00:00, 256.16it/s, center_shift=0.000027, iteration=7, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Matteo merda\n",
            "Constructing exemplar for class [26]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 13it [00:00, 299.99it/s, center_shift=0.000000, iteration=13, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Matteo merda\n",
            "Constructing exemplar for class [27]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 13it [00:00, 316.54it/s, center_shift=0.000058, iteration=13, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Matteo merda\n",
            "Constructing exemplar for class [28]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 17it [00:00, 299.00it/s, center_shift=0.000000, iteration=17, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Matteo merda\n",
            "Constructing exemplar for class [29]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 24it [00:00, 326.72it/s, center_shift=0.000000, iteration=24, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Matteo merda\n",
            "Validating classes ['palm_tree', 'bottle', 'man', 'mushroom', 'snail', 'tiger', 'beaver', 'skyscraper', 'wardrobe', 'train'] -> [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "Validating classes ['bicycle', 'plain', 'couch', 'lobster', 'lion', 'chair', 'tulip', 'television', 'skunk', 'girl'] -> [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
            "Validating classes ['bowl', 'tank', 'lawn_mower', 'snake', 'ray', 'oak_tree', 'poppy', 'castle', 'telephone', 'clock'] -> [20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
            "Accuracy: 0.7203333333333334\n",
            "BATCH [3]\n",
            "Training on ['worm', 'rabbit', 'tractor', 'cockroach', 'house', 'lamp', 'sweet_pepper', 'crab', 'beetle', 'dolphin'] -> [30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
            "calculating output old classes\n",
            "Known classes [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
            "Epoch [1/70], LR: [2.0]\n",
            "Loss: 0.13397105038166046\n",
            "Epoch [2/70], LR: [2.0]\n",
            "Loss: 0.11615883558988571\n",
            "Epoch [3/70], LR: [2.0]\n",
            "Loss: 0.11652098596096039\n",
            "Epoch [4/70], LR: [2.0]\n",
            "Loss: 0.10607439279556274\n",
            "Epoch [5/70], LR: [2.0]\n",
            "Loss: 0.10558393597602844\n",
            "Epoch [6/70], LR: [2.0]\n",
            "Loss: 0.11037584394216537\n",
            "Epoch [7/70], LR: [2.0]\n",
            "Loss: 0.10810662806034088\n",
            "Epoch [8/70], LR: [2.0]\n",
            "Loss: 0.11502301692962646\n",
            "Epoch [9/70], LR: [2.0]\n",
            "Loss: 0.10248161852359772\n",
            "Epoch [10/70], LR: [2.0]\n",
            "Loss: 0.10127092152833939\n",
            "Epoch [11/70], LR: [2.0]\n",
            "Loss: 0.10286262631416321\n",
            "Epoch [12/70], LR: [2.0]\n",
            "Loss: 0.10269641876220703\n",
            "Epoch [13/70], LR: [2.0]\n",
            "Loss: 0.1105334684252739\n",
            "Epoch [14/70], LR: [2.0]\n",
            "Loss: 0.11181630939245224\n",
            "Epoch [15/70], LR: [2.0]\n",
            "Loss: 0.11960211396217346\n",
            "Epoch [16/70], LR: [2.0]\n",
            "Loss: 0.09774642437696457\n",
            "Epoch [17/70], LR: [2.0]\n",
            "Loss: 0.0933690294623375\n",
            "Epoch [18/70], LR: [2.0]\n",
            "Loss: 0.10653257369995117\n",
            "Epoch [19/70], LR: [2.0]\n",
            "Loss: 0.09543434530496597\n",
            "Epoch [20/70], LR: [2.0]\n",
            "Loss: 0.10263533145189285\n",
            "Epoch [21/70], LR: [2.0]\n",
            "Loss: 0.1004510372877121\n",
            "Epoch [22/70], LR: [2.0]\n",
            "Loss: 0.0977623239159584\n",
            "Epoch [23/70], LR: [2.0]\n",
            "Loss: 0.09870626032352448\n",
            "Epoch [24/70], LR: [2.0]\n",
            "Loss: 0.10495906323194504\n",
            "Epoch [25/70], LR: [2.0]\n",
            "Loss: 0.09722796082496643\n",
            "Epoch [26/70], LR: [2.0]\n",
            "Loss: 0.10493267327547073\n",
            "Epoch [27/70], LR: [2.0]\n",
            "Loss: 0.09922606498003006\n",
            "Epoch [28/70], LR: [2.0]\n",
            "Loss: 0.09538792073726654\n",
            "Epoch [29/70], LR: [2.0]\n",
            "Loss: 0.10911928117275238\n",
            "Epoch [30/70], LR: [2.0]\n",
            "Loss: 0.10564500093460083\n",
            "Epoch [31/70], LR: [2.0]\n",
            "Loss: 0.09580112993717194\n",
            "Epoch [32/70], LR: [2.0]\n",
            "Loss: 0.10779930651187897\n",
            "Epoch [33/70], LR: [2.0]\n",
            "Loss: 0.08987390249967575\n",
            "Epoch [34/70], LR: [2.0]\n",
            "Loss: 0.0951480120420456\n",
            "Epoch [35/70], LR: [2.0]\n",
            "Loss: 0.09785307943820953\n",
            "Epoch [36/70], LR: [2.0]\n",
            "Loss: 0.09467067569494247\n",
            "Epoch [37/70], LR: [2.0]\n",
            "Loss: 0.08984999358654022\n",
            "Epoch [38/70], LR: [2.0]\n",
            "Loss: 0.09324652701616287\n",
            "Epoch [39/70], LR: [2.0]\n",
            "Loss: 0.09473587572574615\n",
            "Epoch [40/70], LR: [2.0]\n",
            "Loss: 0.09160597622394562\n",
            "Epoch [41/70], LR: [2.0]\n",
            "Loss: 0.09728384763002396\n",
            "Epoch [42/70], LR: [2.0]\n",
            "Loss: 0.09182069450616837\n",
            "Epoch [43/70], LR: [2.0]\n",
            "Loss: 0.08864075690507889\n",
            "Epoch [44/70], LR: [2.0]\n",
            "Loss: 0.0942058265209198\n",
            "Epoch [45/70], LR: [2.0]\n",
            "Loss: 0.0920136496424675\n",
            "Epoch [46/70], LR: [2.0]\n",
            "Loss: 0.08992462605237961\n",
            "Epoch [47/70], LR: [2.0]\n",
            "Loss: 0.09733162075281143\n",
            "Epoch [48/70], LR: [0.4]\n",
            "Loss: 0.07806200534105301\n",
            "Epoch [49/70], LR: [0.4]\n",
            "Loss: 0.08065622299909592\n",
            "Epoch [50/70], LR: [0.4]\n",
            "Loss: 0.0913572758436203\n",
            "Epoch [51/70], LR: [0.4]\n",
            "Loss: 0.07630765438079834\n",
            "Epoch [52/70], LR: [0.4]\n",
            "Loss: 0.07696033269166946\n",
            "Epoch [53/70], LR: [0.4]\n",
            "Loss: 0.07898123562335968\n",
            "Epoch [54/70], LR: [0.4]\n",
            "Loss: 0.0782533660531044\n",
            "Epoch [55/70], LR: [0.4]\n",
            "Loss: 0.08840423077344894\n",
            "Epoch [56/70], LR: [0.4]\n",
            "Loss: 0.08609827607870102\n",
            "Epoch [57/70], LR: [0.4]\n",
            "Loss: 0.0842098668217659\n",
            "Epoch [58/70], LR: [0.4]\n",
            "Loss: 0.08847576379776001\n",
            "Epoch [59/70], LR: [0.4]\n",
            "Loss: 0.08212730288505554\n",
            "Epoch [60/70], LR: [0.4]\n",
            "Loss: 0.07937414199113846\n",
            "Epoch [61/70], LR: [0.4]\n",
            "Loss: 0.08257102966308594\n",
            "Epoch [62/70], LR: [0.4]\n",
            "Loss: 0.08796536177396774\n",
            "Epoch [63/70], LR: [0.4]\n",
            "Loss: 0.07823105156421661\n",
            "Epoch [64/70], LR: [0.08000000000000002]\n",
            "Loss: 0.07865049690008163\n",
            "Epoch [65/70], LR: [0.08000000000000002]\n",
            "Loss: 0.08512450009584427\n",
            "Epoch [66/70], LR: [0.08000000000000002]\n",
            "Loss: 0.08158671855926514\n",
            "Epoch [67/70], LR: [0.08000000000000002]\n",
            "Loss: 0.07333661615848541\n",
            "Epoch [68/70], LR: [0.08000000000000002]\n",
            "Loss: 0.0790720134973526\n",
            "Epoch [69/70], LR: [0.08000000000000002]\n",
            "Loss: 0.08062814921140671\n",
            "Epoch [70/70], LR: [0.08000000000000002]\n",
            "Loss: 0.07872235774993896\n",
            "num exemplar sets: 30\n",
            "Exemplar means len: 30\n",
            "Reducing exemplars of class 0 to 50\n",
            "Reducing exemplars of class 1 to 50\n",
            "Reducing exemplars of class 2 to 50\n",
            "Reducing exemplars of class 3 to 50\n",
            "Reducing exemplars of class 4 to 50\n",
            "Reducing exemplars of class 5 to 50\n",
            "Reducing exemplars of class 6 to 50\n",
            "Reducing exemplars of class 7 to 50\n",
            "Reducing exemplars of class 8 to 50\n",
            "Reducing exemplars of class 9 to 50\n",
            "Reducing exemplars of class 10 to 50\n",
            "Reducing exemplars of class 11 to 50\n",
            "Reducing exemplars of class 12 to 50\n",
            "Reducing exemplars of class 13 to 50\n",
            "Reducing exemplars of class 14 to 50\n",
            "Reducing exemplars of class 15 to 50\n",
            "Reducing exemplars of class 16 to 50\n",
            "Reducing exemplars of class 17 to 50\n",
            "Reducing exemplars of class 18 to 50\n",
            "Reducing exemplars of class 19 to 50\n",
            "Reducing exemplars of class 20 to 50\n",
            "Reducing exemplars of class 21 to 50\n",
            "Reducing exemplars of class 22 to 50\n",
            "Reducing exemplars of class 23 to 50\n",
            "Reducing exemplars of class 24 to 50\n",
            "Reducing exemplars of class 25 to 50\n",
            "Reducing exemplars of class 26 to 50\n",
            "Reducing exemplars of class 27 to 50\n",
            "Reducing exemplars of class 28 to 50\n",
            "Reducing exemplars of class 29 to 50\n",
            "Constructing exemplar for class [30]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 17it [00:00, 310.60it/s, center_shift=0.000000, iteration=17, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Matteo merda\n",
            "Constructing exemplar for class [31]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 21it [00:00, 314.61it/s, center_shift=0.000000, iteration=21, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Matteo merda\n",
            "Constructing exemplar for class [32]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 23it [00:00, 338.41it/s, center_shift=0.000000, iteration=23, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Matteo merda\n",
            "Constructing exemplar for class [33]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 15it [00:00, 307.77it/s, center_shift=0.000043, iteration=15, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Matteo merda\n",
            "Constructing exemplar for class [34]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 30it [00:00, 293.33it/s, center_shift=0.000000, iteration=30, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Matteo merda\n",
            "Constructing exemplar for class [35]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 25it [00:00, 315.12it/s, center_shift=0.000000, iteration=25, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Matteo merda\n",
            "Constructing exemplar for class [36]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 10it [00:00, 276.15it/s, center_shift=0.000000, iteration=10, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Constructing exemplar for class [37]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[running kmeans]: 28it [00:00, 259.45it/s, center_shift=0.000000, iteration=28, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Matteo merda\n",
            "Constructing exemplar for class [38]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 10it [00:00, 299.27it/s, center_shift=0.000000, iteration=10, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Constructing exemplar for class [39]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[running kmeans]: 10it [00:00, 268.40it/s, center_shift=0.000000, iteration=10, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Validating classes ['palm_tree', 'bottle', 'man', 'mushroom', 'snail', 'tiger', 'beaver', 'skyscraper', 'wardrobe', 'train'] -> [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validating classes ['bicycle', 'plain', 'couch', 'lobster', 'lion', 'chair', 'tulip', 'television', 'skunk', 'girl'] -> [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
            "Validating classes ['bowl', 'tank', 'lawn_mower', 'snake', 'ray', 'oak_tree', 'poppy', 'castle', 'telephone', 'clock'] -> [20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
            "Validating classes ['worm', 'rabbit', 'tractor', 'cockroach', 'house', 'lamp', 'sweet_pepper', 'crab', 'beetle', 'dolphin'] -> [30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
            "Accuracy: 0.63175\n",
            "BATCH [4]\n",
            "Training on ['mouse', 'flatfish', 'pear', 'lizard', 'shark', 'orchid', 'cup', 'bus', 'sunflower', 'dinosaur'] -> [40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
            "calculating output old classes\n",
            "Known classes [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
            "Epoch [1/70], LR: [2.0]\n",
            "Loss: 0.12801094353199005\n",
            "Epoch [2/70], LR: [2.0]\n",
            "Loss: 0.10606054961681366\n",
            "Epoch [3/70], LR: [2.0]\n",
            "Loss: 0.11632814258337021\n",
            "Epoch [4/70], LR: [2.0]\n",
            "Loss: 0.1076427549123764\n",
            "Epoch [5/70], LR: [2.0]\n",
            "Loss: 0.10977926105260849\n",
            "Epoch [6/70], LR: [2.0]\n",
            "Loss: 0.09657920151948929\n",
            "Epoch [7/70], LR: [2.0]\n",
            "Loss: 0.1018294095993042\n",
            "Epoch [8/70], LR: [2.0]\n",
            "Loss: 0.11430779099464417\n",
            "Epoch [9/70], LR: [2.0]\n",
            "Loss: 0.10743478685617447\n",
            "Epoch [10/70], LR: [2.0]\n",
            "Loss: 0.1061139851808548\n",
            "Epoch [11/70], LR: [2.0]\n",
            "Loss: 0.10578738152980804\n",
            "Epoch [12/70], LR: [2.0]\n",
            "Loss: 0.1076972559094429\n",
            "Epoch [13/70], LR: [2.0]\n",
            "Loss: 0.10409314185380936\n",
            "Epoch [14/70], LR: [2.0]\n",
            "Loss: 0.10071652382612228\n",
            "Epoch [15/70], LR: [2.0]\n",
            "Loss: 0.10610586404800415\n",
            "Epoch [16/70], LR: [2.0]\n",
            "Loss: 0.09158628433942795\n",
            "Epoch [17/70], LR: [2.0]\n",
            "Loss: 0.09984161704778671\n",
            "Epoch [18/70], LR: [2.0]\n",
            "Loss: 0.09963425248861313\n",
            "Epoch [19/70], LR: [2.0]\n",
            "Loss: 0.09877882897853851\n",
            "Epoch [20/70], LR: [2.0]\n",
            "Loss: 0.10174195468425751\n",
            "Epoch [21/70], LR: [2.0]\n",
            "Loss: 0.0964057520031929\n",
            "Epoch [22/70], LR: [2.0]\n",
            "Loss: 0.09207054227590561\n",
            "Epoch [23/70], LR: [2.0]\n",
            "Loss: 0.10419639199972153\n",
            "Epoch [24/70], LR: [2.0]\n",
            "Loss: 0.10616444051265717\n",
            "Epoch [25/70], LR: [2.0]\n",
            "Loss: 0.09992023557424545\n",
            "Epoch [26/70], LR: [2.0]\n",
            "Loss: 0.10146141052246094\n",
            "Epoch [27/70], LR: [2.0]\n",
            "Loss: 0.09517659991979599\n",
            "Epoch [28/70], LR: [2.0]\n",
            "Loss: 0.09355484694242477\n",
            "Epoch [29/70], LR: [2.0]\n",
            "Loss: 0.09707880020141602\n",
            "Epoch [30/70], LR: [2.0]\n",
            "Loss: 0.08888088166713715\n",
            "Epoch [31/70], LR: [2.0]\n",
            "Loss: 0.08631525188684464\n",
            "Epoch [32/70], LR: [2.0]\n",
            "Loss: 0.09479200839996338\n",
            "Epoch [33/70], LR: [2.0]\n",
            "Loss: 0.09210822731256485\n",
            "Epoch [34/70], LR: [2.0]\n",
            "Loss: 0.10641054064035416\n",
            "Epoch [35/70], LR: [2.0]\n",
            "Loss: 0.09170950949192047\n",
            "Epoch [36/70], LR: [2.0]\n",
            "Loss: 0.09428180009126663\n",
            "Epoch [37/70], LR: [2.0]\n",
            "Loss: 0.09760522842407227\n",
            "Epoch [38/70], LR: [2.0]\n",
            "Loss: 0.09236451983451843\n",
            "Epoch [39/70], LR: [2.0]\n",
            "Loss: 0.09314563125371933\n",
            "Epoch [40/70], LR: [2.0]\n",
            "Loss: 0.08235589414834976\n",
            "Epoch [41/70], LR: [2.0]\n",
            "Loss: 0.08992809057235718\n",
            "Epoch [42/70], LR: [2.0]\n",
            "Loss: 0.09874994307756424\n",
            "Epoch [43/70], LR: [2.0]\n",
            "Loss: 0.09832142293453217\n",
            "Epoch [44/70], LR: [2.0]\n",
            "Loss: 0.10191512852907181\n",
            "Epoch [45/70], LR: [2.0]\n",
            "Loss: 0.09371928870677948\n",
            "Epoch [46/70], LR: [2.0]\n",
            "Loss: 0.09434874355792999\n",
            "Epoch [47/70], LR: [2.0]\n",
            "Loss: 0.09927606582641602\n",
            "Epoch [48/70], LR: [0.4]\n",
            "Loss: 0.08343217521905899\n",
            "Epoch [49/70], LR: [0.4]\n",
            "Loss: 0.0846041664481163\n",
            "Epoch [50/70], LR: [0.4]\n",
            "Loss: 0.08953900635242462\n",
            "Epoch [51/70], LR: [0.4]\n",
            "Loss: 0.08824223279953003\n",
            "Epoch [52/70], LR: [0.4]\n",
            "Loss: 0.08266457170248032\n",
            "Epoch [53/70], LR: [0.4]\n",
            "Loss: 0.08700422197580338\n",
            "Epoch [54/70], LR: [0.4]\n",
            "Loss: 0.08139374852180481\n",
            "Epoch [55/70], LR: [0.4]\n",
            "Loss: 0.07789257913827896\n",
            "Epoch [56/70], LR: [0.4]\n",
            "Loss: 0.07458509504795074\n",
            "Epoch [57/70], LR: [0.4]\n",
            "Loss: 0.08392804861068726\n",
            "Epoch [58/70], LR: [0.4]\n",
            "Loss: 0.08529550582170486\n",
            "Epoch [59/70], LR: [0.4]\n",
            "Loss: 0.08018434047698975\n",
            "Epoch [60/70], LR: [0.4]\n",
            "Loss: 0.0819806307554245\n",
            "Epoch [61/70], LR: [0.4]\n",
            "Loss: 0.08610185980796814\n",
            "Epoch [62/70], LR: [0.4]\n",
            "Loss: 0.0805206447839737\n",
            "Epoch [63/70], LR: [0.4]\n",
            "Loss: 0.08156951516866684\n",
            "Epoch [64/70], LR: [0.08000000000000002]\n",
            "Loss: 0.08380834758281708\n",
            "Epoch [65/70], LR: [0.08000000000000002]\n",
            "Loss: 0.08058936148881912\n",
            "Epoch [66/70], LR: [0.08000000000000002]\n",
            "Loss: 0.08356421440839767\n",
            "Epoch [67/70], LR: [0.08000000000000002]\n",
            "Loss: 0.08312800526618958\n",
            "Epoch [68/70], LR: [0.08000000000000002]\n",
            "Loss: 0.08492877334356308\n",
            "Epoch [69/70], LR: [0.08000000000000002]\n",
            "Loss: 0.0734955221414566\n",
            "Epoch [70/70], LR: [0.08000000000000002]\n",
            "Loss: 0.07955466955900192\n",
            "num exemplar sets: 40\n",
            "Exemplar means len: 40\n",
            "Reducing exemplars of class 0 to 40\n",
            "Reducing exemplars of class 1 to 40\n",
            "Reducing exemplars of class 2 to 40\n",
            "Reducing exemplars of class 3 to 40\n",
            "Reducing exemplars of class 4 to 40\n",
            "Reducing exemplars of class 5 to 40\n",
            "Reducing exemplars of class 6 to 40\n",
            "Reducing exemplars of class 7 to 40\n",
            "Reducing exemplars of class 8 to 40\n",
            "Reducing exemplars of class 9 to 40\n",
            "Reducing exemplars of class 10 to 40\n",
            "Reducing exemplars of class 11 to 40\n",
            "Reducing exemplars of class 12 to 40\n",
            "Reducing exemplars of class 13 to 40\n",
            "Reducing exemplars of class 14 to 40\n",
            "Reducing exemplars of class 15 to 40\n",
            "Reducing exemplars of class 16 to 40\n",
            "Reducing exemplars of class 17 to 40\n",
            "Reducing exemplars of class 18 to 40\n",
            "Reducing exemplars of class 19 to 40\n",
            "Reducing exemplars of class 20 to 40\n",
            "Reducing exemplars of class 21 to 40\n",
            "Reducing exemplars of class 22 to 40\n",
            "Reducing exemplars of class 23 to 40\n",
            "Reducing exemplars of class 24 to 40\n",
            "Reducing exemplars of class 25 to 40\n",
            "Reducing exemplars of class 26 to 40\n",
            "Reducing exemplars of class 27 to 40\n",
            "Reducing exemplars of class 28 to 40\n",
            "Reducing exemplars of class 29 to 40\n",
            "Reducing exemplars of class 30 to 40\n",
            "Reducing exemplars of class 31 to 40\n",
            "Reducing exemplars of class 32 to 40\n",
            "Reducing exemplars of class 33 to 40\n",
            "Reducing exemplars of class 34 to 40\n",
            "Reducing exemplars of class 35 to 40\n",
            "Reducing exemplars of class 36 to 40\n",
            "Reducing exemplars of class 37 to 40\n",
            "Reducing exemplars of class 38 to 40\n",
            "Reducing exemplars of class 39 to 40\n",
            "Constructing exemplar for class [40]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 21it [00:00, 293.27it/s, center_shift=0.000000, iteration=21, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Matteo merda\n",
            "Constructing exemplar for class [41]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 11it [00:00, 291.62it/s, center_shift=0.000000, iteration=11, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Constructing exemplar for class [42]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[running kmeans]: 32it [00:00, 290.90it/s, center_shift=0.000000, iteration=32, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Matteo merda\n",
            "Constructing exemplar for class [43]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 13it [00:00, 246.67it/s, center_shift=0.000000, iteration=13, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Constructing exemplar for class [44]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[running kmeans]: 11it [00:00, 274.13it/s, center_shift=0.000022, iteration=11, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Constructing exemplar for class [45]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[running kmeans]: 24it [00:00, 312.78it/s, center_shift=0.000000, iteration=24, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Matteo merda\n",
            "Constructing exemplar for class [46]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 27it [00:00, 288.17it/s, center_shift=0.000000, iteration=27, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Matteo merda\n",
            "Constructing exemplar for class [47]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 13it [00:00, 286.46it/s, center_shift=0.000000, iteration=13, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Constructing exemplar for class [48]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[running kmeans]: 13it [00:00, 274.41it/s, center_shift=0.000000, iteration=13, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Constructing exemplar for class [49]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[running kmeans]: 14it [00:00, 270.22it/s, center_shift=0.000000, iteration=14, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Validating classes ['palm_tree', 'bottle', 'man', 'mushroom', 'snail', 'tiger', 'beaver', 'skyscraper', 'wardrobe', 'train'] -> [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validating classes ['bicycle', 'plain', 'couch', 'lobster', 'lion', 'chair', 'tulip', 'television', 'skunk', 'girl'] -> [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
            "Validating classes ['bowl', 'tank', 'lawn_mower', 'snake', 'ray', 'oak_tree', 'poppy', 'castle', 'telephone', 'clock'] -> [20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
            "Validating classes ['worm', 'rabbit', 'tractor', 'cockroach', 'house', 'lamp', 'sweet_pepper', 'crab', 'beetle', 'dolphin'] -> [30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
            "Validating classes ['mouse', 'flatfish', 'pear', 'lizard', 'shark', 'orchid', 'cup', 'bus', 'sunflower', 'dinosaur'] -> [40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
            "Accuracy: 0.565\n",
            "BATCH [5]\n",
            "Training on ['whale', 'wolf', 'woman', 'cloud', 'porcupine', 'road', 'plate', 'table', 'sea', 'seal'] -> [50, 51, 52, 53, 54, 55, 56, 57, 58, 59]\n",
            "calculating output old classes\n",
            "Known classes [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]\n",
            "Epoch [1/70], LR: [2.0]\n",
            "Loss: 0.11240056157112122\n",
            "Epoch [2/70], LR: [2.0]\n",
            "Loss: 0.10933081805706024\n",
            "Epoch [3/70], LR: [2.0]\n",
            "Loss: 0.09590736031532288\n",
            "Epoch [4/70], LR: [2.0]\n",
            "Loss: 0.09634362161159515\n",
            "Epoch [5/70], LR: [2.0]\n",
            "Loss: 0.09456546604633331\n",
            "Epoch [6/70], LR: [2.0]\n",
            "Loss: 0.10082525759935379\n",
            "Epoch [7/70], LR: [2.0]\n",
            "Loss: 0.09819352626800537\n",
            "Epoch [8/70], LR: [2.0]\n",
            "Loss: 0.10096139460802078\n",
            "Epoch [9/70], LR: [2.0]\n",
            "Loss: 0.09711838513612747\n",
            "Epoch [10/70], LR: [2.0]\n",
            "Loss: 0.09705256670713425\n",
            "Epoch [11/70], LR: [2.0]\n",
            "Loss: 0.09982338547706604\n",
            "Epoch [12/70], LR: [2.0]\n",
            "Loss: 0.09569767862558365\n",
            "Epoch [13/70], LR: [2.0]\n",
            "Loss: 0.08534500747919083\n",
            "Epoch [14/70], LR: [2.0]\n",
            "Loss: 0.08611298352479935\n",
            "Epoch [15/70], LR: [2.0]\n",
            "Loss: 0.10256409645080566\n",
            "Epoch [16/70], LR: [2.0]\n",
            "Loss: 0.09480411559343338\n",
            "Epoch [17/70], LR: [2.0]\n",
            "Loss: 0.08966327458620071\n",
            "Epoch [18/70], LR: [2.0]\n",
            "Loss: 0.09807071089744568\n",
            "Epoch [19/70], LR: [2.0]\n",
            "Loss: 0.08943568170070648\n",
            "Epoch [20/70], LR: [2.0]\n",
            "Loss: 0.09686436504125595\n",
            "Epoch [21/70], LR: [2.0]\n",
            "Loss: 0.09844055026769638\n",
            "Epoch [22/70], LR: [2.0]\n",
            "Loss: 0.09059298038482666\n",
            "Epoch [23/70], LR: [2.0]\n",
            "Loss: 0.08758049458265305\n",
            "Epoch [24/70], LR: [2.0]\n",
            "Loss: 0.09638768434524536\n",
            "Epoch [25/70], LR: [2.0]\n",
            "Loss: 0.08403463661670685\n",
            "Epoch [26/70], LR: [2.0]\n",
            "Loss: 0.09066972136497498\n",
            "Epoch [27/70], LR: [2.0]\n",
            "Loss: 0.0889551192522049\n",
            "Epoch [28/70], LR: [2.0]\n",
            "Loss: 0.08736421167850494\n",
            "Epoch [29/70], LR: [2.0]\n",
            "Loss: 0.09165335446596146\n",
            "Epoch [30/70], LR: [2.0]\n",
            "Loss: 0.09618734568357468\n",
            "Epoch [31/70], LR: [2.0]\n",
            "Loss: 0.09405846893787384\n",
            "Epoch [32/70], LR: [2.0]\n",
            "Loss: 0.09278470277786255\n",
            "Epoch [33/70], LR: [2.0]\n",
            "Loss: 0.08767839521169662\n",
            "Epoch [34/70], LR: [2.0]\n",
            "Loss: 0.08257275819778442\n",
            "Epoch [35/70], LR: [2.0]\n",
            "Loss: 0.08885321766138077\n",
            "Epoch [36/70], LR: [2.0]\n",
            "Loss: 0.09239235520362854\n",
            "Epoch [37/70], LR: [2.0]\n",
            "Loss: 0.08856019377708435\n",
            "Epoch [38/70], LR: [2.0]\n",
            "Loss: 0.08965131640434265\n",
            "Epoch [39/70], LR: [2.0]\n",
            "Loss: 0.08843175321817398\n",
            "Epoch [40/70], LR: [2.0]\n",
            "Loss: 0.0909930020570755\n",
            "Epoch [41/70], LR: [2.0]\n",
            "Loss: 0.08547484874725342\n",
            "Epoch [42/70], LR: [2.0]\n",
            "Loss: 0.08626430481672287\n",
            "Epoch [43/70], LR: [2.0]\n",
            "Loss: 0.09726585447788239\n",
            "Epoch [44/70], LR: [2.0]\n",
            "Loss: 0.08508892357349396\n",
            "Epoch [45/70], LR: [2.0]\n",
            "Loss: 0.08210071176290512\n",
            "Epoch [46/70], LR: [2.0]\n",
            "Loss: 0.08414336293935776\n",
            "Epoch [47/70], LR: [2.0]\n",
            "Loss: 0.09190962463617325\n",
            "Epoch [48/70], LR: [0.4]\n",
            "Loss: 0.08439463376998901\n",
            "Epoch [49/70], LR: [0.4]\n",
            "Loss: 0.08517048507928848\n",
            "Epoch [50/70], LR: [0.4]\n",
            "Loss: 0.08213949203491211\n",
            "Epoch [51/70], LR: [0.4]\n",
            "Loss: 0.0801360160112381\n",
            "Epoch [52/70], LR: [0.4]\n",
            "Loss: 0.08775145560503006\n",
            "Epoch [53/70], LR: [0.4]\n",
            "Loss: 0.07290767133235931\n",
            "Epoch [54/70], LR: [0.4]\n",
            "Loss: 0.08258975297212601\n",
            "Epoch [55/70], LR: [0.4]\n",
            "Loss: 0.07844135910272598\n",
            "Epoch [56/70], LR: [0.4]\n",
            "Loss: 0.07802355289459229\n",
            "Epoch [57/70], LR: [0.4]\n",
            "Loss: 0.07724844664335251\n",
            "Epoch [58/70], LR: [0.4]\n",
            "Loss: 0.07893636077642441\n",
            "Epoch [59/70], LR: [0.4]\n",
            "Loss: 0.07976388931274414\n",
            "Epoch [60/70], LR: [0.4]\n",
            "Loss: 0.07951263338327408\n",
            "Epoch [61/70], LR: [0.4]\n",
            "Loss: 0.0809922143816948\n",
            "Epoch [62/70], LR: [0.4]\n",
            "Loss: 0.07799666374921799\n",
            "Epoch [63/70], LR: [0.4]\n",
            "Loss: 0.08819841593503952\n",
            "Epoch [64/70], LR: [0.08000000000000002]\n",
            "Loss: 0.08365832269191742\n",
            "Epoch [65/70], LR: [0.08000000000000002]\n",
            "Loss: 0.07716207206249237\n",
            "Epoch [66/70], LR: [0.08000000000000002]\n",
            "Loss: 0.08007285743951797\n",
            "Epoch [67/70], LR: [0.08000000000000002]\n",
            "Loss: 0.08751747012138367\n",
            "Epoch [68/70], LR: [0.08000000000000002]\n",
            "Loss: 0.08571907877922058\n",
            "Epoch [69/70], LR: [0.08000000000000002]\n",
            "Loss: 0.0777646154165268\n",
            "Epoch [70/70], LR: [0.08000000000000002]\n",
            "Loss: 0.0842643678188324\n",
            "num exemplar sets: 50\n",
            "Exemplar means len: 50\n",
            "Reducing exemplars of class 0 to 33\n",
            "Reducing exemplars of class 1 to 33\n",
            "Reducing exemplars of class 2 to 33\n",
            "Reducing exemplars of class 3 to 33\n",
            "Reducing exemplars of class 4 to 33\n",
            "Reducing exemplars of class 5 to 33\n",
            "Reducing exemplars of class 6 to 33\n",
            "Reducing exemplars of class 7 to 33\n",
            "Reducing exemplars of class 8 to 33\n",
            "Reducing exemplars of class 9 to 33\n",
            "Reducing exemplars of class 10 to 33\n",
            "Reducing exemplars of class 11 to 33\n",
            "Reducing exemplars of class 12 to 33\n",
            "Reducing exemplars of class 13 to 33\n",
            "Reducing exemplars of class 14 to 33\n",
            "Reducing exemplars of class 15 to 33\n",
            "Reducing exemplars of class 16 to 33\n",
            "Reducing exemplars of class 17 to 33\n",
            "Reducing exemplars of class 18 to 33\n",
            "Reducing exemplars of class 19 to 33\n",
            "Reducing exemplars of class 20 to 33\n",
            "Reducing exemplars of class 21 to 33\n",
            "Reducing exemplars of class 22 to 33\n",
            "Reducing exemplars of class 23 to 33\n",
            "Reducing exemplars of class 24 to 33\n",
            "Reducing exemplars of class 25 to 33\n",
            "Reducing exemplars of class 26 to 33\n",
            "Reducing exemplars of class 27 to 33\n",
            "Reducing exemplars of class 28 to 33\n",
            "Reducing exemplars of class 29 to 33\n",
            "Reducing exemplars of class 30 to 33\n",
            "Reducing exemplars of class 31 to 33\n",
            "Reducing exemplars of class 32 to 33\n",
            "Reducing exemplars of class 33 to 33\n",
            "Reducing exemplars of class 34 to 33\n",
            "Reducing exemplars of class 35 to 33\n",
            "Reducing exemplars of class 36 to 33\n",
            "Reducing exemplars of class 37 to 33\n",
            "Reducing exemplars of class 38 to 33\n",
            "Reducing exemplars of class 39 to 33\n",
            "Reducing exemplars of class 40 to 33\n",
            "Reducing exemplars of class 41 to 33\n",
            "Reducing exemplars of class 42 to 33\n",
            "Reducing exemplars of class 43 to 33\n",
            "Reducing exemplars of class 44 to 33\n",
            "Reducing exemplars of class 45 to 33\n",
            "Reducing exemplars of class 46 to 33\n",
            "Reducing exemplars of class 47 to 33\n",
            "Reducing exemplars of class 48 to 33\n",
            "Reducing exemplars of class 49 to 33\n",
            "Constructing exemplar for class [50]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 17it [00:00, 295.29it/s, center_shift=0.000000, iteration=17, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Constructing exemplar for class [51]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[running kmeans]: 18it [00:00, 286.46it/s, center_shift=0.000000, iteration=18, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Constructing exemplar for class [52]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[running kmeans]: 13it [00:00, 271.95it/s, center_shift=0.000000, iteration=13, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Constructing exemplar for class [53]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[running kmeans]: 13it [00:00, 266.72it/s, center_shift=0.000000, iteration=13, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Constructing exemplar for class [54]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[running kmeans]: 20it [00:00, 277.85it/s, center_shift=0.000000, iteration=20, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Matteo merda\n",
            "Constructing exemplar for class [55]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 14it [00:00, 335.97it/s, center_shift=0.000000, iteration=14, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Constructing exemplar for class [56]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[running kmeans]: 20it [00:00, 301.59it/s, center_shift=0.000000, iteration=20, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Matteo merda\n",
            "Constructing exemplar for class [57]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 25it [00:00, 327.91it/s, center_shift=0.000000, iteration=25, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Matteo merda\n",
            "Constructing exemplar for class [58]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 12it [00:00, 330.00it/s, center_shift=0.000000, iteration=12, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Constructing exemplar for class [59]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[running kmeans]: 9it [00:00, 268.54it/s, center_shift=0.000000, iteration=9, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Validating classes ['palm_tree', 'bottle', 'man', 'mushroom', 'snail', 'tiger', 'beaver', 'skyscraper', 'wardrobe', 'train'] -> [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validating classes ['bicycle', 'plain', 'couch', 'lobster', 'lion', 'chair', 'tulip', 'television', 'skunk', 'girl'] -> [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
            "Validating classes ['bowl', 'tank', 'lawn_mower', 'snake', 'ray', 'oak_tree', 'poppy', 'castle', 'telephone', 'clock'] -> [20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
            "Validating classes ['worm', 'rabbit', 'tractor', 'cockroach', 'house', 'lamp', 'sweet_pepper', 'crab', 'beetle', 'dolphin'] -> [30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
            "Validating classes ['mouse', 'flatfish', 'pear', 'lizard', 'shark', 'orchid', 'cup', 'bus', 'sunflower', 'dinosaur'] -> [40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
            "Validating classes ['whale', 'wolf', 'woman', 'cloud', 'porcupine', 'road', 'plate', 'table', 'sea', 'seal'] -> [50, 51, 52, 53, 54, 55, 56, 57, 58, 59]\n",
            "Accuracy: 0.527\n",
            "BATCH [6]\n",
            "Training on ['bear', 'apple', 'forest', 'streetcar', 'can', 'bed', 'crocodile', 'keyboard', 'boy', 'raccoon'] -> [60, 61, 62, 63, 64, 65, 66, 67, 68, 69]\n",
            "calculating output old classes\n",
            "Known classes [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69]\n",
            "Epoch [1/70], LR: [2.0]\n",
            "Loss: 0.12592779099941254\n",
            "Epoch [2/70], LR: [2.0]\n",
            "Loss: 0.10944567620754242\n",
            "Epoch [3/70], LR: [2.0]\n",
            "Loss: 0.1048465222120285\n",
            "Epoch [4/70], LR: [2.0]\n",
            "Loss: 0.10620490461587906\n",
            "Epoch [5/70], LR: [2.0]\n",
            "Loss: 0.09448394179344177\n",
            "Epoch [6/70], LR: [2.0]\n",
            "Loss: 0.10265059024095535\n",
            "Epoch [7/70], LR: [2.0]\n",
            "Loss: 0.09777460992336273\n",
            "Epoch [8/70], LR: [2.0]\n",
            "Loss: 0.10345679521560669\n",
            "Epoch [9/70], LR: [2.0]\n",
            "Loss: 0.09365661442279816\n",
            "Epoch [10/70], LR: [2.0]\n",
            "Loss: 0.10396983474493027\n",
            "Epoch [11/70], LR: [2.0]\n",
            "Loss: 0.10669178515672684\n",
            "Epoch [12/70], LR: [2.0]\n",
            "Loss: 0.09727116674184799\n",
            "Epoch [13/70], LR: [2.0]\n",
            "Loss: 0.09831423312425613\n",
            "Epoch [14/70], LR: [2.0]\n",
            "Loss: 0.09053635597229004\n",
            "Epoch [15/70], LR: [2.0]\n",
            "Loss: 0.09525857865810394\n",
            "Epoch [16/70], LR: [2.0]\n",
            "Loss: 0.09848267585039139\n",
            "Epoch [17/70], LR: [2.0]\n",
            "Loss: 0.10232611000537872\n",
            "Epoch [18/70], LR: [2.0]\n",
            "Loss: 0.09602417051792145\n",
            "Epoch [19/70], LR: [2.0]\n",
            "Loss: 0.09574171155691147\n",
            "Epoch [20/70], LR: [2.0]\n",
            "Loss: 0.09696350246667862\n",
            "Epoch [21/70], LR: [2.0]\n",
            "Loss: 0.08769868314266205\n",
            "Epoch [22/70], LR: [2.0]\n",
            "Loss: 0.09560227394104004\n",
            "Epoch [23/70], LR: [2.0]\n",
            "Loss: 0.09438144415616989\n",
            "Epoch [24/70], LR: [2.0]\n",
            "Loss: 0.09379325807094574\n",
            "Epoch [25/70], LR: [2.0]\n",
            "Loss: 0.08929482847452164\n",
            "Epoch [26/70], LR: [2.0]\n",
            "Loss: 0.1052333191037178\n",
            "Epoch [27/70], LR: [2.0]\n",
            "Loss: 0.10327193886041641\n",
            "Epoch [28/70], LR: [2.0]\n",
            "Loss: 0.09655064344406128\n",
            "Epoch [29/70], LR: [2.0]\n",
            "Loss: 0.08983256667852402\n",
            "Epoch [30/70], LR: [2.0]\n",
            "Loss: 0.09018286317586899\n",
            "Epoch [31/70], LR: [2.0]\n",
            "Loss: 0.09937215596437454\n",
            "Epoch [32/70], LR: [2.0]\n",
            "Loss: 0.09426496177911758\n",
            "Epoch [33/70], LR: [2.0]\n",
            "Loss: 0.09697514772415161\n",
            "Epoch [34/70], LR: [2.0]\n",
            "Loss: 0.09109612554311752\n",
            "Epoch [35/70], LR: [2.0]\n",
            "Loss: 0.10419302433729172\n",
            "Epoch [36/70], LR: [2.0]\n",
            "Loss: 0.08899787068367004\n",
            "Epoch [37/70], LR: [2.0]\n",
            "Loss: 0.09690901637077332\n",
            "Epoch [38/70], LR: [2.0]\n",
            "Loss: 0.08874133229255676\n",
            "Epoch [39/70], LR: [2.0]\n",
            "Loss: 0.09063977003097534\n",
            "Epoch [40/70], LR: [2.0]\n",
            "Loss: 0.09221954643726349\n",
            "Epoch [41/70], LR: [2.0]\n",
            "Loss: 0.09669375419616699\n",
            "Epoch [42/70], LR: [2.0]\n",
            "Loss: 0.09154289215803146\n",
            "Epoch [43/70], LR: [2.0]\n",
            "Loss: 0.0915207490324974\n",
            "Epoch [44/70], LR: [2.0]\n",
            "Loss: 0.09771735221147537\n",
            "Epoch [45/70], LR: [2.0]\n",
            "Loss: 0.08999919891357422\n",
            "Epoch [46/70], LR: [2.0]\n",
            "Loss: 0.08871232718229294\n",
            "Epoch [47/70], LR: [2.0]\n",
            "Loss: 0.09595061838626862\n",
            "Epoch [48/70], LR: [0.4]\n",
            "Loss: 0.08916005492210388\n",
            "Epoch [49/70], LR: [0.4]\n",
            "Loss: 0.08700326830148697\n",
            "Epoch [50/70], LR: [0.4]\n",
            "Loss: 0.08440408110618591\n",
            "Epoch [51/70], LR: [0.4]\n",
            "Loss: 0.09099765121936798\n",
            "Epoch [52/70], LR: [0.4]\n",
            "Loss: 0.08359205722808838\n",
            "Epoch [53/70], LR: [0.4]\n",
            "Loss: 0.08203698694705963\n",
            "Epoch [54/70], LR: [0.4]\n",
            "Loss: 0.08359727263450623\n",
            "Epoch [55/70], LR: [0.4]\n",
            "Loss: 0.08624749630689621\n",
            "Epoch [56/70], LR: [0.4]\n",
            "Loss: 0.0834730938076973\n",
            "Epoch [57/70], LR: [0.4]\n",
            "Loss: 0.0778283029794693\n",
            "Epoch [58/70], LR: [0.4]\n",
            "Loss: 0.07960695773363113\n",
            "Epoch [59/70], LR: [0.4]\n",
            "Loss: 0.07940227538347244\n",
            "Epoch [60/70], LR: [0.4]\n",
            "Loss: 0.07990001887083054\n",
            "Epoch [61/70], LR: [0.4]\n",
            "Loss: 0.0855451449751854\n",
            "Epoch [62/70], LR: [0.4]\n",
            "Loss: 0.08672148734331131\n",
            "Epoch [63/70], LR: [0.4]\n",
            "Loss: 0.08237753808498383\n",
            "Epoch [64/70], LR: [0.08000000000000002]\n",
            "Loss: 0.0772610679268837\n",
            "Epoch [65/70], LR: [0.08000000000000002]\n",
            "Loss: 0.08461607992649078\n",
            "Epoch [66/70], LR: [0.08000000000000002]\n",
            "Loss: 0.08554138243198395\n",
            "Epoch [67/70], LR: [0.08000000000000002]\n",
            "Loss: 0.0921148732304573\n",
            "Epoch [68/70], LR: [0.08000000000000002]\n",
            "Loss: 0.08489137887954712\n",
            "Epoch [69/70], LR: [0.08000000000000002]\n",
            "Loss: 0.0904686376452446\n",
            "Epoch [70/70], LR: [0.08000000000000002]\n",
            "Loss: 0.08129709959030151\n",
            "num exemplar sets: 60\n",
            "Exemplar means len: 60\n",
            "Reducing exemplars of class 0 to 28\n",
            "Reducing exemplars of class 1 to 28\n",
            "Reducing exemplars of class 2 to 28\n",
            "Reducing exemplars of class 3 to 28\n",
            "Reducing exemplars of class 4 to 28\n",
            "Reducing exemplars of class 5 to 28\n",
            "Reducing exemplars of class 6 to 28\n",
            "Reducing exemplars of class 7 to 28\n",
            "Reducing exemplars of class 8 to 28\n",
            "Reducing exemplars of class 9 to 28\n",
            "Reducing exemplars of class 10 to 28\n",
            "Reducing exemplars of class 11 to 28\n",
            "Reducing exemplars of class 12 to 28\n",
            "Reducing exemplars of class 13 to 28\n",
            "Reducing exemplars of class 14 to 28\n",
            "Reducing exemplars of class 15 to 28\n",
            "Reducing exemplars of class 16 to 28\n",
            "Reducing exemplars of class 17 to 28\n",
            "Reducing exemplars of class 18 to 28\n",
            "Reducing exemplars of class 19 to 28\n",
            "Reducing exemplars of class 20 to 28\n",
            "Reducing exemplars of class 21 to 28\n",
            "Reducing exemplars of class 22 to 28\n",
            "Reducing exemplars of class 23 to 28\n",
            "Reducing exemplars of class 24 to 28\n",
            "Reducing exemplars of class 25 to 28\n",
            "Reducing exemplars of class 26 to 28\n",
            "Reducing exemplars of class 27 to 28\n",
            "Reducing exemplars of class 28 to 28\n",
            "Reducing exemplars of class 29 to 28\n",
            "Reducing exemplars of class 30 to 28\n",
            "Reducing exemplars of class 31 to 28\n",
            "Reducing exemplars of class 32 to 28\n",
            "Reducing exemplars of class 33 to 28\n",
            "Reducing exemplars of class 34 to 28\n",
            "Reducing exemplars of class 35 to 28\n",
            "Reducing exemplars of class 36 to 28\n",
            "Reducing exemplars of class 37 to 28\n",
            "Reducing exemplars of class 38 to 28\n",
            "Reducing exemplars of class 39 to 28\n",
            "Reducing exemplars of class 40 to 28\n",
            "Reducing exemplars of class 41 to 28\n",
            "Reducing exemplars of class 42 to 28\n",
            "Reducing exemplars of class 43 to 28\n",
            "Reducing exemplars of class 44 to 28\n",
            "Reducing exemplars of class 45 to 28\n",
            "Reducing exemplars of class 46 to 28\n",
            "Reducing exemplars of class 47 to 28\n",
            "Reducing exemplars of class 48 to 28\n",
            "Reducing exemplars of class 49 to 28\n",
            "Reducing exemplars of class 50 to 28\n",
            "Reducing exemplars of class 51 to 28\n",
            "Reducing exemplars of class 52 to 28\n",
            "Reducing exemplars of class 53 to 28\n",
            "Reducing exemplars of class 54 to 28\n",
            "Reducing exemplars of class 55 to 28\n",
            "Reducing exemplars of class 56 to 28\n",
            "Reducing exemplars of class 57 to 28\n",
            "Reducing exemplars of class 58 to 28\n",
            "Reducing exemplars of class 59 to 28\n",
            "Constructing exemplar for class [60]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 17it [00:00, 312.78it/s, center_shift=0.000000, iteration=17, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Constructing exemplar for class [61]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[running kmeans]: 10it [00:00, 290.05it/s, center_shift=0.000000, iteration=10, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Constructing exemplar for class [62]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[running kmeans]: 18it [00:00, 327.43it/s, center_shift=0.000000, iteration=18, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Constructing exemplar for class [63]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[running kmeans]: 15it [00:00, 293.28it/s, center_shift=0.000000, iteration=15, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Constructing exemplar for class [64]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[running kmeans]: 18it [00:00, 294.46it/s, center_shift=0.000000, iteration=18, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Constructing exemplar for class [65]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[running kmeans]: 24it [00:00, 289.12it/s, center_shift=0.000000, iteration=24, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Constructing exemplar for class [66]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[running kmeans]: 20it [00:00, 269.07it/s, center_shift=0.000000, iteration=20, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Constructing exemplar for class [67]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[running kmeans]: 15it [00:00, 315.64it/s, center_shift=0.000000, iteration=15, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Constructing exemplar for class [68]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[running kmeans]: 13it [00:00, 325.91it/s, center_shift=0.000000, iteration=13, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Constructing exemplar for class [69]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[running kmeans]: 13it [00:00, 276.33it/s, center_shift=0.000000, iteration=13, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Validating classes ['palm_tree', 'bottle', 'man', 'mushroom', 'snail', 'tiger', 'beaver', 'skyscraper', 'wardrobe', 'train'] -> [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validating classes ['bicycle', 'plain', 'couch', 'lobster', 'lion', 'chair', 'tulip', 'television', 'skunk', 'girl'] -> [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
            "Validating classes ['bowl', 'tank', 'lawn_mower', 'snake', 'ray', 'oak_tree', 'poppy', 'castle', 'telephone', 'clock'] -> [20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
            "Validating classes ['worm', 'rabbit', 'tractor', 'cockroach', 'house', 'lamp', 'sweet_pepper', 'crab', 'beetle', 'dolphin'] -> [30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
            "Validating classes ['mouse', 'flatfish', 'pear', 'lizard', 'shark', 'orchid', 'cup', 'bus', 'sunflower', 'dinosaur'] -> [40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
            "Validating classes ['whale', 'wolf', 'woman', 'cloud', 'porcupine', 'road', 'plate', 'table', 'sea', 'seal'] -> [50, 51, 52, 53, 54, 55, 56, 57, 58, 59]\n",
            "Validating classes ['bear', 'apple', 'forest', 'streetcar', 'can', 'bed', 'crocodile', 'keyboard', 'boy', 'raccoon'] -> [60, 61, 62, 63, 64, 65, 66, 67, 68, 69]\n",
            "Accuracy: 0.4765714285714286\n",
            "BATCH [7]\n",
            "Training on ['willow_tree', 'maple_tree', 'orange', 'rocket', 'spider', 'chimpanzee', 'cattle', 'kangaroo', 'bridge', 'fox'] -> [70, 71, 72, 73, 74, 75, 76, 77, 78, 79]\n",
            "calculating output old classes\n",
            "Known classes [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79]\n",
            "Epoch [1/70], LR: [2.0]\n",
            "Loss: 0.1107109934091568\n",
            "Epoch [2/70], LR: [2.0]\n",
            "Loss: 0.11276880651712418\n",
            "Epoch [3/70], LR: [2.0]\n",
            "Loss: 0.1112741082906723\n",
            "Epoch [4/70], LR: [2.0]\n",
            "Loss: 0.0903521403670311\n",
            "Epoch [5/70], LR: [2.0]\n",
            "Loss: 0.10288062691688538\n",
            "Epoch [6/70], LR: [2.0]\n",
            "Loss: 0.10213246941566467\n",
            "Epoch [7/70], LR: [2.0]\n",
            "Loss: 0.09478944540023804\n",
            "Epoch [8/70], LR: [2.0]\n",
            "Loss: 0.09213600307703018\n",
            "Epoch [9/70], LR: [2.0]\n",
            "Loss: 0.09785611182451248\n",
            "Epoch [10/70], LR: [2.0]\n",
            "Loss: 0.10081566870212555\n",
            "Epoch [11/70], LR: [2.0]\n",
            "Loss: 0.0867144912481308\n",
            "Epoch [12/70], LR: [2.0]\n",
            "Loss: 0.09662016481161118\n",
            "Epoch [13/70], LR: [2.0]\n",
            "Loss: 0.09955134987831116\n",
            "Epoch [14/70], LR: [2.0]\n",
            "Loss: 0.10469603538513184\n",
            "Epoch [15/70], LR: [2.0]\n",
            "Loss: 0.09137145429849625\n",
            "Epoch [16/70], LR: [2.0]\n",
            "Loss: 0.08804480731487274\n",
            "Epoch [17/70], LR: [2.0]\n",
            "Loss: 0.09947089105844498\n",
            "Epoch [18/70], LR: [2.0]\n",
            "Loss: 0.09266204386949539\n",
            "Epoch [19/70], LR: [2.0]\n",
            "Loss: 0.08513829857110977\n",
            "Epoch [20/70], LR: [2.0]\n",
            "Loss: 0.0871790274977684\n",
            "Epoch [21/70], LR: [2.0]\n",
            "Loss: 0.09286671131849289\n",
            "Epoch [22/70], LR: [2.0]\n",
            "Loss: 0.09873836487531662\n",
            "Epoch [23/70], LR: [2.0]\n",
            "Loss: 0.09383852779865265\n",
            "Epoch [24/70], LR: [2.0]\n",
            "Loss: 0.08881068974733353\n",
            "Epoch [25/70], LR: [2.0]\n",
            "Loss: 0.0888378694653511\n",
            "Epoch [26/70], LR: [2.0]\n",
            "Loss: 0.09590936452150345\n",
            "Epoch [27/70], LR: [2.0]\n",
            "Loss: 0.09130916744470596\n",
            "Epoch [28/70], LR: [2.0]\n",
            "Loss: 0.08960647135972977\n",
            "Epoch [29/70], LR: [2.0]\n",
            "Loss: 0.0886540487408638\n",
            "Epoch [30/70], LR: [2.0]\n",
            "Loss: 0.09706869721412659\n",
            "Epoch [31/70], LR: [2.0]\n",
            "Loss: 0.08934970200061798\n",
            "Epoch [32/70], LR: [2.0]\n",
            "Loss: 0.09346497803926468\n",
            "Epoch [33/70], LR: [2.0]\n",
            "Loss: 0.09041381627321243\n",
            "Epoch [34/70], LR: [2.0]\n",
            "Loss: 0.08896137773990631\n",
            "Epoch [35/70], LR: [2.0]\n",
            "Loss: 0.09425505995750427\n",
            "Epoch [36/70], LR: [2.0]\n",
            "Loss: 0.09310844540596008\n",
            "Epoch [37/70], LR: [2.0]\n",
            "Loss: 0.10166849195957184\n",
            "Epoch [38/70], LR: [2.0]\n",
            "Loss: 0.0905093103647232\n",
            "Epoch [39/70], LR: [2.0]\n",
            "Loss: 0.08811212331056595\n",
            "Epoch [40/70], LR: [2.0]\n",
            "Loss: 0.08462246507406235\n",
            "Epoch [41/70], LR: [2.0]\n",
            "Loss: 0.09958235919475555\n",
            "Epoch [42/70], LR: [2.0]\n",
            "Loss: 0.09942547231912613\n",
            "Epoch [43/70], LR: [2.0]\n",
            "Loss: 0.0844239592552185\n",
            "Epoch [44/70], LR: [2.0]\n",
            "Loss: 0.0923471674323082\n",
            "Epoch [45/70], LR: [2.0]\n",
            "Loss: 0.08696693927049637\n",
            "Epoch [46/70], LR: [2.0]\n",
            "Loss: 0.0849701464176178\n",
            "Epoch [47/70], LR: [2.0]\n",
            "Loss: 0.08673606067895889\n",
            "Epoch [48/70], LR: [0.4]\n",
            "Loss: 0.07717395573854446\n",
            "Epoch [49/70], LR: [0.4]\n",
            "Loss: 0.08358187973499298\n",
            "Epoch [50/70], LR: [0.4]\n",
            "Loss: 0.08392167836427689\n",
            "Epoch [51/70], LR: [0.4]\n",
            "Loss: 0.08485379070043564\n",
            "Epoch [52/70], LR: [0.4]\n",
            "Loss: 0.08565748482942581\n",
            "Epoch [53/70], LR: [0.4]\n",
            "Loss: 0.08940082788467407\n",
            "Epoch [54/70], LR: [0.4]\n",
            "Loss: 0.09296181052923203\n",
            "Epoch [55/70], LR: [0.4]\n",
            "Loss: 0.08287907391786575\n",
            "Epoch [56/70], LR: [0.4]\n",
            "Loss: 0.07837418466806412\n",
            "Epoch [57/70], LR: [0.4]\n",
            "Loss: 0.08777116239070892\n",
            "Epoch [58/70], LR: [0.4]\n",
            "Loss: 0.07757320255041122\n",
            "Epoch [59/70], LR: [0.4]\n",
            "Loss: 0.09079238772392273\n",
            "Epoch [60/70], LR: [0.4]\n",
            "Loss: 0.08617881685495377\n",
            "Epoch [61/70], LR: [0.4]\n",
            "Loss: 0.08491487801074982\n",
            "Epoch [62/70], LR: [0.4]\n",
            "Loss: 0.08437757194042206\n",
            "Epoch [63/70], LR: [0.4]\n",
            "Loss: 0.08032085001468658\n",
            "Epoch [64/70], LR: [0.08000000000000002]\n",
            "Loss: 0.07973653823137283\n",
            "Epoch [65/70], LR: [0.08000000000000002]\n",
            "Loss: 0.07550104707479477\n",
            "Epoch [66/70], LR: [0.08000000000000002]\n",
            "Loss: 0.09168479591608047\n",
            "Epoch [67/70], LR: [0.08000000000000002]\n",
            "Loss: 0.07946081459522247\n",
            "Epoch [68/70], LR: [0.08000000000000002]\n",
            "Loss: 0.08540422469377518\n",
            "Epoch [69/70], LR: [0.08000000000000002]\n",
            "Loss: 0.08529862016439438\n",
            "Epoch [70/70], LR: [0.08000000000000002]\n",
            "Loss: 0.09004835039377213\n",
            "num exemplar sets: 70\n",
            "Exemplar means len: 70\n",
            "Reducing exemplars of class 0 to 25\n",
            "Reducing exemplars of class 1 to 25\n",
            "Reducing exemplars of class 2 to 25\n",
            "Reducing exemplars of class 3 to 25\n",
            "Reducing exemplars of class 4 to 25\n",
            "Reducing exemplars of class 5 to 25\n",
            "Reducing exemplars of class 6 to 25\n",
            "Reducing exemplars of class 7 to 25\n",
            "Reducing exemplars of class 8 to 25\n",
            "Reducing exemplars of class 9 to 25\n",
            "Reducing exemplars of class 10 to 25\n",
            "Reducing exemplars of class 11 to 25\n",
            "Reducing exemplars of class 12 to 25\n",
            "Reducing exemplars of class 13 to 25\n",
            "Reducing exemplars of class 14 to 25\n",
            "Reducing exemplars of class 15 to 25\n",
            "Reducing exemplars of class 16 to 25\n",
            "Reducing exemplars of class 17 to 25\n",
            "Reducing exemplars of class 18 to 25\n",
            "Reducing exemplars of class 19 to 25\n",
            "Reducing exemplars of class 20 to 25\n",
            "Reducing exemplars of class 21 to 25\n",
            "Reducing exemplars of class 22 to 25\n",
            "Reducing exemplars of class 23 to 25\n",
            "Reducing exemplars of class 24 to 25\n",
            "Reducing exemplars of class 25 to 25\n",
            "Reducing exemplars of class 26 to 25\n",
            "Reducing exemplars of class 27 to 25\n",
            "Reducing exemplars of class 28 to 25\n",
            "Reducing exemplars of class 29 to 25\n",
            "Reducing exemplars of class 30 to 25\n",
            "Reducing exemplars of class 31 to 25\n",
            "Reducing exemplars of class 32 to 25\n",
            "Reducing exemplars of class 33 to 25\n",
            "Reducing exemplars of class 34 to 25\n",
            "Reducing exemplars of class 35 to 25\n",
            "Reducing exemplars of class 36 to 25\n",
            "Reducing exemplars of class 37 to 25\n",
            "Reducing exemplars of class 38 to 25\n",
            "Reducing exemplars of class 39 to 25\n",
            "Reducing exemplars of class 40 to 25\n",
            "Reducing exemplars of class 41 to 25\n",
            "Reducing exemplars of class 42 to 25\n",
            "Reducing exemplars of class 43 to 25\n",
            "Reducing exemplars of class 44 to 25\n",
            "Reducing exemplars of class 45 to 25\n",
            "Reducing exemplars of class 46 to 25\n",
            "Reducing exemplars of class 47 to 25\n",
            "Reducing exemplars of class 48 to 25\n",
            "Reducing exemplars of class 49 to 25\n",
            "Reducing exemplars of class 50 to 25\n",
            "Reducing exemplars of class 51 to 25\n",
            "Reducing exemplars of class 52 to 25\n",
            "Reducing exemplars of class 53 to 25\n",
            "Reducing exemplars of class 54 to 25\n",
            "Reducing exemplars of class 55 to 25\n",
            "Reducing exemplars of class 56 to 25\n",
            "Reducing exemplars of class 57 to 25\n",
            "Reducing exemplars of class 58 to 25\n",
            "Reducing exemplars of class 59 to 25\n",
            "Reducing exemplars of class 60 to 25\n",
            "Reducing exemplars of class 61 to 25\n",
            "Reducing exemplars of class 62 to 25\n",
            "Reducing exemplars of class 63 to 25\n",
            "Reducing exemplars of class 64 to 25\n",
            "Reducing exemplars of class 65 to 25\n",
            "Reducing exemplars of class 66 to 25\n",
            "Reducing exemplars of class 67 to 25\n",
            "Reducing exemplars of class 68 to 25\n",
            "Reducing exemplars of class 69 to 25\n",
            "Constructing exemplar for class [70]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 17it [00:00, 343.83it/s, center_shift=0.000000, iteration=17, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Constructing exemplar for class [71]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[running kmeans]: 18it [00:00, 342.70it/s, center_shift=0.000093, iteration=18, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Constructing exemplar for class [72]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[running kmeans]: 18it [00:00, 302.93it/s, center_shift=0.000000, iteration=18, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Constructing exemplar for class [73]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[running kmeans]: 14it [00:00, 316.88it/s, center_shift=0.000086, iteration=14, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Constructing exemplar for class [74]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[running kmeans]: 12it [00:00, 287.15it/s, center_shift=0.000000, iteration=12, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Constructing exemplar for class [75]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[running kmeans]: 24it [00:00, 315.92it/s, center_shift=0.000000, iteration=24, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Constructing exemplar for class [76]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[running kmeans]: 17it [00:00, 277.63it/s, center_shift=0.000000, iteration=17, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Constructing exemplar for class [77]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[running kmeans]: 11it [00:00, 273.18it/s, center_shift=0.000093, iteration=11, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Constructing exemplar for class [78]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[running kmeans]: 11it [00:00, 298.07it/s, center_shift=0.000000, iteration=11, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Constructing exemplar for class [79]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[running kmeans]: 17it [00:00, 293.29it/s, center_shift=0.000000, iteration=17, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Validating classes ['palm_tree', 'bottle', 'man', 'mushroom', 'snail', 'tiger', 'beaver', 'skyscraper', 'wardrobe', 'train'] -> [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validating classes ['bicycle', 'plain', 'couch', 'lobster', 'lion', 'chair', 'tulip', 'television', 'skunk', 'girl'] -> [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
            "Validating classes ['bowl', 'tank', 'lawn_mower', 'snake', 'ray', 'oak_tree', 'poppy', 'castle', 'telephone', 'clock'] -> [20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
            "Validating classes ['worm', 'rabbit', 'tractor', 'cockroach', 'house', 'lamp', 'sweet_pepper', 'crab', 'beetle', 'dolphin'] -> [30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
            "Validating classes ['mouse', 'flatfish', 'pear', 'lizard', 'shark', 'orchid', 'cup', 'bus', 'sunflower', 'dinosaur'] -> [40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
            "Validating classes ['whale', 'wolf', 'woman', 'cloud', 'porcupine', 'road', 'plate', 'table', 'sea', 'seal'] -> [50, 51, 52, 53, 54, 55, 56, 57, 58, 59]\n",
            "Validating classes ['bear', 'apple', 'forest', 'streetcar', 'can', 'bed', 'crocodile', 'keyboard', 'boy', 'raccoon'] -> [60, 61, 62, 63, 64, 65, 66, 67, 68, 69]\n",
            "Validating classes ['willow_tree', 'maple_tree', 'orange', 'rocket', 'spider', 'chimpanzee', 'cattle', 'kangaroo', 'bridge', 'fox'] -> [70, 71, 72, 73, 74, 75, 76, 77, 78, 79]\n",
            "Accuracy: 0.45375\n",
            "BATCH [8]\n",
            "Training on ['butterfly', 'baby', 'elephant', 'shrew', 'pine_tree', 'squirrel', 'mountain', 'caterpillar', 'bee', 'camel'] -> [80, 81, 82, 83, 84, 85, 86, 87, 88, 89]\n",
            "calculating output old classes\n",
            "Known classes [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89]\n",
            "Epoch [1/70], LR: [2.0]\n",
            "Loss: 0.10576889663934708\n",
            "Epoch [2/70], LR: [2.0]\n",
            "Loss: 0.09787026792764664\n",
            "Epoch [3/70], LR: [2.0]\n",
            "Loss: 0.09834098070859909\n",
            "Epoch [4/70], LR: [2.0]\n",
            "Loss: 0.10668046027421951\n",
            "Epoch [5/70], LR: [2.0]\n",
            "Loss: 0.09539168328046799\n",
            "Epoch [6/70], LR: [2.0]\n",
            "Loss: 0.09329743683338165\n",
            "Epoch [7/70], LR: [2.0]\n",
            "Loss: 0.09600170701742172\n",
            "Epoch [8/70], LR: [2.0]\n",
            "Loss: 0.09249100089073181\n",
            "Epoch [9/70], LR: [2.0]\n",
            "Loss: 0.10114359855651855\n",
            "Epoch [10/70], LR: [2.0]\n",
            "Loss: 0.10032054781913757\n",
            "Epoch [11/70], LR: [2.0]\n",
            "Loss: 0.09778148680925369\n",
            "Epoch [12/70], LR: [2.0]\n",
            "Loss: 0.09597969800233841\n",
            "Epoch [13/70], LR: [2.0]\n",
            "Loss: 0.0999627634882927\n",
            "Epoch [14/70], LR: [2.0]\n",
            "Loss: 0.1032320111989975\n",
            "Epoch [15/70], LR: [2.0]\n",
            "Loss: 0.09720785915851593\n",
            "Epoch [16/70], LR: [2.0]\n",
            "Loss: 0.09652096778154373\n",
            "Epoch [17/70], LR: [2.0]\n",
            "Loss: 0.09589752554893494\n",
            "Epoch [18/70], LR: [2.0]\n",
            "Loss: 0.09458155930042267\n",
            "Epoch [19/70], LR: [2.0]\n",
            "Loss: 0.09487275779247284\n",
            "Epoch [20/70], LR: [2.0]\n",
            "Loss: 0.09341106563806534\n",
            "Epoch [21/70], LR: [2.0]\n",
            "Loss: 0.10151846706867218\n",
            "Epoch [22/70], LR: [2.0]\n",
            "Loss: 0.09015383571386337\n",
            "Epoch [23/70], LR: [2.0]\n",
            "Loss: 0.10046560317277908\n",
            "Epoch [24/70], LR: [2.0]\n",
            "Loss: 0.09175272285938263\n",
            "Epoch [25/70], LR: [2.0]\n",
            "Loss: 0.09230171144008636\n",
            "Epoch [26/70], LR: [2.0]\n",
            "Loss: 0.0966205820441246\n",
            "Epoch [27/70], LR: [2.0]\n",
            "Loss: 0.08992037922143936\n",
            "Epoch [28/70], LR: [2.0]\n",
            "Loss: 0.09628458321094513\n",
            "Epoch [29/70], LR: [2.0]\n",
            "Loss: 0.09233495593070984\n",
            "Epoch [30/70], LR: [2.0]\n",
            "Loss: 0.09557255357503891\n",
            "Epoch [31/70], LR: [2.0]\n",
            "Loss: 0.08969626575708389\n",
            "Epoch [32/70], LR: [2.0]\n",
            "Loss: 0.09793390333652496\n",
            "Epoch [33/70], LR: [2.0]\n",
            "Loss: 0.09328053891658783\n",
            "Epoch [34/70], LR: [2.0]\n",
            "Loss: 0.09892112761735916\n",
            "Epoch [35/70], LR: [2.0]\n",
            "Loss: 0.09494365751743317\n",
            "Epoch [36/70], LR: [2.0]\n",
            "Loss: 0.09506803005933762\n",
            "Epoch [37/70], LR: [2.0]\n",
            "Loss: 0.09173005819320679\n",
            "Epoch [38/70], LR: [2.0]\n",
            "Loss: 0.09565146267414093\n",
            "Epoch [39/70], LR: [2.0]\n",
            "Loss: 0.10358696430921555\n",
            "Epoch [40/70], LR: [2.0]\n",
            "Loss: 0.0926642119884491\n",
            "Epoch [41/70], LR: [2.0]\n",
            "Loss: 0.09384492039680481\n",
            "Epoch [42/70], LR: [2.0]\n",
            "Loss: 0.09202030301094055\n",
            "Epoch [43/70], LR: [2.0]\n",
            "Loss: 0.09972742944955826\n",
            "Epoch [44/70], LR: [2.0]\n",
            "Loss: 0.0967288613319397\n",
            "Epoch [45/70], LR: [2.0]\n",
            "Loss: 0.09131656587123871\n",
            "Epoch [46/70], LR: [2.0]\n",
            "Loss: 0.09911158680915833\n",
            "Epoch [47/70], LR: [2.0]\n",
            "Loss: 0.08671975880861282\n",
            "Epoch [48/70], LR: [0.4]\n",
            "Loss: 0.08858440816402435\n",
            "Epoch [49/70], LR: [0.4]\n",
            "Loss: 0.08271007984876633\n",
            "Epoch [50/70], LR: [0.4]\n",
            "Loss: 0.08134183287620544\n",
            "Epoch [51/70], LR: [0.4]\n",
            "Loss: 0.09081803262233734\n",
            "Epoch [52/70], LR: [0.4]\n",
            "Loss: 0.08641370385885239\n",
            "Epoch [53/70], LR: [0.4]\n",
            "Loss: 0.08094379305839539\n",
            "Epoch [54/70], LR: [0.4]\n",
            "Loss: 0.094073586165905\n",
            "Epoch [55/70], LR: [0.4]\n",
            "Loss: 0.08209577947854996\n",
            "Epoch [56/70], LR: [0.4]\n",
            "Loss: 0.08622148633003235\n",
            "Epoch [57/70], LR: [0.4]\n",
            "Loss: 0.08616989850997925\n",
            "Epoch [58/70], LR: [0.4]\n",
            "Loss: 0.0877743661403656\n",
            "Epoch [59/70], LR: [0.4]\n",
            "Loss: 0.08641970902681351\n",
            "Epoch [60/70], LR: [0.4]\n",
            "Loss: 0.09034231305122375\n",
            "Epoch [61/70], LR: [0.4]\n",
            "Loss: 0.08702101558446884\n",
            "Epoch [62/70], LR: [0.4]\n",
            "Loss: 0.08660640567541122\n",
            "Epoch [63/70], LR: [0.4]\n",
            "Loss: 0.08621380478143692\n",
            "Epoch [64/70], LR: [0.08000000000000002]\n",
            "Loss: 0.08698061853647232\n",
            "Epoch [65/70], LR: [0.08000000000000002]\n",
            "Loss: 0.09031235426664352\n",
            "Epoch [66/70], LR: [0.08000000000000002]\n",
            "Loss: 0.08535875380039215\n",
            "Epoch [67/70], LR: [0.08000000000000002]\n",
            "Loss: 0.08112137019634247\n",
            "Epoch [68/70], LR: [0.08000000000000002]\n",
            "Loss: 0.09093879908323288\n",
            "Epoch [69/70], LR: [0.08000000000000002]\n",
            "Loss: 0.08876970410346985\n",
            "Epoch [70/70], LR: [0.08000000000000002]\n",
            "Loss: 0.08801234513521194\n",
            "num exemplar sets: 80\n",
            "Exemplar means len: 80\n",
            "Reducing exemplars of class 0 to 22\n",
            "Reducing exemplars of class 1 to 22\n",
            "Reducing exemplars of class 2 to 22\n",
            "Reducing exemplars of class 3 to 22\n",
            "Reducing exemplars of class 4 to 22\n",
            "Reducing exemplars of class 5 to 22\n",
            "Reducing exemplars of class 6 to 22\n",
            "Reducing exemplars of class 7 to 22\n",
            "Reducing exemplars of class 8 to 22\n",
            "Reducing exemplars of class 9 to 22\n",
            "Reducing exemplars of class 10 to 22\n",
            "Reducing exemplars of class 11 to 22\n",
            "Reducing exemplars of class 12 to 22\n",
            "Reducing exemplars of class 13 to 22\n",
            "Reducing exemplars of class 14 to 22\n",
            "Reducing exemplars of class 15 to 22\n",
            "Reducing exemplars of class 16 to 22\n",
            "Reducing exemplars of class 17 to 22\n",
            "Reducing exemplars of class 18 to 22\n",
            "Reducing exemplars of class 19 to 22\n",
            "Reducing exemplars of class 20 to 22\n",
            "Reducing exemplars of class 21 to 22\n",
            "Reducing exemplars of class 22 to 22\n",
            "Reducing exemplars of class 23 to 22\n",
            "Reducing exemplars of class 24 to 22\n",
            "Reducing exemplars of class 25 to 22\n",
            "Reducing exemplars of class 26 to 22\n",
            "Reducing exemplars of class 27 to 22\n",
            "Reducing exemplars of class 28 to 22\n",
            "Reducing exemplars of class 29 to 22\n",
            "Reducing exemplars of class 30 to 22\n",
            "Reducing exemplars of class 31 to 22\n",
            "Reducing exemplars of class 32 to 22\n",
            "Reducing exemplars of class 33 to 22\n",
            "Reducing exemplars of class 34 to 22\n",
            "Reducing exemplars of class 35 to 22\n",
            "Reducing exemplars of class 36 to 22\n",
            "Reducing exemplars of class 37 to 22\n",
            "Reducing exemplars of class 38 to 22\n",
            "Reducing exemplars of class 39 to 22\n",
            "Reducing exemplars of class 40 to 22\n",
            "Reducing exemplars of class 41 to 22\n",
            "Reducing exemplars of class 42 to 22\n",
            "Reducing exemplars of class 43 to 22\n",
            "Reducing exemplars of class 44 to 22\n",
            "Reducing exemplars of class 45 to 22\n",
            "Reducing exemplars of class 46 to 22\n",
            "Reducing exemplars of class 47 to 22\n",
            "Reducing exemplars of class 48 to 22\n",
            "Reducing exemplars of class 49 to 22\n",
            "Reducing exemplars of class 50 to 22\n",
            "Reducing exemplars of class 51 to 22\n",
            "Reducing exemplars of class 52 to 22\n",
            "Reducing exemplars of class 53 to 22\n",
            "Reducing exemplars of class 54 to 22\n",
            "Reducing exemplars of class 55 to 22\n",
            "Reducing exemplars of class 56 to 22\n",
            "Reducing exemplars of class 57 to 22\n",
            "Reducing exemplars of class 58 to 22\n",
            "Reducing exemplars of class 59 to 22\n",
            "Reducing exemplars of class 60 to 22\n",
            "Reducing exemplars of class 61 to 22\n",
            "Reducing exemplars of class 62 to 22\n",
            "Reducing exemplars of class 63 to 22\n",
            "Reducing exemplars of class 64 to 22\n",
            "Reducing exemplars of class 65 to 22\n",
            "Reducing exemplars of class 66 to 22\n",
            "Reducing exemplars of class 67 to 22\n",
            "Reducing exemplars of class 68 to 22\n",
            "Reducing exemplars of class 69 to 22\n",
            "Reducing exemplars of class 70 to 22\n",
            "Reducing exemplars of class 71 to 22\n",
            "Reducing exemplars of class 72 to 22\n",
            "Reducing exemplars of class 73 to 22\n",
            "Reducing exemplars of class 74 to 22\n",
            "Reducing exemplars of class 75 to 22\n",
            "Reducing exemplars of class 76 to 22\n",
            "Reducing exemplars of class 77 to 22\n",
            "Reducing exemplars of class 78 to 22\n",
            "Reducing exemplars of class 79 to 22\n",
            "Constructing exemplar for class [80]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 22it [00:00, 276.65it/s, center_shift=0.000000, iteration=22, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Constructing exemplar for class [81]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[running kmeans]: 15it [00:00, 309.98it/s, center_shift=0.000000, iteration=15, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Constructing exemplar for class [82]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[running kmeans]: 12it [00:00, 279.94it/s, center_shift=0.000000, iteration=12, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Constructing exemplar for class [83]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[running kmeans]: 18it [00:00, 271.59it/s, center_shift=0.000000, iteration=18, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Constructing exemplar for class [84]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[running kmeans]: 14it [00:00, 265.80it/s, center_shift=0.000073, iteration=14, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Constructing exemplar for class [85]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[running kmeans]: 15it [00:00, 261.43it/s, center_shift=0.000000, iteration=15, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Constructing exemplar for class [86]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[running kmeans]: 18it [00:00, 281.33it/s, center_shift=0.000000, iteration=18, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Constructing exemplar for class [87]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[running kmeans]: 13it [00:00, 289.25it/s, center_shift=0.000000, iteration=13, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Constructing exemplar for class [88]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[running kmeans]: 13it [00:00, 271.00it/s, center_shift=0.000000, iteration=13, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Constructing exemplar for class [89]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[running kmeans]: 21it [00:00, 312.99it/s, center_shift=0.000000, iteration=21, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Validating classes ['palm_tree', 'bottle', 'man', 'mushroom', 'snail', 'tiger', 'beaver', 'skyscraper', 'wardrobe', 'train'] -> [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validating classes ['bicycle', 'plain', 'couch', 'lobster', 'lion', 'chair', 'tulip', 'television', 'skunk', 'girl'] -> [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
            "Validating classes ['bowl', 'tank', 'lawn_mower', 'snake', 'ray', 'oak_tree', 'poppy', 'castle', 'telephone', 'clock'] -> [20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
            "Validating classes ['worm', 'rabbit', 'tractor', 'cockroach', 'house', 'lamp', 'sweet_pepper', 'crab', 'beetle', 'dolphin'] -> [30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
            "Validating classes ['mouse', 'flatfish', 'pear', 'lizard', 'shark', 'orchid', 'cup', 'bus', 'sunflower', 'dinosaur'] -> [40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
            "Validating classes ['whale', 'wolf', 'woman', 'cloud', 'porcupine', 'road', 'plate', 'table', 'sea', 'seal'] -> [50, 51, 52, 53, 54, 55, 56, 57, 58, 59]\n",
            "Validating classes ['bear', 'apple', 'forest', 'streetcar', 'can', 'bed', 'crocodile', 'keyboard', 'boy', 'raccoon'] -> [60, 61, 62, 63, 64, 65, 66, 67, 68, 69]\n",
            "Validating classes ['willow_tree', 'maple_tree', 'orange', 'rocket', 'spider', 'chimpanzee', 'cattle', 'kangaroo', 'bridge', 'fox'] -> [70, 71, 72, 73, 74, 75, 76, 77, 78, 79]\n",
            "Validating classes ['butterfly', 'baby', 'elephant', 'shrew', 'pine_tree', 'squirrel', 'mountain', 'caterpillar', 'bee', 'camel'] -> [80, 81, 82, 83, 84, 85, 86, 87, 88, 89]\n",
            "Accuracy: 0.4162222222222222\n",
            "BATCH [9]\n",
            "Training on ['leopard', 'trout', 'turtle', 'rose', 'aquarium_fish', 'possum', 'hamster', 'otter', 'motorcycle', 'pickup_truck'] -> [90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
            "calculating output old classes\n",
            "Known classes [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
            "Epoch [1/70], LR: [2.0]\n",
            "Loss: 0.1112271100282669\n",
            "Epoch [2/70], LR: [2.0]\n",
            "Loss: 0.10480250418186188\n",
            "Epoch [3/70], LR: [2.0]\n",
            "Loss: 0.10298334062099457\n",
            "Epoch [4/70], LR: [2.0]\n",
            "Loss: 0.10544799268245697\n",
            "Epoch [5/70], LR: [2.0]\n",
            "Loss: 0.10498757660388947\n",
            "Epoch [6/70], LR: [2.0]\n",
            "Loss: 0.09764405339956284\n",
            "Epoch [7/70], LR: [2.0]\n",
            "Loss: 0.09605461359024048\n",
            "Epoch [8/70], LR: [2.0]\n",
            "Loss: 0.10079596936702728\n",
            "Epoch [9/70], LR: [2.0]\n",
            "Loss: 0.10009336471557617\n",
            "Epoch [10/70], LR: [2.0]\n",
            "Loss: 0.10383393615484238\n",
            "Epoch [11/70], LR: [2.0]\n",
            "Loss: 0.09741782397031784\n",
            "Epoch [12/70], LR: [2.0]\n",
            "Loss: 0.10586917400360107\n",
            "Epoch [13/70], LR: [2.0]\n",
            "Loss: 0.10821166634559631\n",
            "Epoch [14/70], LR: [2.0]\n",
            "Loss: 0.09875483065843582\n",
            "Epoch [15/70], LR: [2.0]\n",
            "Loss: 0.1072232574224472\n",
            "Epoch [16/70], LR: [2.0]\n",
            "Loss: 0.10166844725608826\n",
            "Epoch [17/70], LR: [2.0]\n",
            "Loss: 0.1056271344423294\n",
            "Epoch [18/70], LR: [2.0]\n",
            "Loss: 0.09459897875785828\n",
            "Epoch [19/70], LR: [2.0]\n",
            "Loss: 0.09554611891508102\n",
            "Epoch [20/70], LR: [2.0]\n",
            "Loss: 0.10232590138912201\n",
            "Epoch [21/70], LR: [2.0]\n",
            "Loss: 0.09613054990768433\n",
            "Epoch [22/70], LR: [2.0]\n",
            "Loss: 0.09417503327131271\n",
            "Epoch [23/70], LR: [2.0]\n",
            "Loss: 0.09664351493120193\n",
            "Epoch [24/70], LR: [2.0]\n",
            "Loss: 0.09172310680150986\n",
            "Epoch [25/70], LR: [2.0]\n",
            "Loss: 0.09596189856529236\n",
            "Epoch [26/70], LR: [2.0]\n",
            "Loss: 0.10368655622005463\n",
            "Epoch [27/70], LR: [2.0]\n",
            "Loss: 0.09472909569740295\n",
            "Epoch [28/70], LR: [2.0]\n",
            "Loss: 0.09901733696460724\n",
            "Epoch [29/70], LR: [2.0]\n",
            "Loss: 0.09431186318397522\n",
            "Epoch [30/70], LR: [2.0]\n",
            "Loss: 0.09558127820491791\n",
            "Epoch [31/70], LR: [2.0]\n",
            "Loss: 0.1018143743276596\n",
            "Epoch [32/70], LR: [2.0]\n",
            "Loss: 0.10204412043094635\n",
            "Epoch [33/70], LR: [2.0]\n",
            "Loss: 0.10333739966154099\n",
            "Epoch [34/70], LR: [2.0]\n",
            "Loss: 0.10622964054346085\n",
            "Epoch [35/70], LR: [2.0]\n",
            "Loss: 0.10109139233827591\n",
            "Epoch [36/70], LR: [2.0]\n",
            "Loss: 0.09722525626420975\n",
            "Epoch [37/70], LR: [2.0]\n",
            "Loss: 0.09672082960605621\n",
            "Epoch [38/70], LR: [2.0]\n",
            "Loss: 0.10563737154006958\n",
            "Epoch [39/70], LR: [2.0]\n",
            "Loss: 0.09563992917537689\n",
            "Epoch [40/70], LR: [2.0]\n",
            "Loss: 0.09737842530012131\n",
            "Epoch [41/70], LR: [2.0]\n",
            "Loss: 0.10248859971761703\n",
            "Epoch [42/70], LR: [2.0]\n",
            "Loss: 0.10257851332426071\n",
            "Epoch [43/70], LR: [2.0]\n",
            "Loss: 0.09538866579532623\n",
            "Epoch [44/70], LR: [2.0]\n",
            "Loss: 0.09559722244739532\n",
            "Epoch [45/70], LR: [2.0]\n",
            "Loss: 0.09660478681325912\n",
            "Epoch [46/70], LR: [2.0]\n",
            "Loss: 0.09369418770074844\n",
            "Epoch [47/70], LR: [2.0]\n",
            "Loss: 0.09302829205989838\n",
            "Epoch [48/70], LR: [0.4]\n",
            "Loss: 0.09178638458251953\n",
            "Epoch [49/70], LR: [0.4]\n",
            "Loss: 0.09330934286117554\n",
            "Epoch [50/70], LR: [0.4]\n",
            "Loss: 0.0899677723646164\n",
            "Epoch [51/70], LR: [0.4]\n",
            "Loss: 0.09435323625802994\n",
            "Epoch [52/70], LR: [0.4]\n",
            "Loss: 0.08989271521568298\n",
            "Epoch [53/70], LR: [0.4]\n",
            "Loss: 0.09255050867795944\n",
            "Epoch [54/70], LR: [0.4]\n",
            "Loss: 0.09532520920038223\n",
            "Epoch [55/70], LR: [0.4]\n",
            "Loss: 0.0887313261628151\n",
            "Epoch [56/70], LR: [0.4]\n",
            "Loss: 0.09537041932344437\n",
            "Epoch [57/70], LR: [0.4]\n",
            "Loss: 0.09751474857330322\n",
            "Epoch [58/70], LR: [0.4]\n",
            "Loss: 0.09735559672117233\n",
            "Epoch [59/70], LR: [0.4]\n",
            "Loss: 0.09183503687381744\n",
            "Epoch [60/70], LR: [0.4]\n",
            "Loss: 0.09198513627052307\n",
            "Epoch [61/70], LR: [0.4]\n",
            "Loss: 0.09262235462665558\n",
            "Epoch [62/70], LR: [0.4]\n",
            "Loss: 0.09842386841773987\n",
            "Epoch [63/70], LR: [0.4]\n",
            "Loss: 0.0893985852599144\n",
            "Epoch [64/70], LR: [0.08000000000000002]\n",
            "Loss: 0.09285511076450348\n",
            "Epoch [65/70], LR: [0.08000000000000002]\n",
            "Loss: 0.09518588334321976\n",
            "Epoch [66/70], LR: [0.08000000000000002]\n",
            "Loss: 0.09101750701665878\n",
            "Epoch [67/70], LR: [0.08000000000000002]\n",
            "Loss: 0.10453986376523972\n",
            "Epoch [68/70], LR: [0.08000000000000002]\n",
            "Loss: 0.08503583818674088\n",
            "Epoch [69/70], LR: [0.08000000000000002]\n",
            "Loss: 0.08808469772338867\n",
            "Epoch [70/70], LR: [0.08000000000000002]\n",
            "Loss: 0.09848645329475403\n",
            "num exemplar sets: 90\n",
            "Exemplar means len: 90\n",
            "Reducing exemplars of class 0 to 20\n",
            "Reducing exemplars of class 1 to 20\n",
            "Reducing exemplars of class 2 to 20\n",
            "Reducing exemplars of class 3 to 20\n",
            "Reducing exemplars of class 4 to 20\n",
            "Reducing exemplars of class 5 to 20\n",
            "Reducing exemplars of class 6 to 20\n",
            "Reducing exemplars of class 7 to 20\n",
            "Reducing exemplars of class 8 to 20\n",
            "Reducing exemplars of class 9 to 20\n",
            "Reducing exemplars of class 10 to 20\n",
            "Reducing exemplars of class 11 to 20\n",
            "Reducing exemplars of class 12 to 20\n",
            "Reducing exemplars of class 13 to 20\n",
            "Reducing exemplars of class 14 to 20\n",
            "Reducing exemplars of class 15 to 20\n",
            "Reducing exemplars of class 16 to 20\n",
            "Reducing exemplars of class 17 to 20\n",
            "Reducing exemplars of class 18 to 20\n",
            "Reducing exemplars of class 19 to 20\n",
            "Reducing exemplars of class 20 to 20\n",
            "Reducing exemplars of class 21 to 20\n",
            "Reducing exemplars of class 22 to 20\n",
            "Reducing exemplars of class 23 to 20\n",
            "Reducing exemplars of class 24 to 20\n",
            "Reducing exemplars of class 25 to 20\n",
            "Reducing exemplars of class 26 to 20\n",
            "Reducing exemplars of class 27 to 20\n",
            "Reducing exemplars of class 28 to 20\n",
            "Reducing exemplars of class 29 to 20\n",
            "Reducing exemplars of class 30 to 20\n",
            "Reducing exemplars of class 31 to 20\n",
            "Reducing exemplars of class 32 to 20\n",
            "Reducing exemplars of class 33 to 20\n",
            "Reducing exemplars of class 34 to 20\n",
            "Reducing exemplars of class 35 to 20\n",
            "Reducing exemplars of class 36 to 20\n",
            "Reducing exemplars of class 37 to 20\n",
            "Reducing exemplars of class 38 to 20\n",
            "Reducing exemplars of class 39 to 20\n",
            "Reducing exemplars of class 40 to 20\n",
            "Reducing exemplars of class 41 to 20\n",
            "Reducing exemplars of class 42 to 20\n",
            "Reducing exemplars of class 43 to 20\n",
            "Reducing exemplars of class 44 to 20\n",
            "Reducing exemplars of class 45 to 20\n",
            "Reducing exemplars of class 46 to 20\n",
            "Reducing exemplars of class 47 to 20\n",
            "Reducing exemplars of class 48 to 20\n",
            "Reducing exemplars of class 49 to 20\n",
            "Reducing exemplars of class 50 to 20\n",
            "Reducing exemplars of class 51 to 20\n",
            "Reducing exemplars of class 52 to 20\n",
            "Reducing exemplars of class 53 to 20\n",
            "Reducing exemplars of class 54 to 20\n",
            "Reducing exemplars of class 55 to 20\n",
            "Reducing exemplars of class 56 to 20\n",
            "Reducing exemplars of class 57 to 20\n",
            "Reducing exemplars of class 58 to 20\n",
            "Reducing exemplars of class 59 to 20\n",
            "Reducing exemplars of class 60 to 20\n",
            "Reducing exemplars of class 61 to 20\n",
            "Reducing exemplars of class 62 to 20\n",
            "Reducing exemplars of class 63 to 20\n",
            "Reducing exemplars of class 64 to 20\n",
            "Reducing exemplars of class 65 to 20\n",
            "Reducing exemplars of class 66 to 20\n",
            "Reducing exemplars of class 67 to 20\n",
            "Reducing exemplars of class 68 to 20\n",
            "Reducing exemplars of class 69 to 20\n",
            "Reducing exemplars of class 70 to 20\n",
            "Reducing exemplars of class 71 to 20\n",
            "Reducing exemplars of class 72 to 20\n",
            "Reducing exemplars of class 73 to 20\n",
            "Reducing exemplars of class 74 to 20\n",
            "Reducing exemplars of class 75 to 20\n",
            "Reducing exemplars of class 76 to 20\n",
            "Reducing exemplars of class 77 to 20\n",
            "Reducing exemplars of class 78 to 20\n",
            "Reducing exemplars of class 79 to 20\n",
            "Reducing exemplars of class 80 to 20\n",
            "Reducing exemplars of class 81 to 20\n",
            "Reducing exemplars of class 82 to 20\n",
            "Reducing exemplars of class 83 to 20\n",
            "Reducing exemplars of class 84 to 20\n",
            "Reducing exemplars of class 85 to 20\n",
            "Reducing exemplars of class 86 to 20\n",
            "Reducing exemplars of class 87 to 20\n",
            "Reducing exemplars of class 88 to 20\n",
            "Reducing exemplars of class 89 to 20\n",
            "Constructing exemplar for class [90]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 12it [00:00, 280.30it/s, center_shift=0.000000, iteration=12, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Constructing exemplar for class [91]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[running kmeans]: 24it [00:00, 310.76it/s, center_shift=0.000000, iteration=24, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Constructing exemplar for class [92]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[running kmeans]: 12it [00:00, 278.93it/s, center_shift=0.000000, iteration=12, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Constructing exemplar for class [93]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[running kmeans]: 20it [00:00, 283.75it/s, center_shift=0.000000, iteration=20, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Constructing exemplar for class [94]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[running kmeans]: 29it [00:00, 268.67it/s, center_shift=0.000000, iteration=29, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Matteo merda\n",
            "Constructing exemplar for class [95]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 11it [00:00, 301.17it/s, center_shift=0.000000, iteration=11, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Constructing exemplar for class [96]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[running kmeans]: 16it [00:00, 275.66it/s, center_shift=0.000000, iteration=16, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Constructing exemplar for class [97]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[running kmeans]: 16it [00:00, 289.82it/s, center_shift=0.000000, iteration=16, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Constructing exemplar for class [98]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[running kmeans]: 27it [00:00, 294.09it/s, center_shift=0.000000, iteration=27, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Constructing exemplar for class [99]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[running kmeans]: 30it [00:00, 333.73it/s, center_shift=0.000000, iteration=30, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cuda:0..\n",
            "torch.Size([10, 64])\n",
            "torch.Size([1, 64])\n",
            "Distances size: torch.Size([10])\n",
            "Matteo merda\n",
            "Validating classes ['palm_tree', 'bottle', 'man', 'mushroom', 'snail', 'tiger', 'beaver', 'skyscraper', 'wardrobe', 'train'] -> [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validating classes ['bicycle', 'plain', 'couch', 'lobster', 'lion', 'chair', 'tulip', 'television', 'skunk', 'girl'] -> [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
            "Validating classes ['bowl', 'tank', 'lawn_mower', 'snake', 'ray', 'oak_tree', 'poppy', 'castle', 'telephone', 'clock'] -> [20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
            "Validating classes ['worm', 'rabbit', 'tractor', 'cockroach', 'house', 'lamp', 'sweet_pepper', 'crab', 'beetle', 'dolphin'] -> [30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
            "Validating classes ['mouse', 'flatfish', 'pear', 'lizard', 'shark', 'orchid', 'cup', 'bus', 'sunflower', 'dinosaur'] -> [40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
            "Validating classes ['whale', 'wolf', 'woman', 'cloud', 'porcupine', 'road', 'plate', 'table', 'sea', 'seal'] -> [50, 51, 52, 53, 54, 55, 56, 57, 58, 59]\n",
            "Validating classes ['bear', 'apple', 'forest', 'streetcar', 'can', 'bed', 'crocodile', 'keyboard', 'boy', 'raccoon'] -> [60, 61, 62, 63, 64, 65, 66, 67, 68, 69]\n",
            "Validating classes ['willow_tree', 'maple_tree', 'orange', 'rocket', 'spider', 'chimpanzee', 'cattle', 'kangaroo', 'bridge', 'fox'] -> [70, 71, 72, 73, 74, 75, 76, 77, 78, 79]\n",
            "Validating classes ['butterfly', 'baby', 'elephant', 'shrew', 'pine_tree', 'squirrel', 'mountain', 'caterpillar', 'bee', 'camel'] -> [80, 81, 82, 83, 84, 85, 86, 87, 88, 89]\n",
            "Validating classes ['leopard', 'trout', 'turtle', 'rose', 'aquarium_fish', 'possum', 'hamster', 'otter', 'motorcycle', 'pickup_truck'] -> [90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
            "Accuracy: 0.4043\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkq_p07mdhDp",
        "colab_type": "text"
      },
      "source": [
        "TRAINING AND VALIDATE ICARL \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-3lYRZhdliE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "68814c7f-9806-4904-bbf5-89a8ca7134cb"
      },
      "source": [
        "net=iCarlNet(n_classes=100)\n",
        "net.to(DEVICE)\n",
        "accuracies = []\n",
        "for i, train_dataset in enumerate(train_datasets):\n",
        "  torch.cuda.empty_cache()\n",
        "  print(f\"BATCH [{i}]\")\n",
        "  print(f\"Training on {train_dataset.labels} -> {train_dataset.labels_to_int}\")\n",
        "  net.train()\n",
        "  net.update_representation(copy.deepcopy(train_dataset))\n",
        "  #net.update_representation_using_cross_entropy_and_kl(copy.deepcopy(train_dataset))\n",
        "\n",
        "  m = int(K/((i+1)*10))\n",
        "  # net.compute_means(train_dataset.transform)\n",
        "  net.reduce_exemplar_sets(m)\n",
        "  for data_per_label in train_dataset.data_per_label:\n",
        "    print(f\"Constructing exemplar for class [{data_per_label[0][1]}]\")\n",
        "    # net.construct_exemplar_set(data_per_label,m,train_dataset.transform)\n",
        "    net.construct_exemplar_set_with_class_mean(data_per_label,m,train_dataset.transform)\n",
        "    # net.construct_examplar_set_random(data_per_label,m,train_dataset.transform)\n",
        "  net.compute_means(train_dataset.transform)\n",
        "  #net.compute_exemplar_list_knn(train_dataset.transform)\n",
        "  net.eval()\n",
        "  corrects = 0\n",
        "  total = 0\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    for num in range(i+1):\n",
        "      print(f\"Validating classes {test_datasets[num].labels} -> {test_datasets[num].labels_to_int}\")\n",
        "      test_dataloader = DataLoader(test_datasets[num], batch_size=BATCH_SIZE, num_workers=4, shuffle = True)\n",
        "      for _, images, labels in test_dataloader:\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "        # classify using NME\n",
        "        #preds = torch.stack(net.KNN_classify(images,100)).cuda()\n",
        "        #preds=torch.stack(net.classify_without_mean_cosine_similarity(images)).cuda()\n",
        "        preds = torch.stack(net.classify_without_mean(images)).cuda()\n",
        "        #preds=net.classifierMlp(images)\n",
        "        # outputs = net(images)\n",
        "        # _, preds = torch.max(outputs.data, 1)\n",
        "        # Update Corrects\n",
        "        corrects += torch.sum(preds == labels.data).data.item()\n",
        "        total += len(images)\n",
        "    torch.cuda.empty_cache()\n",
        "    # Calculate Accuracy\n",
        "    accuracy = corrects / float(total)\n",
        "    accuracies.append(accuracy)\n",
        "    print(f\"Accuracy: {accuracy}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BATCH [0]\n",
            "Training on ['palm_tree', 'bottle', 'man', 'mushroom', 'snail', 'tiger', 'beaver', 'skyscraper', 'wardrobe', 'train', 'bicycle', 'plain', 'couch', 'lobster', 'lion', 'chair', 'tulip', 'television', 'skunk', 'girl', 'bowl', 'tank', 'lawn_mower', 'snake', 'ray', 'oak_tree', 'poppy', 'castle', 'telephone', 'clock', 'worm', 'rabbit', 'tractor', 'cockroach', 'house', 'lamp', 'sweet_pepper', 'crab', 'beetle', 'dolphin', 'mouse', 'flatfish', 'pear', 'lizard', 'shark', 'orchid', 'cup', 'bus', 'sunflower', 'dinosaur', 'whale', 'wolf', 'woman', 'cloud', 'porcupine', 'road', 'plate', 'table', 'sea', 'seal', 'bear', 'apple', 'forest', 'streetcar', 'can', 'bed', 'crocodile', 'keyboard', 'boy', 'raccoon', 'willow_tree', 'maple_tree', 'orange', 'rocket', 'spider', 'chimpanzee', 'cattle', 'kangaroo', 'bridge', 'fox', 'butterfly', 'baby', 'elephant', 'shrew', 'pine_tree', 'squirrel', 'mountain', 'caterpillar', 'bee', 'camel', 'leopard', 'trout', 'turtle', 'rose', 'aquarium_fish', 'possum', 'hamster', 'otter', 'motorcycle', 'pickup_truck'] -> [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
            "Known classes [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
            "Epoch [1/70], LR: [2.0]\n",
            "Loss: 0.051244352012872696\n",
            "Epoch [2/70], LR: [2.0]\n",
            "Loss: 0.04704379290342331\n",
            "Epoch [3/70], LR: [2.0]\n",
            "Loss: 0.04729402810335159\n",
            "Epoch [4/70], LR: [2.0]\n",
            "Loss: 0.044824935495853424\n",
            "Epoch [5/70], LR: [2.0]\n",
            "Loss: 0.045090630650520325\n",
            "Epoch [6/70], LR: [2.0]\n",
            "Loss: 0.03886314108967781\n",
            "Epoch [7/70], LR: [2.0]\n",
            "Loss: 0.0358746275305748\n",
            "Epoch [8/70], LR: [2.0]\n",
            "Loss: 0.03717456012964249\n",
            "Epoch [9/70], LR: [2.0]\n",
            "Loss: 0.03322029113769531\n",
            "Epoch [10/70], LR: [2.0]\n",
            "Loss: 0.02770964987576008\n",
            "Epoch [11/70], LR: [2.0]\n",
            "Loss: 0.0319095179438591\n",
            "Epoch [12/70], LR: [2.0]\n",
            "Loss: 0.027348922565579414\n",
            "Epoch [13/70], LR: [2.0]\n",
            "Loss: 0.029767589643597603\n",
            "Epoch [14/70], LR: [2.0]\n",
            "Loss: 0.026563184335827827\n",
            "Epoch [15/70], LR: [2.0]\n",
            "Loss: 0.02678765542805195\n",
            "Epoch [16/70], LR: [2.0]\n",
            "Loss: 0.023264169692993164\n",
            "Epoch [17/70], LR: [2.0]\n",
            "Loss: 0.027909765020012856\n",
            "Epoch [18/70], LR: [2.0]\n",
            "Loss: 0.024788763374090195\n",
            "Epoch [19/70], LR: [2.0]\n",
            "Loss: 0.02653423510491848\n",
            "Epoch [20/70], LR: [2.0]\n",
            "Loss: 0.02271735668182373\n",
            "Epoch [21/70], LR: [2.0]\n",
            "Loss: 0.024114316329360008\n",
            "Epoch [22/70], LR: [2.0]\n",
            "Loss: 0.02381265163421631\n",
            "Epoch [23/70], LR: [2.0]\n",
            "Loss: 0.026436835527420044\n",
            "Epoch [24/70], LR: [2.0]\n",
            "Loss: 0.020725704729557037\n",
            "Epoch [25/70], LR: [2.0]\n",
            "Loss: 0.020715495571494102\n",
            "Epoch [26/70], LR: [2.0]\n",
            "Loss: 0.020452378317713737\n",
            "Epoch [27/70], LR: [2.0]\n",
            "Loss: 0.023202668875455856\n",
            "Epoch [28/70], LR: [2.0]\n",
            "Loss: 0.02130303345620632\n",
            "Epoch [29/70], LR: [2.0]\n",
            "Loss: 0.02320454828441143\n",
            "Epoch [30/70], LR: [2.0]\n",
            "Loss: 0.027469253167510033\n",
            "Epoch [31/70], LR: [2.0]\n",
            "Loss: 0.022398516535758972\n",
            "Epoch [32/70], LR: [2.0]\n",
            "Loss: 0.02112642303109169\n",
            "Epoch [33/70], LR: [2.0]\n",
            "Loss: 0.02204546518623829\n",
            "Epoch [34/70], LR: [2.0]\n",
            "Loss: 0.017082344740629196\n",
            "Epoch [35/70], LR: [2.0]\n",
            "Loss: 0.027901893481612206\n",
            "Epoch [36/70], LR: [2.0]\n",
            "Loss: 0.022871242836117744\n",
            "Epoch [37/70], LR: [2.0]\n",
            "Loss: 0.021120617166161537\n",
            "Epoch [38/70], LR: [2.0]\n",
            "Loss: 0.023058485239744186\n",
            "Epoch [39/70], LR: [2.0]\n",
            "Loss: 0.019479604437947273\n",
            "Epoch [40/70], LR: [2.0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-64adcad0c1e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training on {train_dataset.labels} -> {train_dataset.labels_to_int}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_representation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0;31m#net.update_representation_using_cross_entropy_and_kl(copy.deepcopy(train_dataset))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-761ea1dee669>\u001b[0m in \u001b[0;36mupdate_representation\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    287\u001b[0m       \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEulG_cnchiH",
        "colab_type": "text"
      },
      "source": [
        "Train on all CIFAR100 in one shot, accuracy: **0.6785**, **0.68**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4NhX3N5cdm0",
        "colab_type": "text"
      },
      "source": [
        "**Plot of accuracy over learned classes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9ZTpRJEcc3m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "beef9fb0-aecc-4954-a2b3-c65c99fb7a98"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Learned classes')\n",
        "plt.plot(np.arange(10, 110, 10), accuracies)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vwt2ztUXFaH",
        "colab_type": "text"
      },
      "source": [
        "# **Learning without Fortgetting (LwF) model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ie3wtV4DTdu",
        "colab_type": "text"
      },
      "source": [
        "**LwF**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnA3s8D9rItr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class LwF(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        self.total_num_classes = n_classes\n",
        "        self.known_classes = 0\n",
        "        self.list_known_classes=[]\n",
        "        self.exemplar_sets = []\n",
        "        self.flag_mean = True\n",
        "        self.exemplar_means = []\n",
        "\n",
        "        # We take a standard ResNet and Extend it\n",
        "        super(LwF, self).__init__()\n",
        "        self.extractor = resnet32()\n",
        "        self.fully_connected = nn.Linear(self.extractor.out_dim, 0, bias=True)\n",
        "        torch.nn.init.xavier_uniform_(self.fully_connected.weight)\n",
        "\n",
        "        self.fully_connected.bias.data.fill_(0.01)\n",
        "        self.loss=nn.BCEWithLogitsLoss()\n",
        "        self.optimizer = optim.SGD(self.parameters(), lr=2.0,weight_decay=0.00001)\n",
        "        self.scheduler=MultiStepLR(self.optimizer,[47,63],gamma=GAMMA)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # X: input data\n",
        "        self.extractor.to(DEVICE)\n",
        "        self.fully_connected.to(DEVICE)\n",
        "        x = self.extractor(x)\n",
        "        x = self.fully_connected(x)\n",
        "        return x\n",
        "\n",
        "    def increment_classes(self, classes_to_add):          # increments the number of classes we are using\n",
        "      n_classes_to_add = len(classes_to_add)\n",
        "      self.list_known_classes+=classes_to_add             #add the new classes\n",
        "      print(f\"Known classes {self.list_known_classes}\")\n",
        "      weight = self.fully_connected.weight.data\n",
        "      feature_size = self.fully_connected.in_features\n",
        "      old_num_classes = self.fully_connected.out_features\n",
        "      self.fully_connected = nn.Linear(\n",
        "          feature_size, old_num_classes+n_classes_to_add, bias = True)\n",
        "      self.fully_connected.weight.data[:old_num_classes] = weight\n",
        "\n",
        "    def update_representation(self, dataset):             \n",
        "        # self.combine_dataset_with_exemplars(dataset)\n",
        "        # self.flag_mean = True\n",
        "        classes_to_idx = dataset.labels_to_int\n",
        "        new_classes = [cls for cls in classes_to_idx if cls not in self.list_known_classes] #gets indexes of new classes only\n",
        "\n",
        "        train_data_loader = DataLoader(\n",
        "            dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "        \n",
        "        preds_old_net = []\n",
        "        #preds_old_net = torch.zeros(len(dataset), self.num_classes).cuda()\n",
        "        \n",
        "        if self.known_classes > 0:\n",
        "\n",
        "          self.eval()\n",
        "          logits_old_net = torch.zeros(len(dataset.data), self.known_classes).cuda()\n",
        "          with torch.no_grad():\n",
        "            for indices, images, labels in train_data_loader:\n",
        "              images = images.to(DEVICE)\n",
        "              g = self.forward(images)\n",
        "              sigmoid = torch.nn.Sigmoid()\n",
        "              logits_old_net[indices] = sigmoid(g)\n",
        "\n",
        "          torch.cuda.empty_cache()\n",
        "\n",
        "        self.increment_classes(new_classes)\n",
        "        \n",
        "        optimizer = optim.SGD(self.parameters(), lr=2.0,weight_decay=0.00001, momentum = 0.9)\n",
        "        scheduler = MultiStepLR(optimizer,[47,63],gamma=GAMMA)\n",
        "        self.train()\n",
        "\n",
        "        eye = torch.eye(self.known_classes+len(new_classes))\n",
        "\n",
        "        for epoch in range(NUM_EPOCHS):\n",
        "          print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], LR: {scheduler.get_last_lr()}\")\n",
        "          i=0\n",
        "          for indices, images, labels in train_data_loader:\n",
        "            images = images.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "            indices = indices.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            output = self.forward(images)\n",
        "\n",
        "            if self.known_classes==0:\n",
        "              labels_one_hot_new_classes = []\n",
        "              for label in labels:\n",
        "                labels_one_hot_new_classes.append(eye[label])\n",
        "              labels_one_hot_new_classes = torch.stack(labels_one_hot_new_classes).cuda()\n",
        "              loss=self.loss(output,labels_one_hot_new_classes)\n",
        "              loss.backward()\n",
        "            if self.known_classes > 0:\n",
        "              labels_one_hot_new_classes = eye[:, self.known_classes:]\n",
        " \n",
        "              labels_one_hot = []\n",
        "              for label in labels:\n",
        "                labels_one_hot.append(labels_one_hot_new_classes[label])\n",
        "              labels_one_hot = torch.stack(labels_one_hot).cuda()\n",
        "              logits = logits_old_net[indices].cuda()\n",
        "              labels_concatenate=torch.cat((logits,labels_one_hot),dim=1)\n",
        "              loss=self.loss(output,labels_concatenate)\n",
        "              loss.backward()\n",
        "            optimizer.step()\n",
        "            i+=1\n",
        "          torch.cuda.empty_cache()\n",
        "          print(f\"Loss: {loss.item()}\")\n",
        "          scheduler.step() \n",
        "        self.known_classes += len(new_classes)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1TeLZSGXj8e",
        "colab_type": "text"
      },
      "source": [
        "**Training LwF**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulrc98yTDaDD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "996be12a-7dd6-47ad-f3a3-df5e21a21344"
      },
      "source": [
        "net = LwF(n_classes=100)\n",
        "net.to(DEVICE)\n",
        "\n",
        "for i, train_dataset in enumerate(train_datasets):\n",
        "  torch.cuda.empty_cache()\n",
        "  print(f\"BATCH [{i}]\")\n",
        "  print(f\"Training on {train_dataset.labels} -> {train_dataset.labels_to_int}\")\n",
        "  net.train()\n",
        "  net.update_representation(copy.deepcopy(train_dataset))\n",
        "\n",
        "  net.eval()\n",
        "  corrects = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "    for num in range(i+1):\n",
        "      print(f\"Validating classes {test_datasets[num].labels} -> {test_datasets[num].labels_to_int}\")\n",
        "      test_dataloader = DataLoader(test_datasets[num], batch_size=BATCH_SIZE, num_workers=4, shuffle = True)\n",
        "      for _, images, labels in test_dataloader:\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "        outputs = net(images)\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "        # Update Corrects\n",
        "        corrects += torch.sum(preds == labels.data).data.item()\n",
        "        total += len(images)\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    # Calculate Accuracy\n",
        "    accuracy = corrects / float(total)\n",
        "    print(f\"Accuracy: {accuracy}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BATCH [0]\n",
            "Training on ['palm_tree', 'bottle', 'man', 'mushroom', 'snail', 'tiger', 'beaver', 'skyscraper', 'wardrobe', 'train'] -> [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "Known classes [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "Epoch [1/70], LR: [2.0]\n",
            "Loss: 0.33715981245040894\n",
            "Epoch [2/70], LR: [2.0]\n",
            "Loss: 0.31833168864250183\n",
            "Epoch [3/70], LR: [2.0]\n",
            "Loss: 0.2927075922489166\n",
            "Epoch [4/70], LR: [2.0]\n",
            "Loss: 0.26772040128707886\n",
            "Epoch [5/70], LR: [2.0]\n",
            "Loss: 0.2996297776699066\n",
            "Epoch [6/70], LR: [2.0]\n",
            "Loss: 0.28331801295280457\n",
            "Epoch [7/70], LR: [2.0]\n",
            "Loss: 0.34404587745666504\n",
            "Epoch [8/70], LR: [2.0]\n",
            "Loss: 0.2553049623966217\n",
            "Epoch [9/70], LR: [2.0]\n",
            "Loss: 0.3227398991584778\n",
            "Epoch [10/70], LR: [2.0]\n",
            "Loss: 0.2415180653333664\n",
            "Epoch [11/70], LR: [2.0]\n",
            "Loss: 0.29381632804870605\n",
            "Epoch [12/70], LR: [2.0]\n",
            "Loss: 0.2299620360136032\n",
            "Epoch [13/70], LR: [2.0]\n",
            "Loss: 0.28154703974723816\n",
            "Epoch [14/70], LR: [2.0]\n",
            "Loss: 0.3108881711959839\n",
            "Epoch [15/70], LR: [2.0]\n",
            "Loss: 0.20036859810352325\n",
            "Epoch [16/70], LR: [2.0]\n",
            "Loss: 0.20122289657592773\n",
            "Epoch [17/70], LR: [2.0]\n",
            "Loss: 0.26338598132133484\n",
            "Epoch [18/70], LR: [2.0]\n",
            "Loss: 0.3983556926250458\n",
            "Epoch [19/70], LR: [2.0]\n",
            "Loss: 0.31451207399368286\n",
            "Epoch [20/70], LR: [2.0]\n",
            "Loss: 0.25193044543266296\n",
            "Epoch [21/70], LR: [2.0]\n",
            "Loss: 0.3795168101787567\n",
            "Epoch [22/70], LR: [2.0]\n",
            "Loss: 0.19975072145462036\n",
            "Epoch [23/70], LR: [2.0]\n",
            "Loss: 0.3542877733707428\n",
            "Epoch [24/70], LR: [2.0]\n",
            "Loss: 0.2685577869415283\n",
            "Epoch [25/70], LR: [2.0]\n",
            "Loss: 0.2702174186706543\n",
            "Epoch [26/70], LR: [2.0]\n",
            "Loss: 0.3157877027988434\n",
            "Epoch [27/70], LR: [2.0]\n",
            "Loss: 0.2747212052345276\n",
            "Epoch [28/70], LR: [2.0]\n",
            "Loss: 0.1304319053888321\n",
            "Epoch [29/70], LR: [2.0]\n",
            "Loss: 0.3072212338447571\n",
            "Epoch [30/70], LR: [2.0]\n",
            "Loss: 0.17147047817707062\n",
            "Epoch [31/70], LR: [2.0]\n",
            "Loss: 0.22076921164989471\n",
            "Epoch [32/70], LR: [2.0]\n",
            "Loss: 0.25929173827171326\n",
            "Epoch [33/70], LR: [2.0]\n",
            "Loss: 0.2261076718568802\n",
            "Epoch [34/70], LR: [2.0]\n",
            "Loss: 0.20317821204662323\n",
            "Epoch [35/70], LR: [2.0]\n",
            "Loss: 0.35337159037590027\n",
            "Epoch [36/70], LR: [2.0]\n",
            "Loss: 0.24284005165100098\n",
            "Epoch [37/70], LR: [2.0]\n",
            "Loss: 0.17841875553131104\n",
            "Epoch [38/70], LR: [2.0]\n",
            "Loss: 0.18791989982128143\n",
            "Epoch [39/70], LR: [2.0]\n",
            "Loss: 0.11132919788360596\n",
            "Epoch [40/70], LR: [2.0]\n",
            "Loss: 0.1689358651638031\n",
            "Epoch [41/70], LR: [2.0]\n",
            "Loss: 0.19748058915138245\n",
            "Epoch [42/70], LR: [2.0]\n",
            "Loss: 0.47761890292167664\n",
            "Epoch [43/70], LR: [2.0]\n",
            "Loss: 0.23486728966236115\n",
            "Epoch [44/70], LR: [2.0]\n",
            "Loss: 0.14499609172344208\n",
            "Epoch [45/70], LR: [2.0]\n",
            "Loss: 0.3152041733264923\n",
            "Epoch [46/70], LR: [2.0]\n",
            "Loss: 0.29161307215690613\n",
            "Epoch [47/70], LR: [2.0]\n",
            "Loss: 0.24964022636413574\n",
            "Epoch [48/70], LR: [0.4]\n",
            "Loss: 0.061327408999204636\n",
            "Epoch [49/70], LR: [0.4]\n",
            "Loss: 0.2258560210466385\n",
            "Epoch [50/70], LR: [0.4]\n",
            "Loss: 0.15486812591552734\n",
            "Epoch [51/70], LR: [0.4]\n",
            "Loss: 0.1627340018749237\n",
            "Epoch [52/70], LR: [0.4]\n",
            "Loss: 0.11537156254053116\n",
            "Epoch [53/70], LR: [0.4]\n",
            "Loss: 0.14921647310256958\n",
            "Epoch [54/70], LR: [0.4]\n",
            "Loss: 0.2747935950756073\n",
            "Epoch [55/70], LR: [0.4]\n",
            "Loss: 0.05233392119407654\n",
            "Epoch [56/70], LR: [0.4]\n",
            "Loss: 0.16193565726280212\n",
            "Epoch [57/70], LR: [0.4]\n",
            "Loss: 0.09409896284341812\n",
            "Epoch [58/70], LR: [0.4]\n",
            "Loss: 0.10321300476789474\n",
            "Epoch [59/70], LR: [0.4]\n",
            "Loss: 0.2183864563703537\n",
            "Epoch [60/70], LR: [0.4]\n",
            "Loss: 0.15873882174491882\n",
            "Epoch [61/70], LR: [0.4]\n",
            "Loss: 0.16968463361263275\n",
            "Epoch [62/70], LR: [0.4]\n",
            "Loss: 0.15635377168655396\n",
            "Epoch [63/70], LR: [0.4]\n",
            "Loss: 0.07038873434066772\n",
            "Epoch [64/70], LR: [0.08000000000000002]\n",
            "Loss: 0.10898899286985397\n",
            "Epoch [65/70], LR: [0.08000000000000002]\n",
            "Loss: 0.16070213913917542\n",
            "Epoch [66/70], LR: [0.08000000000000002]\n",
            "Loss: 0.13777995109558105\n",
            "Epoch [67/70], LR: [0.08000000000000002]\n",
            "Loss: 0.0761868879199028\n",
            "Epoch [68/70], LR: [0.08000000000000002]\n",
            "Loss: 0.2816978394985199\n",
            "Epoch [69/70], LR: [0.08000000000000002]\n",
            "Loss: 0.27624788880348206\n",
            "Epoch [70/70], LR: [0.08000000000000002]\n",
            "Loss: 0.09030621498823166\n",
            "Validating classes ['palm_tree', 'bottle', 'man', 'mushroom', 'snail', 'tiger', 'beaver', 'skyscraper', 'wardrobe', 'train'] -> [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "Accuracy: 0.783\n",
            "BATCH [1]\n",
            "Training on ['bicycle', 'plain', 'couch', 'lobster', 'lion', 'chair', 'tulip', 'television', 'skunk', 'girl'] -> [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
            "Known classes [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
            "Epoch [1/70], LR: [2.0]\n",
            "Loss: 0.22003474831581116\n",
            "Epoch [2/70], LR: [2.0]\n",
            "Loss: 0.22796180844306946\n",
            "Epoch [3/70], LR: [2.0]\n",
            "Loss: 0.24715135991573334\n",
            "Epoch [4/70], LR: [2.0]\n",
            "Loss: 0.2381691187620163\n",
            "Epoch [5/70], LR: [2.0]\n",
            "Loss: 0.2352771759033203\n",
            "Epoch [6/70], LR: [2.0]\n",
            "Loss: 0.24990396201610565\n",
            "Epoch [7/70], LR: [2.0]\n",
            "Loss: 0.1774834245443344\n",
            "Epoch [8/70], LR: [2.0]\n",
            "Loss: 0.20288391411304474\n",
            "Epoch [9/70], LR: [2.0]\n",
            "Loss: 0.21246619522571564\n",
            "Epoch [10/70], LR: [2.0]\n",
            "Loss: 0.17700007557868958\n",
            "Epoch [11/70], LR: [2.0]\n",
            "Loss: 0.16135595738887787\n",
            "Epoch [12/70], LR: [2.0]\n",
            "Loss: 0.23108641803264618\n",
            "Epoch [13/70], LR: [2.0]\n",
            "Loss: 0.14537940919399261\n",
            "Epoch [14/70], LR: [2.0]\n",
            "Loss: 0.24508057534694672\n",
            "Epoch [15/70], LR: [2.0]\n",
            "Loss: 0.15808641910552979\n",
            "Epoch [16/70], LR: [2.0]\n",
            "Loss: 0.18756146728992462\n",
            "Epoch [17/70], LR: [2.0]\n",
            "Loss: 0.1738535612821579\n",
            "Epoch [18/70], LR: [2.0]\n",
            "Loss: 0.2064872831106186\n",
            "Epoch [19/70], LR: [2.0]\n",
            "Loss: 0.145571768283844\n",
            "Epoch [20/70], LR: [2.0]\n",
            "Loss: 0.16885684430599213\n",
            "Epoch [21/70], LR: [2.0]\n",
            "Loss: 0.1473136842250824\n",
            "Epoch [22/70], LR: [2.0]\n",
            "Loss: 0.14262264966964722\n",
            "Epoch [23/70], LR: [2.0]\n",
            "Loss: 0.2194831669330597\n",
            "Epoch [24/70], LR: [2.0]\n",
            "Loss: 0.14285264909267426\n",
            "Epoch [25/70], LR: [2.0]\n",
            "Loss: 0.14529716968536377\n",
            "Epoch [26/70], LR: [2.0]\n",
            "Loss: 0.21261678636074066\n",
            "Epoch [27/70], LR: [2.0]\n",
            "Loss: 0.25509265065193176\n",
            "Epoch [28/70], LR: [2.0]\n",
            "Loss: 0.18462558090686798\n",
            "Epoch [29/70], LR: [2.0]\n",
            "Loss: 0.17348363995552063\n",
            "Epoch [30/70], LR: [2.0]\n",
            "Loss: 0.18792220950126648\n",
            "Epoch [31/70], LR: [2.0]\n",
            "Loss: 0.14864973723888397\n",
            "Epoch [32/70], LR: [2.0]\n",
            "Loss: 0.1410870999097824\n",
            "Epoch [33/70], LR: [2.0]\n",
            "Loss: 0.25218483805656433\n",
            "Epoch [34/70], LR: [2.0]\n",
            "Loss: 0.17706750333309174\n",
            "Epoch [35/70], LR: [2.0]\n",
            "Loss: 0.12999773025512695\n",
            "Epoch [36/70], LR: [2.0]\n",
            "Loss: 0.2599092423915863\n",
            "Epoch [37/70], LR: [2.0]\n",
            "Loss: 0.2102218121290207\n",
            "Epoch [38/70], LR: [2.0]\n",
            "Loss: 0.17686811089515686\n",
            "Epoch [39/70], LR: [2.0]\n",
            "Loss: 0.1261425018310547\n",
            "Epoch [40/70], LR: [2.0]\n",
            "Loss: 0.15125449001789093\n",
            "Epoch [41/70], LR: [2.0]\n",
            "Loss: 0.2602609097957611\n",
            "Epoch [42/70], LR: [2.0]\n",
            "Loss: 0.15571574866771698\n",
            "Epoch [43/70], LR: [2.0]\n",
            "Loss: 0.16562746465206146\n",
            "Epoch [44/70], LR: [2.0]\n",
            "Loss: 0.1780715435743332\n",
            "Epoch [45/70], LR: [2.0]\n",
            "Loss: 0.13167671859264374\n",
            "Epoch [46/70], LR: [2.0]\n",
            "Loss: 0.22377417981624603\n",
            "Epoch [47/70], LR: [2.0]\n",
            "Loss: 0.09842561185359955\n",
            "Epoch [48/70], LR: [0.4]\n",
            "Loss: 0.19228067994117737\n",
            "Epoch [49/70], LR: [0.4]\n",
            "Loss: 0.12398409098386765\n",
            "Epoch [50/70], LR: [0.4]\n",
            "Loss: 0.11984901875257492\n",
            "Epoch [51/70], LR: [0.4]\n",
            "Loss: 0.16747939586639404\n",
            "Epoch [52/70], LR: [0.4]\n",
            "Loss: 0.19891908764839172\n",
            "Epoch [53/70], LR: [0.4]\n",
            "Loss: 0.1662539541721344\n",
            "Epoch [54/70], LR: [0.4]\n",
            "Loss: 0.1958189308643341\n",
            "Epoch [55/70], LR: [0.4]\n",
            "Loss: 0.17955899238586426\n",
            "Epoch [56/70], LR: [0.4]\n",
            "Loss: 0.1699945479631424\n",
            "Epoch [57/70], LR: [0.4]\n",
            "Loss: 0.21082568168640137\n",
            "Epoch [58/70], LR: [0.4]\n",
            "Loss: 0.16223375499248505\n",
            "Epoch [59/70], LR: [0.4]\n",
            "Loss: 0.14599788188934326\n",
            "Epoch [60/70], LR: [0.4]\n",
            "Loss: 0.14409013092517853\n",
            "Epoch [61/70], LR: [0.4]\n",
            "Loss: 0.1412947028875351\n",
            "Epoch [62/70], LR: [0.4]\n",
            "Loss: 0.12982730567455292\n",
            "Epoch [63/70], LR: [0.4]\n",
            "Loss: 0.1180952787399292\n",
            "Epoch [64/70], LR: [0.08000000000000002]\n",
            "Loss: 0.19528451561927795\n",
            "Epoch [65/70], LR: [0.08000000000000002]\n",
            "Loss: 0.16305115818977356\n",
            "Epoch [66/70], LR: [0.08000000000000002]\n",
            "Loss: 0.13428418338298798\n",
            "Epoch [67/70], LR: [0.08000000000000002]\n",
            "Loss: 0.17114093899726868\n",
            "Epoch [68/70], LR: [0.08000000000000002]\n",
            "Loss: 0.15818293392658234\n",
            "Epoch [69/70], LR: [0.08000000000000002]\n",
            "Loss: 0.11708100140094757\n",
            "Epoch [70/70], LR: [0.08000000000000002]\n",
            "Loss: 0.13401077687740326\n",
            "Validating classes ['palm_tree', 'bottle', 'man', 'mushroom', 'snail', 'tiger', 'beaver', 'skyscraper', 'wardrobe', 'train'] -> [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "Validating classes ['bicycle', 'plain', 'couch', 'lobster', 'lion', 'chair', 'tulip', 'television', 'skunk', 'girl'] -> [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
            "Accuracy: 0.6125\n",
            "BATCH [2]\n",
            "Training on ['bowl', 'tank', 'lawn_mower', 'snake', 'ray', 'oak_tree', 'poppy', 'castle', 'telephone', 'clock'] -> [20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
            "Known classes [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
            "Epoch [1/70], LR: [2.0]\n",
            "Loss: 0.20444485545158386\n",
            "Epoch [2/70], LR: [2.0]\n",
            "Loss: 0.21879909932613373\n",
            "Epoch [3/70], LR: [2.0]\n",
            "Loss: 0.17735859751701355\n",
            "Epoch [4/70], LR: [2.0]\n",
            "Loss: 0.20192405581474304\n",
            "Epoch [5/70], LR: [2.0]\n",
            "Loss: 0.16904908418655396\n",
            "Epoch [6/70], LR: [2.0]\n",
            "Loss: 0.2089277058839798\n",
            "Epoch [7/70], LR: [2.0]\n",
            "Loss: 0.2475808560848236\n",
            "Epoch [8/70], LR: [2.0]\n",
            "Loss: 0.15233001112937927\n",
            "Epoch [9/70], LR: [2.0]\n",
            "Loss: 0.1490141898393631\n",
            "Epoch [10/70], LR: [2.0]\n",
            "Loss: 0.16065137088298798\n",
            "Epoch [11/70], LR: [2.0]\n",
            "Loss: 0.20618264377117157\n",
            "Epoch [12/70], LR: [2.0]\n",
            "Loss: 0.1566133350133896\n",
            "Epoch [13/70], LR: [2.0]\n",
            "Loss: 0.2220282405614853\n",
            "Epoch [14/70], LR: [2.0]\n",
            "Loss: 0.14472463726997375\n",
            "Epoch [15/70], LR: [2.0]\n",
            "Loss: 0.178595170378685\n",
            "Epoch [16/70], LR: [2.0]\n",
            "Loss: 0.19184184074401855\n",
            "Epoch [17/70], LR: [2.0]\n",
            "Loss: 0.2995177209377289\n",
            "Epoch [18/70], LR: [2.0]\n",
            "Loss: 0.17564065754413605\n",
            "Epoch [19/70], LR: [2.0]\n",
            "Loss: 0.16542239487171173\n",
            "Epoch [20/70], LR: [2.0]\n",
            "Loss: 0.17233754694461823\n",
            "Epoch [21/70], LR: [2.0]\n",
            "Loss: 0.19740106165409088\n",
            "Epoch [22/70], LR: [2.0]\n",
            "Loss: 0.1924726963043213\n",
            "Epoch [23/70], LR: [2.0]\n",
            "Loss: 0.16238999366760254\n",
            "Epoch [24/70], LR: [2.0]\n",
            "Loss: 0.1878572255373001\n",
            "Epoch [25/70], LR: [2.0]\n",
            "Loss: 0.1491716206073761\n",
            "Epoch [26/70], LR: [2.0]\n",
            "Loss: 0.17773930728435516\n",
            "Epoch [27/70], LR: [2.0]\n",
            "Loss: 0.19992978870868683\n",
            "Epoch [28/70], LR: [2.0]\n",
            "Loss: 0.1980467587709427\n",
            "Epoch [29/70], LR: [2.0]\n",
            "Loss: 0.14317090809345245\n",
            "Epoch [30/70], LR: [2.0]\n",
            "Loss: 0.1843009889125824\n",
            "Epoch [31/70], LR: [2.0]\n",
            "Loss: 0.17238660156726837\n",
            "Epoch [32/70], LR: [2.0]\n",
            "Loss: 0.1523757427930832\n",
            "Epoch [33/70], LR: [2.0]\n",
            "Loss: 0.16541340947151184\n",
            "Epoch [34/70], LR: [2.0]\n",
            "Loss: 0.19025319814682007\n",
            "Epoch [35/70], LR: [2.0]\n",
            "Loss: 0.1572955995798111\n",
            "Epoch [36/70], LR: [2.0]\n",
            "Loss: 0.13220596313476562\n",
            "Epoch [37/70], LR: [2.0]\n",
            "Loss: 0.14518071711063385\n",
            "Epoch [38/70], LR: [2.0]\n",
            "Loss: 0.193928062915802\n",
            "Epoch [39/70], LR: [2.0]\n",
            "Loss: 0.15148578584194183\n",
            "Epoch [40/70], LR: [2.0]\n",
            "Loss: 0.15872427821159363\n",
            "Epoch [41/70], LR: [2.0]\n",
            "Loss: 0.1690916270017624\n",
            "Epoch [42/70], LR: [2.0]\n",
            "Loss: 0.20071427524089813\n",
            "Epoch [43/70], LR: [2.0]\n",
            "Loss: 0.16152217984199524\n",
            "Epoch [44/70], LR: [2.0]\n",
            "Loss: 0.1249268427491188\n",
            "Epoch [45/70], LR: [2.0]\n",
            "Loss: 0.15559327602386475\n",
            "Epoch [46/70], LR: [2.0]\n",
            "Loss: 0.20632316172122955\n",
            "Epoch [47/70], LR: [2.0]\n",
            "Loss: 0.10980682820081711\n",
            "Epoch [48/70], LR: [0.4]\n",
            "Loss: 0.17725971341133118\n",
            "Epoch [49/70], LR: [0.4]\n",
            "Loss: 0.146863654255867\n",
            "Epoch [50/70], LR: [0.4]\n",
            "Loss: 0.2097369283437729\n",
            "Epoch [51/70], LR: [0.4]\n",
            "Loss: 0.12762588262557983\n",
            "Epoch [52/70], LR: [0.4]\n",
            "Loss: 0.15551024675369263\n",
            "Epoch [53/70], LR: [0.4]\n",
            "Loss: 0.11283491551876068\n",
            "Epoch [54/70], LR: [0.4]\n",
            "Loss: 0.16559118032455444\n",
            "Epoch [55/70], LR: [0.4]\n",
            "Loss: 0.15605254471302032\n",
            "Epoch [56/70], LR: [0.4]\n",
            "Loss: 0.17089691758155823\n",
            "Epoch [57/70], LR: [0.4]\n",
            "Loss: 0.22682976722717285\n",
            "Epoch [58/70], LR: [0.4]\n",
            "Loss: 0.18151964247226715\n",
            "Epoch [59/70], LR: [0.4]\n",
            "Loss: 0.12335358560085297\n",
            "Epoch [60/70], LR: [0.4]\n",
            "Loss: 0.11438550800085068\n",
            "Epoch [61/70], LR: [0.4]\n",
            "Loss: 0.1418326497077942\n",
            "Epoch [62/70], LR: [0.4]\n",
            "Loss: 0.15548193454742432\n",
            "Epoch [63/70], LR: [0.4]\n",
            "Loss: 0.20064984261989594\n",
            "Epoch [64/70], LR: [0.08000000000000002]\n",
            "Loss: 0.15033236145973206\n",
            "Epoch [65/70], LR: [0.08000000000000002]\n",
            "Loss: 0.1619449406862259\n",
            "Epoch [66/70], LR: [0.08000000000000002]\n",
            "Loss: 0.17235282063484192\n",
            "Epoch [67/70], LR: [0.08000000000000002]\n",
            "Loss: 0.12784738838672638\n",
            "Epoch [68/70], LR: [0.08000000000000002]\n",
            "Loss: 0.12116140127182007\n",
            "Epoch [69/70], LR: [0.08000000000000002]\n",
            "Loss: 0.13560643792152405\n",
            "Epoch [70/70], LR: [0.08000000000000002]\n",
            "Loss: 0.1285640448331833\n",
            "Validating classes ['palm_tree', 'bottle', 'man', 'mushroom', 'snail', 'tiger', 'beaver', 'skyscraper', 'wardrobe', 'train'] -> [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "Validating classes ['bicycle', 'plain', 'couch', 'lobster', 'lion', 'chair', 'tulip', 'television', 'skunk', 'girl'] -> [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
            "Validating classes ['bowl', 'tank', 'lawn_mower', 'snake', 'ray', 'oak_tree', 'poppy', 'castle', 'telephone', 'clock'] -> [20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
            "Accuracy: 0.521\n",
            "BATCH [3]\n",
            "Training on ['worm', 'rabbit', 'tractor', 'cockroach', 'house', 'lamp', 'sweet_pepper', 'crab', 'beetle', 'dolphin'] -> [30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
            "Known classes [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
            "Epoch [1/70], LR: [2.0]\n",
            "Loss: 0.22651724517345428\n",
            "Epoch [2/70], LR: [2.0]\n",
            "Loss: 0.2331334799528122\n",
            "Epoch [3/70], LR: [2.0]\n",
            "Loss: 0.1565379500389099\n",
            "Epoch [4/70], LR: [2.0]\n",
            "Loss: 0.17589998245239258\n",
            "Epoch [5/70], LR: [2.0]\n",
            "Loss: 0.19846688210964203\n",
            "Epoch [6/70], LR: [2.0]\n",
            "Loss: 0.21672113239765167\n",
            "Epoch [7/70], LR: [2.0]\n",
            "Loss: 0.19164703786373138\n",
            "Epoch [8/70], LR: [2.0]\n",
            "Loss: 0.15615513920783997\n",
            "Epoch [9/70], LR: [2.0]\n",
            "Loss: 0.1725722998380661\n",
            "Epoch [10/70], LR: [2.0]\n",
            "Loss: 0.1684991866350174\n",
            "Epoch [11/70], LR: [2.0]\n",
            "Loss: 0.21787872910499573\n",
            "Epoch [12/70], LR: [2.0]\n",
            "Loss: 0.19574013352394104\n",
            "Epoch [13/70], LR: [2.0]\n",
            "Loss: 0.20534539222717285\n",
            "Epoch [14/70], LR: [2.0]\n",
            "Loss: 0.19078797101974487\n",
            "Epoch [15/70], LR: [2.0]\n",
            "Loss: 0.18956860899925232\n",
            "Epoch [16/70], LR: [2.0]\n",
            "Loss: 0.17066721618175507\n",
            "Epoch [17/70], LR: [2.0]\n",
            "Loss: 0.2097703516483307\n",
            "Epoch [18/70], LR: [2.0]\n",
            "Loss: 0.2197011560201645\n",
            "Epoch [19/70], LR: [2.0]\n",
            "Loss: 0.20598502457141876\n",
            "Epoch [20/70], LR: [2.0]\n",
            "Loss: 0.1551792472600937\n",
            "Epoch [21/70], LR: [2.0]\n",
            "Loss: 0.18741224706172943\n",
            "Epoch [22/70], LR: [2.0]\n",
            "Loss: 0.18615959584712982\n",
            "Epoch [23/70], LR: [2.0]\n",
            "Loss: 0.17818786203861237\n",
            "Epoch [24/70], LR: [2.0]\n",
            "Loss: 0.24453048408031464\n",
            "Epoch [25/70], LR: [2.0]\n",
            "Loss: 0.19158688187599182\n",
            "Epoch [26/70], LR: [2.0]\n",
            "Loss: 0.17797331511974335\n",
            "Epoch [27/70], LR: [2.0]\n",
            "Loss: 0.15046679973602295\n",
            "Epoch [28/70], LR: [2.0]\n",
            "Loss: 0.17439596354961395\n",
            "Epoch [29/70], LR: [2.0]\n",
            "Loss: 0.21788959205150604\n",
            "Epoch [30/70], LR: [2.0]\n",
            "Loss: 0.24069462716579437\n",
            "Epoch [31/70], LR: [2.0]\n",
            "Loss: 0.18605034053325653\n",
            "Epoch [32/70], LR: [2.0]\n",
            "Loss: 0.18405325710773468\n",
            "Epoch [33/70], LR: [2.0]\n",
            "Loss: 0.25539278984069824\n",
            "Epoch [34/70], LR: [2.0]\n",
            "Loss: 0.1552032232284546\n",
            "Epoch [35/70], LR: [2.0]\n",
            "Loss: 0.2304374724626541\n",
            "Epoch [36/70], LR: [2.0]\n",
            "Loss: 0.19461672008037567\n",
            "Epoch [37/70], LR: [2.0]\n",
            "Loss: 0.1706770956516266\n",
            "Epoch [38/70], LR: [2.0]\n",
            "Loss: 0.23659400641918182\n",
            "Epoch [39/70], LR: [2.0]\n",
            "Loss: 0.17573252320289612\n",
            "Epoch [40/70], LR: [2.0]\n",
            "Loss: 0.16530553996562958\n",
            "Epoch [41/70], LR: [2.0]\n",
            "Loss: 0.1885206699371338\n",
            "Epoch [42/70], LR: [2.0]\n",
            "Loss: 0.15819941461086273\n",
            "Epoch [43/70], LR: [2.0]\n",
            "Loss: 0.1914694607257843\n",
            "Epoch [44/70], LR: [2.0]\n",
            "Loss: 0.17413759231567383\n",
            "Epoch [45/70], LR: [2.0]\n",
            "Loss: 0.14117644727230072\n",
            "Epoch [46/70], LR: [2.0]\n",
            "Loss: 0.16587187349796295\n",
            "Epoch [47/70], LR: [2.0]\n",
            "Loss: 0.14484581351280212\n",
            "Epoch [48/70], LR: [0.4]\n",
            "Loss: 0.17603377997875214\n",
            "Epoch [49/70], LR: [0.4]\n",
            "Loss: 0.1794859617948532\n",
            "Epoch [50/70], LR: [0.4]\n",
            "Loss: 0.18263396620750427\n",
            "Epoch [51/70], LR: [0.4]\n",
            "Loss: 0.1777055412530899\n",
            "Epoch [52/70], LR: [0.4]\n",
            "Loss: 0.20890222489833832\n",
            "Epoch [53/70], LR: [0.4]\n",
            "Loss: 0.25768548250198364\n",
            "Epoch [54/70], LR: [0.4]\n",
            "Loss: 0.16212700307369232\n",
            "Epoch [55/70], LR: [0.4]\n",
            "Loss: 0.2067069560289383\n",
            "Epoch [56/70], LR: [0.4]\n",
            "Loss: 0.18203914165496826\n",
            "Epoch [57/70], LR: [0.4]\n",
            "Loss: 0.15472634136676788\n",
            "Epoch [58/70], LR: [0.4]\n",
            "Loss: 0.15572354197502136\n",
            "Epoch [59/70], LR: [0.4]\n",
            "Loss: 0.1536683887243271\n",
            "Epoch [60/70], LR: [0.4]\n",
            "Loss: 0.16378840804100037\n",
            "Epoch [61/70], LR: [0.4]\n",
            "Loss: 0.22446326911449432\n",
            "Epoch [62/70], LR: [0.4]\n",
            "Loss: 0.20336365699768066\n",
            "Epoch [63/70], LR: [0.4]\n",
            "Loss: 0.20458436012268066\n",
            "Epoch [64/70], LR: [0.08000000000000002]\n",
            "Loss: 0.16719846427440643\n",
            "Epoch [65/70], LR: [0.08000000000000002]\n",
            "Loss: 0.1590515375137329\n",
            "Epoch [66/70], LR: [0.08000000000000002]\n",
            "Loss: 0.12311319261789322\n",
            "Epoch [67/70], LR: [0.08000000000000002]\n",
            "Loss: 0.133930966258049\n",
            "Epoch [68/70], LR: [0.08000000000000002]\n",
            "Loss: 0.14755909144878387\n",
            "Epoch [69/70], LR: [0.08000000000000002]\n",
            "Loss: 0.15994159877300262\n",
            "Epoch [70/70], LR: [0.08000000000000002]\n",
            "Loss: 0.1896132230758667\n",
            "Validating classes ['palm_tree', 'bottle', 'man', 'mushroom', 'snail', 'tiger', 'beaver', 'skyscraper', 'wardrobe', 'train'] -> [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "Validating classes ['bicycle', 'plain', 'couch', 'lobster', 'lion', 'chair', 'tulip', 'television', 'skunk', 'girl'] -> [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
            "Validating classes ['bowl', 'tank', 'lawn_mower', 'snake', 'ray', 'oak_tree', 'poppy', 'castle', 'telephone', 'clock'] -> [20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
            "Validating classes ['worm', 'rabbit', 'tractor', 'cockroach', 'house', 'lamp', 'sweet_pepper', 'crab', 'beetle', 'dolphin'] -> [30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
            "Accuracy: 0.43475\n",
            "BATCH [4]\n",
            "Training on ['mouse', 'flatfish', 'pear', 'lizard', 'shark', 'orchid', 'cup', 'bus', 'sunflower', 'dinosaur'] -> [40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
            "Known classes [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
            "Epoch [1/70], LR: [2.0]\n",
            "Loss: 0.1957620233297348\n",
            "Epoch [2/70], LR: [2.0]\n",
            "Loss: 0.2069663554430008\n",
            "Epoch [3/70], LR: [2.0]\n",
            "Loss: 0.24155834317207336\n",
            "Epoch [4/70], LR: [2.0]\n",
            "Loss: 0.17931146919727325\n",
            "Epoch [5/70], LR: [2.0]\n",
            "Loss: 0.16970759630203247\n",
            "Epoch [6/70], LR: [2.0]\n",
            "Loss: 0.19878634810447693\n",
            "Epoch [7/70], LR: [2.0]\n",
            "Loss: 0.22875399887561798\n",
            "Epoch [8/70], LR: [2.0]\n",
            "Loss: 0.1950787901878357\n",
            "Epoch [9/70], LR: [2.0]\n",
            "Loss: 0.19238726794719696\n",
            "Epoch [10/70], LR: [2.0]\n",
            "Loss: 0.1878439486026764\n",
            "Epoch [11/70], LR: [2.0]\n",
            "Loss: 0.150088369846344\n",
            "Epoch [12/70], LR: [2.0]\n",
            "Loss: 0.15857073664665222\n",
            "Epoch [13/70], LR: [2.0]\n",
            "Loss: 0.16862061619758606\n",
            "Epoch [14/70], LR: [2.0]\n",
            "Loss: 0.16408893465995789\n",
            "Epoch [15/70], LR: [2.0]\n",
            "Loss: 0.1761694997549057\n",
            "Epoch [16/70], LR: [2.0]\n",
            "Loss: 0.1740458607673645\n",
            "Epoch [17/70], LR: [2.0]\n",
            "Loss: 0.16570167243480682\n",
            "Epoch [18/70], LR: [2.0]\n",
            "Loss: 0.18063780665397644\n",
            "Epoch [19/70], LR: [2.0]\n",
            "Loss: 0.17321451008319855\n",
            "Epoch [20/70], LR: [2.0]\n",
            "Loss: 0.19432799518108368\n",
            "Epoch [21/70], LR: [2.0]\n",
            "Loss: 0.19203178584575653\n",
            "Epoch [22/70], LR: [2.0]\n",
            "Loss: 0.1863538771867752\n",
            "Epoch [23/70], LR: [2.0]\n",
            "Loss: 0.15365979075431824\n",
            "Epoch [24/70], LR: [2.0]\n",
            "Loss: 0.19195540249347687\n",
            "Epoch [25/70], LR: [2.0]\n",
            "Loss: 0.15717428922653198\n",
            "Epoch [26/70], LR: [2.0]\n",
            "Loss: 0.1748521775007248\n",
            "Epoch [27/70], LR: [2.0]\n",
            "Loss: 0.1576116532087326\n",
            "Epoch [28/70], LR: [2.0]\n",
            "Loss: 0.1886715590953827\n",
            "Epoch [29/70], LR: [2.0]\n",
            "Loss: 0.13925044238567352\n",
            "Epoch [30/70], LR: [2.0]\n",
            "Loss: 0.1817215234041214\n",
            "Epoch [31/70], LR: [2.0]\n",
            "Loss: 0.14772608876228333\n",
            "Epoch [32/70], LR: [2.0]\n",
            "Loss: 0.15705938637256622\n",
            "Epoch [33/70], LR: [2.0]\n",
            "Loss: 0.1816895604133606\n",
            "Epoch [34/70], LR: [2.0]\n",
            "Loss: 0.15175826847553253\n",
            "Epoch [35/70], LR: [2.0]\n",
            "Loss: 0.23694953322410583\n",
            "Epoch [36/70], LR: [2.0]\n",
            "Loss: 0.19639672338962555\n",
            "Epoch [37/70], LR: [2.0]\n",
            "Loss: 0.15816737711429596\n",
            "Epoch [38/70], LR: [2.0]\n",
            "Loss: 0.1945088505744934\n",
            "Epoch [39/70], LR: [2.0]\n",
            "Loss: 0.14888735115528107\n",
            "Epoch [40/70], LR: [2.0]\n",
            "Loss: 0.1547057181596756\n",
            "Epoch [41/70], LR: [2.0]\n",
            "Loss: 0.17435826361179352\n",
            "Epoch [42/70], LR: [2.0]\n",
            "Loss: 0.17244209349155426\n",
            "Epoch [43/70], LR: [2.0]\n",
            "Loss: 0.201094850897789\n",
            "Epoch [44/70], LR: [2.0]\n",
            "Loss: 0.15090233087539673\n",
            "Epoch [45/70], LR: [2.0]\n",
            "Loss: 0.17595164477825165\n",
            "Epoch [46/70], LR: [2.0]\n",
            "Loss: 0.1993861347436905\n",
            "Epoch [47/70], LR: [2.0]\n",
            "Loss: 0.1884416788816452\n",
            "Epoch [48/70], LR: [0.4]\n",
            "Loss: 0.19252517819404602\n",
            "Epoch [49/70], LR: [0.4]\n",
            "Loss: 0.1605912744998932\n",
            "Epoch [50/70], LR: [0.4]\n",
            "Loss: 0.15249276161193848\n",
            "Epoch [51/70], LR: [0.4]\n",
            "Loss: 0.16103355586528778\n",
            "Epoch [52/70], LR: [0.4]\n",
            "Loss: 0.16676746308803558\n",
            "Epoch [53/70], LR: [0.4]\n",
            "Loss: 0.15034858882427216\n",
            "Epoch [54/70], LR: [0.4]\n",
            "Loss: 0.16909220814704895\n",
            "Epoch [55/70], LR: [0.4]\n",
            "Loss: 0.20249919593334198\n",
            "Epoch [56/70], LR: [0.4]\n",
            "Loss: 0.18630695343017578\n",
            "Epoch [57/70], LR: [0.4]\n",
            "Loss: 0.15028820931911469\n",
            "Epoch [58/70], LR: [0.4]\n",
            "Loss: 0.1837044060230255\n",
            "Epoch [59/70], LR: [0.4]\n",
            "Loss: 0.13930220901966095\n",
            "Epoch [60/70], LR: [0.4]\n",
            "Loss: 0.1911238580942154\n",
            "Epoch [61/70], LR: [0.4]\n",
            "Loss: 0.1571129560470581\n",
            "Epoch [62/70], LR: [0.4]\n",
            "Loss: 0.16407357156276703\n",
            "Epoch [63/70], LR: [0.4]\n",
            "Loss: 0.16500189900398254\n",
            "Epoch [64/70], LR: [0.08000000000000002]\n",
            "Loss: 0.17075756192207336\n",
            "Epoch [65/70], LR: [0.08000000000000002]\n",
            "Loss: 0.18280448019504547\n",
            "Epoch [66/70], LR: [0.08000000000000002]\n",
            "Loss: 0.18180972337722778\n",
            "Epoch [67/70], LR: [0.08000000000000002]\n",
            "Loss: 0.1517084687948227\n",
            "Epoch [68/70], LR: [0.08000000000000002]\n",
            "Loss: 0.16758427023887634\n",
            "Epoch [69/70], LR: [0.08000000000000002]\n",
            "Loss: 0.16343282163143158\n",
            "Epoch [70/70], LR: [0.08000000000000002]\n",
            "Loss: 0.16883453726768494\n",
            "Validating classes ['palm_tree', 'bottle', 'man', 'mushroom', 'snail', 'tiger', 'beaver', 'skyscraper', 'wardrobe', 'train'] -> [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "Validating classes ['bicycle', 'plain', 'couch', 'lobster', 'lion', 'chair', 'tulip', 'television', 'skunk', 'girl'] -> [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
            "Validating classes ['bowl', 'tank', 'lawn_mower', 'snake', 'ray', 'oak_tree', 'poppy', 'castle', 'telephone', 'clock'] -> [20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
            "Validating classes ['worm', 'rabbit', 'tractor', 'cockroach', 'house', 'lamp', 'sweet_pepper', 'crab', 'beetle', 'dolphin'] -> [30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
            "Validating classes ['mouse', 'flatfish', 'pear', 'lizard', 'shark', 'orchid', 'cup', 'bus', 'sunflower', 'dinosaur'] -> [40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
            "Accuracy: 0.3576\n",
            "BATCH [5]\n",
            "Training on ['whale', 'wolf', 'woman', 'cloud', 'porcupine', 'road', 'plate', 'table', 'sea', 'seal'] -> [50, 51, 52, 53, 54, 55, 56, 57, 58, 59]\n",
            "Known classes [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]\n",
            "Epoch [1/70], LR: [2.0]\n",
            "Loss: 0.22531692683696747\n",
            "Epoch [2/70], LR: [2.0]\n",
            "Loss: 0.1898794323205948\n",
            "Epoch [3/70], LR: [2.0]\n",
            "Loss: 0.21530283987522125\n",
            "Epoch [4/70], LR: [2.0]\n",
            "Loss: 0.22692322731018066\n",
            "Epoch [5/70], LR: [2.0]\n",
            "Loss: 0.2021968960762024\n",
            "Epoch [6/70], LR: [2.0]\n",
            "Loss: 0.19277054071426392\n",
            "Epoch [7/70], LR: [2.0]\n",
            "Loss: 0.19294723868370056\n",
            "Epoch [8/70], LR: [2.0]\n",
            "Loss: 0.21773256361484528\n",
            "Epoch [9/70], LR: [2.0]\n",
            "Loss: 0.1885538399219513\n",
            "Epoch [10/70], LR: [2.0]\n",
            "Loss: 0.1767694652080536\n",
            "Epoch [11/70], LR: [2.0]\n",
            "Loss: 0.17927773296833038\n",
            "Epoch [12/70], LR: [2.0]\n",
            "Loss: 0.16072236001491547\n",
            "Epoch [13/70], LR: [2.0]\n",
            "Loss: 0.1781073659658432\n",
            "Epoch [14/70], LR: [2.0]\n",
            "Loss: 0.1775485724210739\n",
            "Epoch [15/70], LR: [2.0]\n",
            "Loss: 0.14962102472782135\n",
            "Epoch [16/70], LR: [2.0]\n",
            "Loss: 0.17639176547527313\n",
            "Epoch [17/70], LR: [2.0]\n",
            "Loss: 0.1665380597114563\n",
            "Epoch [18/70], LR: [2.0]\n",
            "Loss: 0.16038858890533447\n",
            "Epoch [19/70], LR: [2.0]\n",
            "Loss: 0.1888272762298584\n",
            "Epoch [20/70], LR: [2.0]\n",
            "Loss: 0.20826619863510132\n",
            "Epoch [21/70], LR: [2.0]\n",
            "Loss: 0.15565373003482819\n",
            "Epoch [22/70], LR: [2.0]\n",
            "Loss: 0.15521234273910522\n",
            "Epoch [23/70], LR: [2.0]\n",
            "Loss: 0.1668173223733902\n",
            "Epoch [24/70], LR: [2.0]\n",
            "Loss: 0.20521235466003418\n",
            "Epoch [25/70], LR: [2.0]\n",
            "Loss: 0.18017002940177917\n",
            "Epoch [26/70], LR: [2.0]\n",
            "Loss: 0.21538317203521729\n",
            "Epoch [27/70], LR: [2.0]\n",
            "Loss: 0.1790684461593628\n",
            "Epoch [28/70], LR: [2.0]\n",
            "Loss: 0.177625373005867\n",
            "Epoch [29/70], LR: [2.0]\n",
            "Loss: 0.20369242131710052\n",
            "Epoch [30/70], LR: [2.0]\n",
            "Loss: 0.18325616419315338\n",
            "Epoch [31/70], LR: [2.0]\n",
            "Loss: 0.15007266402244568\n",
            "Epoch [32/70], LR: [2.0]\n",
            "Loss: 0.18342244625091553\n",
            "Epoch [33/70], LR: [2.0]\n",
            "Loss: 0.1670854538679123\n",
            "Epoch [34/70], LR: [2.0]\n",
            "Loss: 0.17102552950382233\n",
            "Epoch [35/70], LR: [2.0]\n",
            "Loss: 0.19990919530391693\n",
            "Epoch [36/70], LR: [2.0]\n",
            "Loss: 0.18967598676681519\n",
            "Epoch [37/70], LR: [2.0]\n",
            "Loss: 0.16181476414203644\n",
            "Epoch [38/70], LR: [2.0]\n",
            "Loss: 0.15571899712085724\n",
            "Epoch [39/70], LR: [2.0]\n",
            "Loss: 0.16427019238471985\n",
            "Epoch [40/70], LR: [2.0]\n",
            "Loss: 0.17777621746063232\n",
            "Epoch [41/70], LR: [2.0]\n",
            "Loss: 0.17374716699123383\n",
            "Epoch [42/70], LR: [2.0]\n",
            "Loss: 0.1735631823539734\n",
            "Epoch [43/70], LR: [2.0]\n",
            "Loss: 0.21885418891906738\n",
            "Epoch [44/70], LR: [2.0]\n",
            "Loss: 0.18425971269607544\n",
            "Epoch [45/70], LR: [2.0]\n",
            "Loss: 0.21439248323440552\n",
            "Epoch [46/70], LR: [2.0]\n",
            "Loss: 0.17260275781154633\n",
            "Epoch [47/70], LR: [2.0]\n",
            "Loss: 0.1916983276605606\n",
            "Epoch [48/70], LR: [0.4]\n",
            "Loss: 0.17634516954421997\n",
            "Epoch [49/70], LR: [0.4]\n",
            "Loss: 0.20305892825126648\n",
            "Epoch [50/70], LR: [0.4]\n",
            "Loss: 0.19592979550361633\n",
            "Epoch [51/70], LR: [0.4]\n",
            "Loss: 0.1953374296426773\n",
            "Epoch [52/70], LR: [0.4]\n",
            "Loss: 0.1927928924560547\n",
            "Epoch [53/70], LR: [0.4]\n",
            "Loss: 0.17890459299087524\n",
            "Epoch [54/70], LR: [0.4]\n",
            "Loss: 0.19957353174686432\n",
            "Epoch [55/70], LR: [0.4]\n",
            "Loss: 0.18572765588760376\n",
            "Epoch [56/70], LR: [0.4]\n",
            "Loss: 0.15659746527671814\n",
            "Epoch [57/70], LR: [0.4]\n",
            "Loss: 0.18715091049671173\n",
            "Epoch [58/70], LR: [0.4]\n",
            "Loss: 0.19546979665756226\n",
            "Epoch [59/70], LR: [0.4]\n",
            "Loss: 0.1611054539680481\n",
            "Epoch [60/70], LR: [0.4]\n",
            "Loss: 0.17365354299545288\n",
            "Epoch [61/70], LR: [0.4]\n",
            "Loss: 0.15965674817562103\n",
            "Epoch [62/70], LR: [0.4]\n",
            "Loss: 0.1759617030620575\n",
            "Epoch [63/70], LR: [0.4]\n",
            "Loss: 0.1650615930557251\n",
            "Epoch [64/70], LR: [0.08000000000000002]\n",
            "Loss: 0.16175369918346405\n",
            "Epoch [65/70], LR: [0.08000000000000002]\n",
            "Loss: 0.18029361963272095\n",
            "Epoch [66/70], LR: [0.08000000000000002]\n",
            "Loss: 0.16932453215122223\n",
            "Epoch [67/70], LR: [0.08000000000000002]\n",
            "Loss: 0.1627817451953888\n",
            "Epoch [68/70], LR: [0.08000000000000002]\n",
            "Loss: 0.1766340136528015\n",
            "Epoch [69/70], LR: [0.08000000000000002]\n",
            "Loss: 0.18789924681186676\n",
            "Epoch [70/70], LR: [0.08000000000000002]\n",
            "Loss: 0.1930665522813797\n",
            "Validating classes ['palm_tree', 'bottle', 'man', 'mushroom', 'snail', 'tiger', 'beaver', 'skyscraper', 'wardrobe', 'train'] -> [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "Validating classes ['bicycle', 'plain', 'couch', 'lobster', 'lion', 'chair', 'tulip', 'television', 'skunk', 'girl'] -> [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
            "Validating classes ['bowl', 'tank', 'lawn_mower', 'snake', 'ray', 'oak_tree', 'poppy', 'castle', 'telephone', 'clock'] -> [20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
            "Validating classes ['worm', 'rabbit', 'tractor', 'cockroach', 'house', 'lamp', 'sweet_pepper', 'crab', 'beetle', 'dolphin'] -> [30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
            "Validating classes ['mouse', 'flatfish', 'pear', 'lizard', 'shark', 'orchid', 'cup', 'bus', 'sunflower', 'dinosaur'] -> [40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
            "Validating classes ['whale', 'wolf', 'woman', 'cloud', 'porcupine', 'road', 'plate', 'table', 'sea', 'seal'] -> [50, 51, 52, 53, 54, 55, 56, 57, 58, 59]\n",
            "Accuracy: 0.32116666666666666\n",
            "BATCH [6]\n",
            "Training on ['bear', 'apple', 'forest', 'streetcar', 'can', 'bed', 'crocodile', 'keyboard', 'boy', 'raccoon'] -> [60, 61, 62, 63, 64, 65, 66, 67, 68, 69]\n",
            "Known classes [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69]\n",
            "Epoch [1/70], LR: [2.0]\n",
            "Loss: 0.20227143168449402\n",
            "Epoch [2/70], LR: [2.0]\n",
            "Loss: 0.21168793737888336\n",
            "Epoch [3/70], LR: [2.0]\n",
            "Loss: 0.1732725352048874\n",
            "Epoch [4/70], LR: [2.0]\n",
            "Loss: 0.18353648483753204\n",
            "Epoch [5/70], LR: [2.0]\n",
            "Loss: 0.17639613151550293\n",
            "Epoch [6/70], LR: [2.0]\n",
            "Loss: 0.1895178258419037\n",
            "Epoch [7/70], LR: [2.0]\n",
            "Loss: 0.18798796832561493\n",
            "Epoch [8/70], LR: [2.0]\n",
            "Loss: 0.16374748945236206\n",
            "Epoch [9/70], LR: [2.0]\n",
            "Loss: 0.17892175912857056\n",
            "Epoch [10/70], LR: [2.0]\n",
            "Loss: 0.17595738172531128\n",
            "Epoch [11/70], LR: [2.0]\n",
            "Loss: 0.19943052530288696\n",
            "Epoch [12/70], LR: [2.0]\n",
            "Loss: 0.18344736099243164\n",
            "Epoch [13/70], LR: [2.0]\n",
            "Loss: 0.16687847673892975\n",
            "Epoch [14/70], LR: [2.0]\n",
            "Loss: 0.19157211482524872\n",
            "Epoch [15/70], LR: [2.0]\n",
            "Loss: 0.18201754987239838\n",
            "Epoch [16/70], LR: [2.0]\n",
            "Loss: 0.1713615208864212\n",
            "Epoch [17/70], LR: [2.0]\n",
            "Loss: 0.16680030524730682\n",
            "Epoch [18/70], LR: [2.0]\n",
            "Loss: 0.18595291674137115\n",
            "Epoch [19/70], LR: [2.0]\n",
            "Loss: 0.19311898946762085\n",
            "Epoch [20/70], LR: [2.0]\n",
            "Loss: 0.15954941511154175\n",
            "Epoch [21/70], LR: [2.0]\n",
            "Loss: 0.17579405009746552\n",
            "Epoch [22/70], LR: [2.0]\n",
            "Loss: 0.18678422272205353\n",
            "Epoch [23/70], LR: [2.0]\n",
            "Loss: 0.16727684438228607\n",
            "Epoch [24/70], LR: [2.0]\n",
            "Loss: 0.1793716996908188\n",
            "Epoch [25/70], LR: [2.0]\n",
            "Loss: 0.17924335598945618\n",
            "Epoch [26/70], LR: [2.0]\n",
            "Loss: 0.1575164496898651\n",
            "Epoch [27/70], LR: [2.0]\n",
            "Loss: 0.1704842448234558\n",
            "Epoch [28/70], LR: [2.0]\n",
            "Loss: 0.18159398436546326\n",
            "Epoch [29/70], LR: [2.0]\n",
            "Loss: 0.1827494353055954\n",
            "Epoch [30/70], LR: [2.0]\n",
            "Loss: 0.18014562129974365\n",
            "Epoch [31/70], LR: [2.0]\n",
            "Loss: 0.17888227105140686\n",
            "Epoch [32/70], LR: [2.0]\n",
            "Loss: 0.2004118710756302\n",
            "Epoch [33/70], LR: [2.0]\n",
            "Loss: 0.19032609462738037\n",
            "Epoch [34/70], LR: [2.0]\n",
            "Loss: 0.19508466124534607\n",
            "Epoch [35/70], LR: [2.0]\n",
            "Loss: 0.16697894036769867\n",
            "Epoch [36/70], LR: [2.0]\n",
            "Loss: 0.1657114326953888\n",
            "Epoch [37/70], LR: [2.0]\n",
            "Loss: 0.16381485760211945\n",
            "Epoch [38/70], LR: [2.0]\n",
            "Loss: 0.16784368455410004\n",
            "Epoch [39/70], LR: [2.0]\n",
            "Loss: 0.16187378764152527\n",
            "Epoch [40/70], LR: [2.0]\n",
            "Loss: 0.1914752572774887\n",
            "Epoch [41/70], LR: [2.0]\n",
            "Loss: 0.1984662264585495\n",
            "Epoch [42/70], LR: [2.0]\n",
            "Loss: 0.18308734893798828\n",
            "Epoch [43/70], LR: [2.0]\n",
            "Loss: 0.1645771861076355\n",
            "Epoch [44/70], LR: [2.0]\n",
            "Loss: 0.166049987077713\n",
            "Epoch [45/70], LR: [2.0]\n",
            "Loss: 0.202705517411232\n",
            "Epoch [46/70], LR: [2.0]\n",
            "Loss: 0.21330586075782776\n",
            "Epoch [47/70], LR: [2.0]\n",
            "Loss: 0.20996424555778503\n",
            "Epoch [48/70], LR: [0.4]\n",
            "Loss: 0.18022799491882324\n",
            "Epoch [49/70], LR: [0.4]\n",
            "Loss: 0.20487558841705322\n",
            "Epoch [50/70], LR: [0.4]\n",
            "Loss: 0.1670742928981781\n",
            "Epoch [51/70], LR: [0.4]\n",
            "Loss: 0.17901666462421417\n",
            "Epoch [52/70], LR: [0.4]\n",
            "Loss: 0.1800049990415573\n",
            "Epoch [53/70], LR: [0.4]\n",
            "Loss: 0.1910630166530609\n",
            "Epoch [54/70], LR: [0.4]\n",
            "Loss: 0.2061474323272705\n",
            "Epoch [55/70], LR: [0.4]\n",
            "Loss: 0.17786304652690887\n",
            "Epoch [56/70], LR: [0.4]\n",
            "Loss: 0.18777817487716675\n",
            "Epoch [57/70], LR: [0.4]\n",
            "Loss: 0.16344347596168518\n",
            "Epoch [58/70], LR: [0.4]\n",
            "Loss: 0.168262779712677\n",
            "Epoch [59/70], LR: [0.4]\n",
            "Loss: 0.1571759581565857\n",
            "Epoch [60/70], LR: [0.4]\n",
            "Loss: 0.19795747101306915\n",
            "Epoch [61/70], LR: [0.4]\n",
            "Loss: 0.17739374935626984\n",
            "Epoch [62/70], LR: [0.4]\n",
            "Loss: 0.19585418701171875\n",
            "Epoch [63/70], LR: [0.4]\n",
            "Loss: 0.18972153961658478\n",
            "Epoch [64/70], LR: [0.08000000000000002]\n",
            "Loss: 0.15641607344150543\n",
            "Epoch [65/70], LR: [0.08000000000000002]\n",
            "Loss: 0.19515803456306458\n",
            "Epoch [66/70], LR: [0.08000000000000002]\n",
            "Loss: 0.16978681087493896\n",
            "Epoch [67/70], LR: [0.08000000000000002]\n",
            "Loss: 0.16750118136405945\n",
            "Epoch [68/70], LR: [0.08000000000000002]\n",
            "Loss: 0.14487402141094208\n",
            "Epoch [69/70], LR: [0.08000000000000002]\n",
            "Loss: 0.1670188456773758\n",
            "Epoch [70/70], LR: [0.08000000000000002]\n",
            "Loss: 0.17593945562839508\n",
            "Validating classes ['palm_tree', 'bottle', 'man', 'mushroom', 'snail', 'tiger', 'beaver', 'skyscraper', 'wardrobe', 'train'] -> [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "Validating classes ['bicycle', 'plain', 'couch', 'lobster', 'lion', 'chair', 'tulip', 'television', 'skunk', 'girl'] -> [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
            "Validating classes ['bowl', 'tank', 'lawn_mower', 'snake', 'ray', 'oak_tree', 'poppy', 'castle', 'telephone', 'clock'] -> [20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
            "Validating classes ['worm', 'rabbit', 'tractor', 'cockroach', 'house', 'lamp', 'sweet_pepper', 'crab', 'beetle', 'dolphin'] -> [30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
            "Validating classes ['mouse', 'flatfish', 'pear', 'lizard', 'shark', 'orchid', 'cup', 'bus', 'sunflower', 'dinosaur'] -> [40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
            "Validating classes ['whale', 'wolf', 'woman', 'cloud', 'porcupine', 'road', 'plate', 'table', 'sea', 'seal'] -> [50, 51, 52, 53, 54, 55, 56, 57, 58, 59]\n",
            "Validating classes ['bear', 'apple', 'forest', 'streetcar', 'can', 'bed', 'crocodile', 'keyboard', 'boy', 'raccoon'] -> [60, 61, 62, 63, 64, 65, 66, 67, 68, 69]\n",
            "Accuracy: 0.2872857142857143\n",
            "BATCH [7]\n",
            "Training on ['willow_tree', 'maple_tree', 'orange', 'rocket', 'spider', 'chimpanzee', 'cattle', 'kangaroo', 'bridge', 'fox'] -> [70, 71, 72, 73, 74, 75, 76, 77, 78, 79]\n",
            "Known classes [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79]\n",
            "Epoch [1/70], LR: [2.0]\n",
            "Loss: 0.20987699925899506\n",
            "Epoch [2/70], LR: [2.0]\n",
            "Loss: 0.20337152481079102\n",
            "Epoch [3/70], LR: [2.0]\n",
            "Loss: 0.2204602211713791\n",
            "Epoch [4/70], LR: [2.0]\n",
            "Loss: 0.19299621880054474\n",
            "Epoch [5/70], LR: [2.0]\n",
            "Loss: 0.20907807350158691\n",
            "Epoch [6/70], LR: [2.0]\n",
            "Loss: 0.1805698573589325\n",
            "Epoch [7/70], LR: [2.0]\n",
            "Loss: 0.25301799178123474\n",
            "Epoch [8/70], LR: [2.0]\n",
            "Loss: 0.179777130484581\n",
            "Epoch [9/70], LR: [2.0]\n",
            "Loss: 0.1799698770046234\n",
            "Epoch [10/70], LR: [2.0]\n",
            "Loss: 0.19233818352222443\n",
            "Epoch [11/70], LR: [2.0]\n",
            "Loss: 0.18506652116775513\n",
            "Epoch [12/70], LR: [2.0]\n",
            "Loss: 0.16487304866313934\n",
            "Epoch [13/70], LR: [2.0]\n",
            "Loss: 0.21542540192604065\n",
            "Epoch [14/70], LR: [2.0]\n",
            "Loss: 0.1876247525215149\n",
            "Epoch [15/70], LR: [2.0]\n",
            "Loss: 0.2005334347486496\n",
            "Epoch [16/70], LR: [2.0]\n",
            "Loss: 0.1630687564611435\n",
            "Epoch [17/70], LR: [2.0]\n",
            "Loss: 0.23058202862739563\n",
            "Epoch [18/70], LR: [2.0]\n",
            "Loss: 0.19235578179359436\n",
            "Epoch [19/70], LR: [2.0]\n",
            "Loss: 0.20782196521759033\n",
            "Epoch [20/70], LR: [2.0]\n",
            "Loss: 0.20964603126049042\n",
            "Epoch [21/70], LR: [2.0]\n",
            "Loss: 0.19057832658290863\n",
            "Epoch [22/70], LR: [2.0]\n",
            "Loss: 0.1964610069990158\n",
            "Epoch [23/70], LR: [2.0]\n",
            "Loss: 0.18903696537017822\n",
            "Epoch [24/70], LR: [2.0]\n",
            "Loss: 0.21434979140758514\n",
            "Epoch [25/70], LR: [2.0]\n",
            "Loss: 0.18267731368541718\n",
            "Epoch [26/70], LR: [2.0]\n",
            "Loss: 0.18624432384967804\n",
            "Epoch [27/70], LR: [2.0]\n",
            "Loss: 0.2091660052537918\n",
            "Epoch [28/70], LR: [2.0]\n",
            "Loss: 0.19366668164730072\n",
            "Epoch [29/70], LR: [2.0]\n",
            "Loss: 0.1791030615568161\n",
            "Epoch [30/70], LR: [2.0]\n",
            "Loss: 0.1941014677286148\n",
            "Epoch [31/70], LR: [2.0]\n",
            "Loss: 0.18153373897075653\n",
            "Epoch [32/70], LR: [2.0]\n",
            "Loss: 0.2146119922399521\n",
            "Epoch [33/70], LR: [2.0]\n",
            "Loss: 0.1974683254957199\n",
            "Epoch [34/70], LR: [2.0]\n",
            "Loss: 0.18467454612255096\n",
            "Epoch [35/70], LR: [2.0]\n",
            "Loss: 0.18079765141010284\n",
            "Epoch [36/70], LR: [2.0]\n",
            "Loss: 0.19419854879379272\n",
            "Epoch [37/70], LR: [2.0]\n",
            "Loss: 0.18181131780147552\n",
            "Epoch [38/70], LR: [2.0]\n",
            "Loss: 0.20877014100551605\n",
            "Epoch [39/70], LR: [2.0]\n",
            "Loss: 0.17529983818531036\n",
            "Epoch [40/70], LR: [2.0]\n",
            "Loss: 0.2078065425157547\n",
            "Epoch [41/70], LR: [2.0]\n",
            "Loss: 0.230779767036438\n",
            "Epoch [42/70], LR: [2.0]\n",
            "Loss: 0.18980030715465546\n",
            "Epoch [43/70], LR: [2.0]\n",
            "Loss: 0.1792774647474289\n",
            "Epoch [44/70], LR: [2.0]\n",
            "Loss: 0.21427297592163086\n",
            "Epoch [45/70], LR: [2.0]\n",
            "Loss: 0.17442499101161957\n",
            "Epoch [46/70], LR: [2.0]\n",
            "Loss: 0.2021573781967163\n",
            "Epoch [47/70], LR: [2.0]\n",
            "Loss: 0.19455179572105408\n",
            "Epoch [48/70], LR: [0.4]\n",
            "Loss: 0.1684132069349289\n",
            "Epoch [49/70], LR: [0.4]\n",
            "Loss: 0.19058434665203094\n",
            "Epoch [50/70], LR: [0.4]\n",
            "Loss: 0.1685994416475296\n",
            "Epoch [51/70], LR: [0.4]\n",
            "Loss: 0.17358043789863586\n",
            "Epoch [52/70], LR: [0.4]\n",
            "Loss: 0.17949038743972778\n",
            "Epoch [53/70], LR: [0.4]\n",
            "Loss: 0.18246836960315704\n",
            "Epoch [54/70], LR: [0.4]\n",
            "Loss: 0.17206935584545135\n",
            "Epoch [55/70], LR: [0.4]\n",
            "Loss: 0.2014702409505844\n",
            "Epoch [56/70], LR: [0.4]\n",
            "Loss: 0.1810927838087082\n",
            "Epoch [57/70], LR: [0.4]\n",
            "Loss: 0.18565504252910614\n",
            "Epoch [58/70], LR: [0.4]\n",
            "Loss: 0.1785416156053543\n",
            "Epoch [59/70], LR: [0.4]\n",
            "Loss: 0.18329165875911713\n",
            "Epoch [60/70], LR: [0.4]\n",
            "Loss: 0.17321322858333588\n",
            "Epoch [61/70], LR: [0.4]\n",
            "Loss: 0.19983550906181335\n",
            "Epoch [62/70], LR: [0.4]\n",
            "Loss: 0.17459537088871002\n",
            "Epoch [63/70], LR: [0.4]\n",
            "Loss: 0.1959116905927658\n",
            "Epoch [64/70], LR: [0.08000000000000002]\n",
            "Loss: 0.17602834105491638\n",
            "Epoch [65/70], LR: [0.08000000000000002]\n",
            "Loss: 0.18663984537124634\n",
            "Epoch [66/70], LR: [0.08000000000000002]\n",
            "Loss: 0.18069671094417572\n",
            "Epoch [67/70], LR: [0.08000000000000002]\n",
            "Loss: 0.17473238706588745\n",
            "Epoch [68/70], LR: [0.08000000000000002]\n",
            "Loss: 0.1747686117887497\n",
            "Epoch [69/70], LR: [0.08000000000000002]\n",
            "Loss: 0.17939749360084534\n",
            "Epoch [70/70], LR: [0.08000000000000002]\n",
            "Loss: 0.1845051348209381\n",
            "Validating classes ['palm_tree', 'bottle', 'man', 'mushroom', 'snail', 'tiger', 'beaver', 'skyscraper', 'wardrobe', 'train'] -> [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "Validating classes ['bicycle', 'plain', 'couch', 'lobster', 'lion', 'chair', 'tulip', 'television', 'skunk', 'girl'] -> [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
            "Validating classes ['bowl', 'tank', 'lawn_mower', 'snake', 'ray', 'oak_tree', 'poppy', 'castle', 'telephone', 'clock'] -> [20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
            "Validating classes ['worm', 'rabbit', 'tractor', 'cockroach', 'house', 'lamp', 'sweet_pepper', 'crab', 'beetle', 'dolphin'] -> [30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
            "Validating classes ['mouse', 'flatfish', 'pear', 'lizard', 'shark', 'orchid', 'cup', 'bus', 'sunflower', 'dinosaur'] -> [40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
            "Validating classes ['whale', 'wolf', 'woman', 'cloud', 'porcupine', 'road', 'plate', 'table', 'sea', 'seal'] -> [50, 51, 52, 53, 54, 55, 56, 57, 58, 59]\n",
            "Validating classes ['bear', 'apple', 'forest', 'streetcar', 'can', 'bed', 'crocodile', 'keyboard', 'boy', 'raccoon'] -> [60, 61, 62, 63, 64, 65, 66, 67, 68, 69]\n",
            "Validating classes ['willow_tree', 'maple_tree', 'orange', 'rocket', 'spider', 'chimpanzee', 'cattle', 'kangaroo', 'bridge', 'fox'] -> [70, 71, 72, 73, 74, 75, 76, 77, 78, 79]\n",
            "Accuracy: 0.2495\n",
            "BATCH [8]\n",
            "Training on ['butterfly', 'baby', 'elephant', 'shrew', 'pine_tree', 'squirrel', 'mountain', 'caterpillar', 'bee', 'camel'] -> [80, 81, 82, 83, 84, 85, 86, 87, 88, 89]\n",
            "Known classes [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89]\n",
            "Epoch [1/70], LR: [2.0]\n",
            "Loss: 0.2003106325864792\n",
            "Epoch [2/70], LR: [2.0]\n",
            "Loss: 0.18680612742900848\n",
            "Epoch [3/70], LR: [2.0]\n",
            "Loss: 0.19689564406871796\n",
            "Epoch [4/70], LR: [2.0]\n",
            "Loss: 0.20929913222789764\n",
            "Epoch [5/70], LR: [2.0]\n",
            "Loss: 0.2091945856809616\n",
            "Epoch [6/70], LR: [2.0]\n",
            "Loss: 0.20351088047027588\n",
            "Epoch [7/70], LR: [2.0]\n",
            "Loss: 0.2261596918106079\n",
            "Epoch [8/70], LR: [2.0]\n",
            "Loss: 0.2374344915151596\n",
            "Epoch [9/70], LR: [2.0]\n",
            "Loss: 0.20042382180690765\n",
            "Epoch [10/70], LR: [2.0]\n",
            "Loss: 0.19361360371112823\n",
            "Epoch [11/70], LR: [2.0]\n",
            "Loss: 0.1921078860759735\n",
            "Epoch [12/70], LR: [2.0]\n",
            "Loss: 0.19640333950519562\n",
            "Epoch [13/70], LR: [2.0]\n",
            "Loss: 0.18152859807014465\n",
            "Epoch [14/70], LR: [2.0]\n",
            "Loss: 0.18257954716682434\n",
            "Epoch [15/70], LR: [2.0]\n",
            "Loss: 0.21338431537151337\n",
            "Epoch [16/70], LR: [2.0]\n",
            "Loss: 0.18821047246456146\n",
            "Epoch [17/70], LR: [2.0]\n",
            "Loss: 0.19128850102424622\n",
            "Epoch [18/70], LR: [2.0]\n",
            "Loss: 0.18187379837036133\n",
            "Epoch [19/70], LR: [2.0]\n",
            "Loss: 0.18003970384597778\n",
            "Epoch [20/70], LR: [2.0]\n",
            "Loss: 0.18222372233867645\n",
            "Epoch [21/70], LR: [2.0]\n",
            "Loss: 0.20460942387580872\n",
            "Epoch [22/70], LR: [2.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhabEzELXMFR",
        "colab_type": "text"
      },
      "source": [
        "# **Catastrophic forgetting model (finetuning on iCaRL paper)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgMzUscI0asL",
        "colab_type": "text"
      },
      "source": [
        "CATASTROPHIC FORGETTING NET\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ph1HdRD40f5C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CatastrophicForgetting(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        self.total_num_classes = n_classes\n",
        "        self.known_classes = 0\n",
        "        self.list_known_classes=[]\n",
        "        self.exemplar_sets = []\n",
        "        self.flag_mean = True\n",
        "        self.exemplar_means = []\n",
        "\n",
        "        # We take a standard ResNet and Extend it\n",
        "        super(CatastrophicForgetting, self).__init__()\n",
        "        self.extractor = resnet32()\n",
        "        self.fully_connected = nn.Linear(self.extractor.out_dim, 0, bias=True)\n",
        "        torch.nn.init.xavier_uniform_(self.fully_connected.weight)\n",
        "\n",
        "        self.fully_connected.bias.data.fill_(0.01)\n",
        "        self.loss=nn.BCEWithLogitsLoss()\n",
        "        self.optimizer = optim.SGD(self.parameters(), lr=2.0,weight_decay=0.00001)\n",
        "        self.scheduler=MultiStepLR(self.optimizer,[47,63],gamma=GAMMA)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # X: input data\n",
        "        self.extractor.to(DEVICE)\n",
        "        self.fully_connected.to(DEVICE)\n",
        "        x = self.extractor(x)\n",
        "        x = self.fully_connected(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "    def increment_classes(self, classes_to_add):          # increments the number of classes we are using\n",
        "      n_classes_to_add = len(classes_to_add)\n",
        "      self.list_known_classes+=classes_to_add             #add the new classes\n",
        "      print(f\"Known classes {self.list_known_classes}\")\n",
        "      weight = self.fully_connected.weight.data\n",
        "      feature_size = self.fully_connected.in_features\n",
        "      old_num_classes = self.fully_connected.out_features\n",
        "      self.fully_connected = nn.Linear(\n",
        "          feature_size, old_num_classes+n_classes_to_add, bias = True)\n",
        "      self.fully_connected.weight.data[:old_num_classes] = weight\n",
        "\n",
        "\n",
        "    def update_representation(self, dataset):             \n",
        "        classes_to_idx = dataset.labels_to_int\n",
        "        new_classes = [cls for cls in classes_to_idx if cls not in self.list_known_classes] #gets indexes of new classes only\n",
        "\n",
        "        train_data_loader = DataLoader(\n",
        "            dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "\n",
        "        self.increment_classes(new_classes)\n",
        "        \n",
        "        optimizer = optim.SGD(self.parameters(), lr=2.0,weight_decay=0.00001, momentum = 0.9)\n",
        "        scheduler = MultiStepLR(optimizer,[47,63],gamma=GAMMA)\n",
        "        self.train()\n",
        "\n",
        "        eye = torch.eye(self.known_classes+len(new_classes))\n",
        "\n",
        "        for epoch in range(NUM_EPOCHS):\n",
        "          print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], LR: {scheduler.get_last_lr()}\")\n",
        "          i=0\n",
        "          for indices, images, labels in train_data_loader:\n",
        "            images = images.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "            indices = indices.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            output = self.forward(images)\n",
        "            \n",
        "            labels_one_hot_new_classes = []\n",
        "            for label in labels:\n",
        "              labels_one_hot_new_classes.append(eye[label])\n",
        "            labels_one_hot_new_classes = torch.stack(labels_one_hot_new_classes).cuda()\n",
        "            loss=self.loss(output,labels_one_hot_new_classes)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "          torch.cuda.empty_cache()\n",
        "          print(f\"Loss: {loss.item()}\")\n",
        "          scheduler.step() \n",
        "        self.known_classes += len(new_classes)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnIebV0E2A9j",
        "colab_type": "text"
      },
      "source": [
        "TRAINING CATASTROPHIC FORGETTING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASMmv3tc2E7X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = CatastrophicForgetting(n_classes=100)\n",
        "net.to(DEVICE)\n",
        "\n",
        "for i, train_dataset in enumerate(train_datasets):\n",
        "  torch.cuda.empty_cache()\n",
        "  print(f\"BATCH [{i}]\")\n",
        "  print(f\"Training on {train_dataset.labels} -> {train_dataset.labels_to_int}\")\n",
        "  net.train()\n",
        "  net.update_representation(copy.deepcopy(train_dataset))\n",
        "\n",
        "\n",
        "  net.eval()\n",
        "  corrects = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "    for num in range(i+1):\n",
        "      print(f\"Validating classes {test_datasets[num].labels} -> {test_datasets[num].labels_to_int}\")\n",
        "      test_dataloader = DataLoader(test_datasets[num], batch_size=BATCH_SIZE, num_workers=4, shuffle = True)\n",
        "      for _, images, labels in test_dataloader:\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "        outputs = net(images)\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "        corrects += torch.sum(preds == labels.data).data.item()\n",
        "        total += len(images)\n",
        "    torch.cuda.empty_cache()\n",
        "    # Calculate Accuracy\n",
        "    accuracy = corrects / float(total)\n",
        "    print(f\"Accuracy: {accuracy}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVuGEF_FkTip",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}